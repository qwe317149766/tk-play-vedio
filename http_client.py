"""
åŸºäº user_id çš„å…¨å±€ Session ç®¡ç† HTTP å®¢æˆ·ç«¯
ç‰¹æ€§ï¼š
 - æ¯ä¸ª user_id å¯¹åº”ä¸€ä¸ªç‹¬ç«‹çš„ session
 - æœ€å¤šä¿æŒ 5000 ä¸ª sessionï¼Œè¶…è¿‡æ—¶ç§»é™¤æœ€æ—©çš„
 - å¼‚æ­¥æ¸…ç†é˜Ÿåˆ—ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹
 - å¯é…ç½®æ¯ä¸ª user_id çš„ session ä½¿ç”¨æ¬¡æ•°
 - å®Œæ•´çš„é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
"""
import time
import threading
import asyncio
import queue
from typing import Optional, Dict, Any
from collections import OrderedDict

from curl_cffi import requests
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


# å…¨å±€ Session æ± ï¼ˆåŸºäº user_idï¼‰
_client_pool_lock = threading.RLock()
_client_pool: OrderedDict[str, Dict[str, Any]] = OrderedDict()
_client_pool_max_size = 5000

# å¼‚æ­¥æ¸…ç†é˜Ÿåˆ—
_cleanup_queue = queue.Queue()
_cleanup_thread = None


def _start_cleanup_thread():
    """å¯åŠ¨æ¸…ç†çº¿ç¨‹ï¼ˆå•ä¾‹ï¼‰"""
    global _cleanup_thread
    if _cleanup_thread is None or not _cleanup_thread.is_alive():
        _cleanup_thread = threading.Thread(target=_cleanup_worker, daemon=True)
        _cleanup_thread.start()


def _cleanup_worker():
    """å¼‚æ­¥æ¸…ç† session çš„å·¥ä½œçº¿ç¨‹"""
    while True:
        try:
            session_info = _cleanup_queue.get(timeout=1)
            if session_info is None:  # é€€å‡ºä¿¡å·
                break
            
            session = session_info.get("session")
            user_id = session_info.get("user_id", "unknown")
            
            try:
                if session:
                    session.close()
            except Exception as e:
                pass  # å¿½ç•¥æ¸…ç†é”™è¯¯
            
        except queue.Empty:
            continue
        except Exception:
            continue


class _StreamWrapper:
    """åŒ…è£…æµå“åº”ï¼Œclose æ—¶é‡Šæ”¾ session"""
    def __init__(self, client: "HttpClient", user_id: str, resp):
        self._client = client
        self._user_id = user_id
        self._resp = resp

    def __getattr__(self, item):
        return getattr(self._resp, item)

    def close(self):
        try:
            self._resp.close()
        finally:
            # æµå…³é—­æ—¶å¢åŠ ä½¿ç”¨æ¬¡æ•°
            self._client._increment_usage(self._user_id)


class HttpClient:
    """åŸºäº user_id çš„å…¨å±€ Session ç®¡ç† HTTP å®¢æˆ·ç«¯"""

    def __init__(
        self,
        proxy: Optional[str] = None,
        timeout: int = 30,
        max_retries: int = 3,
        retry_delay: float = 1.0,
        verify: bool = False,
        default_impersonate: str = "okhttp4_android",
        enable_keep_alive: bool = True,
        max_session_usage: int = 100,  # æ¯ä¸ª user_id çš„ session æœ€å¤§ä½¿ç”¨æ¬¡æ•°
        max_pool_size: int = 5000,  # å…¨å±€æœ€å¤§ session æ•°é‡
        debug: bool = False,
    ):
        self.proxy = proxy
        self.timeout = timeout
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.verify = verify
        self.default_impersonate = default_impersonate
        self.enable_keep_alive = enable_keep_alive
        self.debug = debug

        # Session ç®¡ç†é…ç½®
        self._max_session_usage = max(10, max_session_usage)
        self._max_pool_size = max(100, max_pool_size)
        
        # æ›´æ–°å…¨å±€æœ€å¤§å€¼
        global _client_pool_max_size
        _client_pool_max_size = self._max_pool_size

        # ç»Ÿè®¡ä¿¡æ¯
        self._stats = {
            "requests": 0,
            "failures": 0,
            "retries": 0,
            "proxy_close_errors": 0,
            "dead_sessions_removed": 0,
            "sessions_created": 0,
            "sessions_recycled": 0,
        }

        self._closed = False

        # å¯åŠ¨æ¸…ç†çº¿ç¨‹
        _start_cleanup_thread()

        if self.debug:
            print(f"[HttpClient] Init completed, max_pool_size={self._max_pool_size}, "
                  f"max_session_usage={self._max_session_usage}")

    def _create_session(self) -> requests.Session:
        """åˆ›å»ºæ–°çš„ Session"""
        session = requests.Session(
            timeout=self.timeout,
            verify=self.verify,
            impersonate=self.default_impersonate,
            proxies={"http": self.proxy, "https": self.proxy} if self.proxy else None,
        )

        # é…ç½® keep-alive
        if self.enable_keep_alive:
            session.headers.update({"Connection": "keep-alive"})
        else:
            session.headers.update({"Connection": "close"})

        self._stats["sessions_created"] += 1
        return session

    def _is_session_alive(self, session) -> bool:
        """æ£€æŸ¥ session æ˜¯å¦å­˜æ´»"""
        try:
            if not hasattr(session, "request"):
                return False
            
            if hasattr(session, "_closed") and session._closed:
                return False
            
            if hasattr(session, "curl"):
                if session.curl is None:
                    return False
            
            if hasattr(session, "cookies"):
                try:
                    _ = len(session.cookies)
                except Exception:
                    return False
            
            return True
        except Exception:
            return False

    def _get_or_create_session(self, user_id: str) -> requests.Session:
        """
        è·å–æˆ–åˆ›å»º user_id å¯¹åº”çš„ session
        å¦‚æœ session ä¸å­˜åœ¨æˆ–å·²å¤±æ•ˆï¼Œåˆ™åˆ›å»ºæ–°çš„
        å¦‚æœæ± å·²æ»¡ï¼Œç§»é™¤æœ€æ—©çš„ session
        """
        with _client_pool_lock:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨
            if user_id in _client_pool:
                session_info = _client_pool[user_id]
                session = session_info["session"]
                
                # æ£€æŸ¥æ˜¯å¦å­˜æ´»
                if self._is_session_alive(session):
                    # ç§»åˆ°æœ«å°¾ï¼ˆLRU æ›´æ–°ï¼‰
                    _client_pool.move_to_end(user_id)
                    
                    # å¦‚æœä½¿ç”¨æ¬¡æ•°è¶…é™ï¼Œè®°å½•æ—¥å¿—ä½†ç»§ç»­ä½¿ç”¨ï¼Œäº¤ç»™å›æ”¶æ± å¼‚æ­¥å¤„ç†
                    if session_info["usage_count"] >= self._max_session_usage:
                        if self.debug:
                            print(f"[HttpClient] Session ä½¿ç”¨æ¬¡æ•°å·²è¶…é™({session_info['usage_count']}/{self._max_session_usage})ï¼Œ"
                                  f"ç»§ç»­ä½¿ç”¨ï¼Œäº¤ç»™å›æ”¶æ± å¤„ç†: user_id={user_id}")
                    
                    return session
                else:
                    # Session å·²å¤±æ•ˆï¼Œç§»é™¤
                    if self.debug:
                        print(f"[HttpClient] Session å·²å¤±æ•ˆï¼Œé‡æ–°åˆ›å»º: user_id={user_id}")
                    
                    _cleanup_queue.put({
                        "session": session,
                        "user_id": user_id,
                    })
                    
                    del _client_pool[user_id]
                    self._stats["dead_sessions_removed"] += 1
            
            # æ£€æŸ¥æ± æ˜¯å¦å·²æ»¡
            if len(_client_pool) >= _client_pool_max_size:
                # ç§»é™¤æœ€æ—©çš„ï¼ˆFIFOï¼‰
                oldest_user_id, oldest_info = _client_pool.popitem(last=False)
                
                if self.debug:
                    print(f"[HttpClient] Session æ± å·²æ»¡({_client_pool_max_size})ï¼Œ"
                          f"ç§»é™¤æœ€æ—©çš„: user_id={oldest_user_id}, "
                          f"ä½¿ç”¨æ¬¡æ•°={oldest_info['usage_count']}")
                
                # åŠ å…¥æ¸…ç†é˜Ÿåˆ—
                _cleanup_queue.put({
                    "session": oldest_info["session"],
                    "user_id": oldest_user_id,
                })
                
                # å¦‚æœè¢«ç§»é™¤çš„ session ä½¿ç”¨æ¬¡æ•°è¾¾åˆ°ä¸Šé™ï¼Œè®¡å…¥å›æ”¶ç»Ÿè®¡
                if oldest_info["usage_count"] >= self._max_session_usage:
                    self._stats["sessions_recycled"] += 1
            
            # åˆ›å»ºæ–°çš„ session
            new_session = self._create_session()
            
            _client_pool[user_id] = {
                "session": new_session,
                "usage_count": 0,
                "created_at": time.time(),
            }
            
            if self.debug:
                print(f"[HttpClient] åˆ›å»ºæ–° session: user_id={user_id}, å½“å‰æ± å¤§å°={len(_client_pool)}")
            
            return new_session

    def _increment_usage(self, user_id: str):
        """å¢åŠ  user_id çš„ session ä½¿ç”¨æ¬¡æ•°"""
        with _client_pool_lock:
            if user_id in _client_pool:
                old_count = _client_pool[user_id]["usage_count"]
                _client_pool[user_id]["usage_count"] = old_count + 1
                new_count = old_count + 1
                
                # å½“è¾¾åˆ°æˆ–è¶…è¿‡ä½¿ç”¨ä¸Šé™æ—¶è®°å½•æ—¥å¿—
                if self.debug and new_count >= self._max_session_usage:
                    print(f"[HttpClient] Session ä½¿ç”¨æ¬¡æ•°: {new_count}/{self._max_session_usage}, "
                          f"user_id={user_id}, ç»§ç»­ä½¿ç”¨ï¼Œäº¤ç»™å›æ”¶æ± å¤„ç†")

    def _request_with_retry(
        self,
        method: str,
        url: str,
        user_id: str = "default",
        **kwargs
    ) -> requests.Response:
        """å¸¦é‡è¯•æœºåˆ¶çš„è¯·æ±‚"""
        self._stats["requests"] += 1
        
        last_exception = None
        
        for attempt in range(self.max_retries):
            try:
                # è·å–æˆ–åˆ›å»º session
                session = self._get_or_create_session(user_id)
                
                # æ‰§è¡Œè¯·æ±‚
                response = session.request(method, url, **kwargs)
                
                # æˆåŠŸï¼Œå¢åŠ ä½¿ç”¨æ¬¡æ•°
                self._increment_usage(user_id)
                
                return response
                
            except Exception as e:
                last_exception = e
                self._stats["retries"] += 1
                
                # åˆ¤æ–­é”™è¯¯ç±»å‹
                error_str = str(e).lower()
                is_proxy_closed = "proxy" in error_str and "close" in error_str
                is_timeout = "timeout" in error_str or "timed out" in error_str
                is_network_error = "connection" in error_str or "network" in error_str
                
                # ç»Ÿè®¡ proxy close é”™è¯¯
                if is_proxy_closed:
                    self._stats["proxy_close_errors"] += 1
                
                if self.debug or is_proxy_closed:
                    if is_proxy_closed:
                        error_type = "ğŸ”´ ä»£ç†/è¿æ¥å…³é—­"
                        print(f"[HttpClient] âš ï¸ PROXY CLOSE é”™è¯¯ï¼é‡è¯• {attempt + 1}/{self.max_retries}")
                        print(f"  URL: {url[:100]}")
                        print(f"  user_id: {user_id}")
                        print(f"  é”™è¯¯: {str(e)[:200]}")
                        with _client_pool_lock:
                            print(f"  æ± çŠ¶æ€: æ€»æ•°={len(_client_pool)}")
                    elif is_timeout:
                        error_type = "è¯·æ±‚è¶…æ—¶"
                    elif is_network_error:
                        error_type = "ç½‘ç»œé”™è¯¯"
                    else:
                        error_type = "è¯·æ±‚å¤±è´¥"
                    
                    if not is_proxy_closed or self.debug:
                        print(f"[HttpClient] é‡è¯• {attempt + 1}/{self.max_retries}: {error_type} -> {e}")
                
                # å¦‚æœæ˜¯ proxy close æˆ–ç½‘ç»œé”™è¯¯ï¼Œå¼ºåˆ¶é‡æ–°åˆ›å»º session
                if is_proxy_closed or is_network_error:
                    with _client_pool_lock:
                        if user_id in _client_pool:
                            session_info = _client_pool[user_id]
                            _cleanup_queue.put({
                                "session": session_info["session"],
                                "user_id": user_id,
                            })
                            del _client_pool[user_id]
                            self._stats["dead_sessions_removed"] += 1
                
                # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥
                if attempt == self.max_retries - 1:
                    self._stats["failures"] += 1
                    raise last_exception
                
                # å»¶è¿Ÿåé‡è¯•
                if self.retry_delay > 0:
                    time.sleep(self.retry_delay)
        
        # ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ
        self._stats["failures"] += 1
        raise last_exception

    # ========== å…¬å…± API ==========

    def request(
        self,
        method: str,
        url: str,
        user_id: str = None,
        session: Any = None,  # å‘åå…¼å®¹ï¼šæ—§çš„ session å‚æ•°
        stream: bool = False,
        **kwargs
    ) -> Any:
        """
        å‘é€ HTTP è¯·æ±‚
        
        Args:
            method: HTTP æ–¹æ³•
            url: è¯·æ±‚ URL
            user_id: ç”¨æˆ·IDï¼ˆç”¨äº session ç®¡ç†ï¼‰
            session: å‘åå…¼å®¹çš„ session å‚æ•°ï¼ˆä¼˜å…ˆçº§é«˜äº user_idï¼‰
            stream: æ˜¯å¦è¿”å›æµ
            **kwargs: å…¶ä»–è¯·æ±‚å‚æ•°
        """
        # å‘åå…¼å®¹ï¼šå¦‚æœæä¾›äº† sessionï¼Œä»ä¸­æå– user_id
        if session is not None:
            # å¦‚æœæ˜¯ FlowSessionWrapperï¼Œæå– user_id
            if isinstance(session, FlowSessionWrapper):
                user_id = session._user_id
            else:
                # ä½¿ç”¨ session å¯¹è±¡çš„ id ä½œä¸º user_id
                user_id = f"session_{id(session)}"
        
        # å¦‚æœè¿˜æ²¡æœ‰ user_idï¼Œä½¿ç”¨é»˜è®¤å€¼
        if user_id is None:
            user_id = "default"
        
        # ä» kwargs ä¸­ç§»é™¤ session å‚æ•°ï¼ˆé¿å…ä¼ é€’ç»™åº•å±‚ï¼‰
        kwargs.pop('session', None)
        
        response = self._request_with_retry(method, url, user_id, stream=stream, **kwargs)
        
        if stream:
            return _StreamWrapper(self, user_id, response)
        else:
            # éæµå¼è¯·æ±‚ï¼Œå¢åŠ ä½¿ç”¨æ¬¡æ•°
            self._increment_usage(user_id)
            return response

    def get(self, url: str, user_id: str = None, session: Any = None, **kwargs) -> requests.Response:
        """GET è¯·æ±‚"""
        return self.request("GET", url, user_id, session, **kwargs)

    def post(self, url: str, user_id: str = None, session: Any = None, **kwargs) -> requests.Response:
        """POST è¯·æ±‚"""
        return self.request("POST", url, user_id, session, **kwargs)

    def put(self, url: str, user_id: str = None, session: Any = None, **kwargs) -> requests.Response:
        """PUT è¯·æ±‚"""
        return self.request("PUT", url, user_id, session, **kwargs)

    def delete(self, url: str, user_id: str = None, session: Any = None, **kwargs) -> requests.Response:
        """DELETE è¯·æ±‚"""
        return self.request("DELETE", url, user_id, session, **kwargs)

    def head(self, url: str, user_id: str = None, session: Any = None, **kwargs) -> requests.Response:
        """HEAD è¯·æ±‚"""
        return self.request("HEAD", url, user_id, session, **kwargs)

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with _client_pool_lock:
            pool_size = len(_client_pool)
            
            # è®¡ç®—å¹³å‡ä½¿ç”¨æ¬¡æ•°
            if pool_size > 0:
                total_usage = sum(info["usage_count"] for info in _client_pool.values())
                avg_usage = total_usage / pool_size
            else:
                avg_usage = 0
        
        return {
            **self._stats,
            "pool_size": pool_size,
            "pool_max_size": _client_pool_max_size,
            "avg_usage_count": avg_usage,
        }

    def clear_user_session(self, user_id: str):
        """æ¸…é™¤æŒ‡å®š user_id çš„ session"""
        with _client_pool_lock:
            if user_id in _client_pool:
                session_info = _client_pool[user_id]
                _cleanup_queue.put({
                    "session": session_info["session"],
                    "user_id": user_id,
                })
                del _client_pool[user_id]
                
                if self.debug:
                    print(f"[HttpClient] æ¸…é™¤ session: user_id={user_id}")

    def update_proxy(self, proxy: str):
        """æ›´æ–°ä»£ç†é…ç½®"""
        self.proxy = proxy
        if self.debug:
            print(f"[HttpClient] ä»£ç†å·²æ›´æ–°: {proxy}")

    # ========== å‘åå…¼å®¹ APIï¼ˆflow_session æ¥å£ï¼‰==========

    def get_flow_session(self, device_id: str = None) -> FlowSessionWrapper:
        """
        è·å– flow sessionï¼ˆè‡ªåŠ¨ç®¡ç†ç‰ˆæœ¬ï¼‰
        
        å¦‚æœä¸ä¼  device_idï¼Œåˆ™ä»å…¨å±€æ± ä¸­è‡ªåŠ¨è·å–ä¸€ä¸ªå¯ç”¨çš„ session
        ï¼ˆä½¿ç”¨æ¬¡æ•°æœªè¾¾åˆ°ä¸Šé™çš„ sessionï¼‰
        
        Args:
            device_id: å¯é€‰çš„è®¾å¤‡IDï¼ˆç”¨ä½œ user_idï¼‰
                      å¦‚æœæä¾›ï¼Œåˆ™ä½¿ç”¨è¯¥ device_id ç»‘å®šçš„ session
                      å¦‚æœä¸æä¾›ï¼Œåˆ™è‡ªåŠ¨ä»æ± ä¸­è·å–å¯ç”¨çš„ session
            
        Returns:
            FlowSessionWrapper å¯¹è±¡
        """
        if device_id:
            # ä¼ ç»Ÿæ¨¡å¼ï¼šä½¿ç”¨ device_id ç»‘å®šçš„ session
            user_id = f"device_{device_id}"
        else:
            # è‡ªåŠ¨æ¨¡å¼ï¼šä»æ± ä¸­è·å–å¯ç”¨çš„ session
            user_id = self._get_available_session_id()
        
        return FlowSessionWrapper(self, user_id)
    
    def _get_available_session_id(self) -> str:
        """
        ä»å…¨å±€æ± ä¸­è·å–ä¸€ä¸ªå¯ç”¨çš„ session ID
        ç­–ç•¥ï¼š
        1. ä¼˜å…ˆæŸ¥æ‰¾ usage_count < max_session_usage çš„ session
        2. å¦‚æœæ²¡æœ‰å¯ç”¨çš„ï¼š
           - æ± æœªæ»¡ï¼šåˆ›å»ºæ–°çš„
           - æ± å·²æ»¡ï¼šè§¦å‘åå°æ¸…ç†ï¼Œç„¶åé‡è¯•
        
        Returns:
            å¯ç”¨çš„ user_id
        """
        retry_count = 0
        max_retries = 3
        
        while retry_count < max_retries:
            with _client_pool_lock:
                # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šæŸ¥æ‰¾ä½¿ç”¨æ¬¡æ•°æœªè¾¾åˆ°ä¸Šé™çš„ session
                for user_id, session_info in _client_pool.items():
                    if session_info["usage_count"] < self._max_session_usage:
                        # æ‰¾åˆ°å¯ç”¨çš„ session
                        if self.debug:
                            print(f"[HttpClient] å¤ç”¨ç°æœ‰ session: {user_id}, "
                                  f"ä½¿ç”¨æ¬¡æ•°={session_info['usage_count']}/{self._max_session_usage}")
                        return user_id
                
                # ç¬¬äºŒä¼˜å…ˆçº§ï¼šæ£€æŸ¥æ± æ˜¯å¦å·²æ»¡
                if len(_client_pool) < _client_pool_max_size:
                    # æ± æœªæ»¡ï¼Œåˆ›å»ºæ–°çš„
                    import time
                    new_user_id = f"auto_session_{int(time.time() * 1000)}"
                    
                    if self.debug:
                        print(f"[HttpClient] æ± æœªæ»¡ï¼Œåˆ›å»ºæ–°çš„è‡ªåŠ¨ session: {new_user_id} "
                              f"(æ± å¤§å°: {len(_client_pool)}/{_client_pool_max_size})")
                    
                    return new_user_id
                else:
                    # æ± å·²æ»¡ä¸”æ²¡æœ‰å¯ç”¨ sessionï¼Œè§¦å‘åå°æ¸…ç†
                    if self.debug:
                        print(f"[HttpClient] æ± å·²æ»¡ä¸”æ— å¯ç”¨ sessionï¼Œè§¦å‘åå°æ¸…ç† "
                              f"(é‡è¯• {retry_count + 1}/{max_retries})")
            
            # åœ¨é”å¤–è§¦å‘æ¸…ç†
            self._trigger_cleanup_full_sessions()
            
            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©æ¸…ç†å®Œæˆ
            import time
            time.sleep(0.1)
            retry_count += 1
        
        # é‡è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
        raise RuntimeError(f"æ— æ³•è·å–å¯ç”¨ session: æ± å·²æ»¡({_client_pool_max_size})ä¸”æ‰€æœ‰ session éƒ½å·²è¾¾åˆ°ä½¿ç”¨ä¸Šé™")

    def release_flow_session(self, session: Any):
        """
        å‘åå…¼å®¹ï¼šé‡Šæ”¾ flow session
        
        åœ¨æ–°çš„è®¾è®¡ä¸­ï¼Œsession æ˜¯è‡ªåŠ¨ç®¡ç†çš„ï¼Œè¿™ä¸ªæ–¹æ³•ä»€ä¹ˆéƒ½ä¸åš
        
        Args:
            session: session å¯¹è±¡ï¼ˆå¿½ç•¥ï¼‰
        """
        pass  # æ–°è®¾è®¡ä¸­è‡ªåŠ¨ç®¡ç†ï¼Œä¸éœ€è¦æ‰‹åŠ¨é‡Šæ”¾

    def _trigger_cleanup_full_sessions(self):
        """
        è§¦å‘åå°æ¸…ç†ï¼šåˆ†æ‰¹æ¸…é™¤æ‰€æœ‰è¾¾åˆ°ä½¿ç”¨ä¸Šé™çš„ session
        ä¼˜å…ˆæ¸…é™¤æœ€æ—©åˆ›å»ºçš„ sessionï¼ˆæŒ‰ created_at æ’åºï¼‰
        """
        sessions_to_cleanup = []
        
        with _client_pool_lock:
            # æ‰¾å‡ºæ‰€æœ‰è¾¾åˆ°ä½¿ç”¨ä¸Šé™çš„ session
            for user_id, session_info in _client_pool.items():
                if session_info["usage_count"] >= self._max_session_usage:
                    sessions_to_cleanup.append((
                        user_id,
                        session_info["session"],
                        session_info["created_at"],
                        session_info["usage_count"]
                    ))
            
            if not sessions_to_cleanup:
                if self.debug:
                    print(f"[HttpClient] æ— éœ€æ¸…ç†ï¼Œæ²¡æœ‰è¾¾åˆ°ä¸Šé™çš„ session")
                return
            
            # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œæœ€æ—©çš„ä¼˜å…ˆ
            sessions_to_cleanup.sort(key=lambda x: x[2])  # x[2] æ˜¯ created_at
            
            # åˆ†æ‰¹æ¸…ç†ï¼šæ¯æ¬¡æ¸…ç† 20% æˆ–è‡³å°‘ 1 ä¸ª
            batch_size = max(1, len(sessions_to_cleanup) // 5)
            batch_to_cleanup = sessions_to_cleanup[:batch_size]
            
            if self.debug:
                print(f"[HttpClient] å¼€å§‹åˆ†æ‰¹æ¸…ç†: å…± {len(sessions_to_cleanup)} ä¸ªè¾¾åˆ°ä¸Šé™çš„ sessionï¼Œ"
                      f"æœ¬æ¬¡æ¸…ç† {len(batch_to_cleanup)} ä¸ª")
            
            # ç§»é™¤å¹¶åŠ å…¥æ¸…ç†é˜Ÿåˆ—
            for user_id, session, created_at, usage_count in batch_to_cleanup:
                # ä»æ± ä¸­ç§»é™¤
                if user_id in _client_pool:
                    del _client_pool[user_id]
                
                # åŠ å…¥æ¸…ç†é˜Ÿåˆ—
                _cleanup_queue.put({
                    "session": session,
                    "user_id": user_id,
                })
                
                # æ›´æ–°ç»Ÿè®¡
                self._stats["sessions_recycled"] += 1
                
                if self.debug:
                    import time
                    age = time.time() - created_at
                    print(f"[HttpClient] æ¸…ç† session: user_id={user_id}, "
                          f"ä½¿ç”¨æ¬¡æ•°={usage_count}, å­˜æ´»æ—¶é—´={age:.1f}ç§’")

    def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        self._closed = True
        
        with _client_pool_lock:
            # å°†æ‰€æœ‰ session åŠ å…¥æ¸…ç†é˜Ÿåˆ—
            for user_id, session_info in _client_pool.items():
                _cleanup_queue.put({
                    "session": session_info["session"],
                    "user_id": user_id,
                })
            
            _client_pool.clear()
        
        if self.debug:
            print(f"[HttpClient] å·²å…³é—­ï¼Œæ¸…ç†äº†æ‰€æœ‰ session")

    def __del__(self):
        try:
            self.close()
        except:
            pass


# ========== å‘åå…¼å®¹ APIï¼ˆåŸºäº flow_session çš„æ—§æ¥å£ï¼‰==========

def get_flow_session_client(
    proxy: Optional[str] = None,
    timeout: int = 30,
    max_retries: int = 3,
    retry_delay: float = 1.0,
    max_session_usage: int = 100,
    max_pool_size: int = 5000,
    debug: bool = False,
) -> HttpClient:
    """
    åˆ›å»ºä¸€ä¸ª HttpClient å®ä¾‹ï¼ˆå‘åå…¼å®¹ï¼‰
    
    æ³¨æ„ï¼šæ–°çš„è®¾è®¡ä¸­ï¼Œsession ç®¡ç†åŸºäº user_id
    """
    return HttpClient(
        proxy=proxy,
        timeout=timeout,
        max_retries=max_retries,
        retry_delay=retry_delay,
        max_session_usage=max_session_usage,
        max_pool_size=max_pool_size,
        debug=debug,
    )


class FlowSessionWrapper:
    """
    å‘åå…¼å®¹çš„ flow_session åŒ…è£…å™¨
    å°†æ—§çš„ flow_session API é€‚é…åˆ°æ–°çš„ user_id æ¨¡å¼
    """
    def __init__(self, client: HttpClient, user_id: str):
        self._client = client
        self._user_id = user_id

    def request(self, method: str, url: str, **kwargs):
        return self._client.request(method, url, self._user_id, **kwargs)

    def get(self, url: str, **kwargs):
        return self._client.get(url, self._user_id, **kwargs)

    def post(self, url: str, **kwargs):
        return self._client.post(url, self._user_id, **kwargs)


# ========== å…¨å±€è¾…åŠ©å‡½æ•° ==========

def get_global_pool_stats() -> Dict[str, Any]:
    """è·å–å…¨å±€æ± ç»Ÿè®¡ä¿¡æ¯"""
    with _client_pool_lock:
        pool_size = len(_client_pool)
        
        if pool_size > 0:
            usage_counts = [info["usage_count"] for info in _client_pool.values()]
            avg_usage = sum(usage_counts) / len(usage_counts)
            max_usage = max(usage_counts)
            min_usage = min(usage_counts)
        else:
            avg_usage = max_usage = min_usage = 0
        
        return {
            "pool_size": pool_size,
            "pool_max_size": _client_pool_max_size,
            "avg_usage_count": avg_usage,
            "max_usage_count": max_usage,
            "min_usage_count": min_usage,
            "cleanup_queue_size": _cleanup_queue.qsize(),
        }


def clear_global_pool():
    """æ¸…ç©ºå…¨å±€æ± """
    with _client_pool_lock:
        for user_id, session_info in _client_pool.items():
            _cleanup_queue.put({
                "session": session_info["session"],
                "user_id": user_id,
            })
        
        _client_pool.clear()


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    client = HttpClient(debug=True, max_session_usage=5, max_pool_size=10)
    
    print("\næµ‹è¯•1: åŒä¸€ user_id å¤šæ¬¡è¯·æ±‚")
    for i in range(7):
        try:
            resp = client.get("https://httpbin.org/get", user_id="user_001")
            print(f"  è¯·æ±‚ {i+1}: æˆåŠŸ, çŠ¶æ€ç ={resp.status_code}")
        except Exception as e:
            print(f"  è¯·æ±‚ {i+1}: å¤±è´¥, é”™è¯¯={e}")
    
    print(f"\nå½“å‰æ± çŠ¶æ€: {client.get_stats()}")
    
    print("\næµ‹è¯•2: å¤šä¸ªä¸åŒ user_id")
    for i in range(15):
        try:
            resp = client.get("https://httpbin.org/get", user_id=f"user_{i:03d}")
            print(f"  user_{i:03d}: æˆåŠŸ")
        except Exception as e:
            print(f"  user_{i:03d}: å¤±è´¥")
    
    print(f"\næœ€ç»ˆæ± çŠ¶æ€: {client.get_stats()}")
    print(f"å…¨å±€æ± ç»Ÿè®¡: {get_global_pool_stats()}")
    
    client.close()
