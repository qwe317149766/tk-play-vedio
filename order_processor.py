"""
è®¢å•å¤„ç†è„šæœ¬
ä» uni_order è¡¨æ‹‰å–è®¢å•ï¼Œå¹¶å‘å¤„ç†è§†é¢‘æ’­æ”¾ä»»åŠ¡

å‘½ä»¤è¡Œå‚æ•°ï¼š
    python order_processor.py [table_number]
    ä¾‹å¦‚ï¼š
    - python order_processor.py 1  # ä½¿ç”¨ uni_devices_1 è¡¨
    - python order_processor.py 2  # ä½¿ç”¨ uni_devices_2 è¡¨
"""
import os
import sys
import json
import time
import random
import asyncio
import threading
import argparse
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from mysql_db import MySQLDB
from mysql_pool import MySQLConnectionPool  # æ–°å¢ï¼šä½¿ç”¨è¿æ¥æ± 
from config_loader import ConfigLoader
from tiktok_api import TikTokAPI
from message_queue import MessageQueue
from redis_client import RedisClient  # æ–°å¢ï¼šä½¿ç”¨Redisç¼“å­˜
import http_client_async  # æ–°å¢ï¼šç”¨äºæ¸…ç†HTTP sessionæ± 
import logging

# é…ç½®æ—¥å¿—ï¼ˆåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶ï¼‰
def setup_logging():
    """é…ç½®æ—¥å¿—ï¼šåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶"""
    # åˆ›å»º logs ç›®å½•
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    log_filename = os.path.join(log_dir, f"order_processor_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # åˆ›å»ºæ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)  # è®¾ç½®ä¸º DEBUG ä»¥æ•è·æ‰€æœ‰é˜¶æ®µæ—¥å¿—
    
    # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
    root_logger.handlers.clear()
    
    # 1. æ§åˆ¶å°å¤„ç†å™¨ï¼ˆINFOçº§åˆ«ï¼‰
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter(log_format)
    console_handler.setFormatter(console_formatter)
    root_logger.addHandler(console_handler)
    
    # 2. æ–‡ä»¶å¤„ç†å™¨ï¼ˆDEBUGçº§åˆ«ï¼ŒåŒ…å«æ‰€æœ‰è¯¦ç»†æ—¥å¿—ï¼‰
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(log_format)
    file_handler.setFormatter(file_formatter)
    root_logger.addHandler(file_handler)
    
    return log_filename

# è®¾ç½®æ—¥å¿—
log_file = None
try:
    log_file = setup_logging()
except Exception as e:
    # å¦‚æœæ—¥å¿—è®¾ç½®å¤±è´¥ï¼Œå›é€€åˆ°åŸºæœ¬é…ç½®
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    print(f"è­¦å‘Š: æ—¥å¿—æ–‡ä»¶è®¾ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æ§åˆ¶å°è¾“å‡º")

logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
_db: Optional[MySQLDB] = None
_api: Optional[TikTokAPI] = None
_redis: Optional[RedisClient] = None  # Redis å®¢æˆ·ç«¯å®ä¾‹
_device_fail_count: Dict[str, int] = {}  # è®¾å¤‡è¿ç»­å¤±è´¥æ¬¡æ•°ï¼Œkey: device_id, value: è¿ç»­å¤±è´¥æ¬¡æ•°
_device_fail_lock = threading.Lock()  # è®¾å¤‡å¤±è´¥è®¡æ•°é”
_page_size: int = 1000  # åˆ†é¡µå¤§å°ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
_device_fail_threshold: Optional[int] = None  # è®¾å¤‡è¿ç»­å¤±è´¥é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤æ¬¡æ•°åå°†è®¾å¤‡çŠ¶æ€æ›´æ–°ä¸º4ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
_thread_pool: Optional[Any] = None  # ä¸“ç”¨çº¿ç¨‹æ± ï¼Œç”¨äºæ•°æ®åº“æ“ä½œå’Œé˜»å¡IO
_stats_timeout: float = 45.0  # stats è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤45ç§’ï¼‰
_request_delay_min: float = 0.05  # è¯·æ±‚ä¹‹é—´çš„æœ€å°å»¶è¿Ÿï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤50msï¼‰
_request_delay_max: float = 0.15  # è¯·æ±‚ä¹‹é—´çš„æœ€å¤§å»¶è¿Ÿï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œé»˜è®¤150msï¼‰

# Redis é”®åå‰ç¼€
REDIS_DEVICE_PLAY_KEY = "tk_play:device:play_num"  # Hash: field=primary_key_id(ä¸»é”®ID), value=å¢é‡æ’­æ”¾æ¬¡æ•°
REDIS_ORDER_COMPLETE_KEY = "tk_play:order:complete_num"  # Hash: field=order_id, value=å¢é‡å®Œæˆæ¬¡æ•°
REDIS_ORDER_NUM_KEY = "tk_play:order:order_num"  # Hash: field=order_id, value=è®¢å•æ€»æ•°ï¼ˆç¼“å­˜ï¼Œé¿å…é¢‘ç¹æŸ¥åº“ï¼‰
REDIS_ORDER_INFO_KEY = "tk_play:order:info"  # Hash: field=order_id, value=JSON(è®¢å•å®Œæ•´ä¿¡æ¯)
REDIS_DEVICE_STATUS_KEY = "tk_play:device:status_update"  # Hash: field=primary_key_id, value=target_statusï¼ˆè®¾å¤‡çŠ¶æ€æ›´æ–°é˜Ÿåˆ—ï¼‰
REDIS_PARENT_ORDER_COMPLETE_KEY = "tk_play:parent_order:complete_num"  # Hash: field=parent_order_id, value=çˆ¶è®¢å•å®Œæˆæ¬¡æ•°
REDIS_ORDER_COMPLETE_ORDER_NUM_KEY = "tk_play:order:complete_order_num"  # Hash: field=order_id, value=å­è®¢å•çš„complate_order_num
REDIS_PARENT_ORDER_SUB_ORDER_NUM_KEY = "tk_play:parent_order:sub_order_num"  # Hash: field=parent_order_id, value=çˆ¶è®¢å•çš„sub_order_num

# ä»»åŠ¡ç»Ÿè®¡ï¼ˆç”¨äºç›‘æ§ï¼‰
_task_stats = {
    "total_completed": 0,
    "total_success": 0,
    "total_failed": 0,
    "last_check_time": time.time()
}
_task_stats_lock = threading.Lock()
_monitor_thread = None
_monitor_stop_event = threading.Event()

# è®¢å•å®Œæˆæ ‡å¿—ï¼ˆç”¨äºå–æ¶ˆå…¶ä»–è®¢å•æ£€æŸ¥ï¼‰
_order_completed_flag = False
_order_completed_lock = threading.Lock()




def device_status_monitor():
    """
    è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹
    æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡è®¾å¤‡çŠ¶æ€å’Œä»»åŠ¡æ‰§è¡Œæƒ…å†µ
    åŒæ—¶è‡ªåŠ¨æ¸…ç†åƒµå°¸è®¾å¤‡ï¼ˆçŠ¶æ€=ä½¿ç”¨ä¸­ä½†æ— å¯¹åº”ä»»åŠ¡ï¼‰
    """
    global _db_instance, _device_table_name, _queue_instance, _task_stats, _monitor_stop_event
    
    logger.info("[ç›‘æ§çº¿ç¨‹] è®¾å¤‡çŠ¶æ€ç›‘æ§å·²å¯åŠ¨ï¼ˆåŒ…å«åƒµå°¸è®¾å¤‡è‡ªåŠ¨æ¸…ç†ï¼‰")
    
    while not _monitor_stop_event.is_set():
        try:
            # ç­‰å¾…30ç§’æˆ–ç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å·
            if _monitor_stop_event.wait(30):
                break
            
            if _db_instance is None or _device_table_name is None:
                continue
            
            # æŸ¥è¯¢è®¾å¤‡çŠ¶æ€ç»Ÿè®¡
            try:
                status_sql = f"""
                SELECT 
                    status,
                    COUNT(*) as count
                FROM {_device_table_name}
                GROUP BY status
                """
                status_results = _db_instance.execute(status_sql, fetch=True)
                
                device_status_map = {
                    0: "å¯ç”¨",
                    1: "ä½¿ç”¨ä¸­",
                    2: "å·²å¤±æ•ˆ",
                    3: "å·²å®Œæˆ",
                    4: "è¿ç»­å¤±è´¥å¼‚å¸¸"
                }
                
                status_counts = {}
                total = 0
                for row in status_results:
                    status = row['status']
                    count = row['count']
                    status_counts[status] = count
                    total += count
                
                # æ„å»ºçŠ¶æ€æŠ¥å‘Š
                status_report = []
                for status in [0, 1, 4, 2, 3]:  # æŒ‰ä¼˜å…ˆçº§æ’åº
                    if status in status_counts:
                        count = status_counts[status]
                        name = device_status_map.get(status, f"çŠ¶æ€{status}")
                        percentage = (count / total * 100) if total > 0 else 0
                        status_report.append(f"{name}={count}({percentage:.1f}%)")
                
                # è·å–ä»»åŠ¡ç»Ÿè®¡
                with _task_stats_lock:
                    completed = _task_stats["total_completed"]
                    success = _task_stats["total_success"]
                    failed = _task_stats["total_failed"]
                    success_rate = (success / completed * 100) if completed > 0 else 0
                
                # è·å–é˜Ÿåˆ—çŠ¶æ€
                queue_info = ""
                if _queue_instance:
                    queue_stats = _queue_instance.get_stats()
                    queue_size = queue_stats.get("queue_size", 0)
                    running = queue_stats.get("running_tasks", 0)
                    queue_info = f"é˜Ÿåˆ—: {queue_size}å¾…å¤„ç†, {running}è¿è¡Œä¸­ | "
                
                # æ£€æµ‹"åƒµå°¸"è®¾å¤‡ï¼ˆä½¿ç”¨ä¸­ä½†æ²¡æœ‰å¯¹åº”ä»»åŠ¡çš„è®¾å¤‡ï¼‰
                zombie_devices = status_counts.get(1, 0) - running
                zombie_warning = ""
                if zombie_devices > 0:
                    zombie_warning = f" âš ï¸ å‘ç°{zombie_devices}ä¸ªåƒµå°¸è®¾å¤‡ï¼ˆçŠ¶æ€=ä½¿ç”¨ä¸­ä½†æ— ä»»åŠ¡ï¼‰"
                
                # æ‰“å°ç›‘æ§æŠ¥å‘Š
                logger.info("=" * 100)
                logger.info(f"ğŸ“Š [è®¾å¤‡ç›‘æ§] {queue_info}ä»»åŠ¡: {completed}å®Œæˆ({success}æˆåŠŸ/{failed}å¤±è´¥, æˆåŠŸç‡{success_rate:.1f}%) | è®¾å¤‡æ€»æ•°: {total}")
                logger.info(f"ğŸ“Š [è®¾å¤‡çŠ¶æ€] {', '.join(status_report)}{zombie_warning}")
                logger.info("=" * 100)
                
                # æ‰¹é‡å¤„ç†Redisä¸­çš„è®¾å¤‡çŠ¶æ€å˜æ›´è¯·æ±‚
                try:
                    if _redis:
                        status_updates = _redis.hgetall(REDIS_DEVICE_STATUS_KEY)
                        if status_updates:
                            update_count = len(status_updates)
                            logger.info(f"ğŸ”„ [è®¾å¤‡çŠ¶æ€æ‰¹é‡æ›´æ–°] å‘ç° {update_count} ä¸ªè®¾å¤‡éœ€è¦æ›´æ–°çŠ¶æ€")
                            
                            # æŒ‰ç…§æ‰¹æ¬¡å¤„ç†ï¼ˆæ¯æ‰¹200ä¸ªï¼‰
                            batch_size = 200
                            status_items = list(status_updates.items())
                            total_batches = (update_count + batch_size - 1) // batch_size
                            updated_count = 0
                            
                            for batch_idx in range(0, update_count, batch_size):
                                batch_data = status_items[batch_idx:batch_idx + batch_size]
                                current_batch = batch_idx // batch_size + 1
                                
                                try:
                                    # è·å–ä¸»é”®å­—æ®µå
                                    primary_key_field = get_table_primary_key_field(_db_instance, _device_table_name)
                                    
                                    # æ„å»ºCASE WHENæ‰¹é‡æ›´æ–°SQL
                                    case_when_parts = []
                                    primary_key_ids = []
                                    
                                    for primary_key_str, target_status_str in batch_data:
                                        try:
                                            primary_key_id = int(primary_key_str)
                                            target_status = int(target_status_str)
                                            case_when_parts.append(f"WHEN {primary_key_id} THEN {target_status}")
                                            primary_key_ids.append(primary_key_id)
                                        except (ValueError, TypeError) as e:
                                            logger.error(f"[è®¾å¤‡çŠ¶æ€æ›´æ–°] æ•°æ®æ ¼å¼é”™è¯¯: primary_key={primary_key_str}, status={target_status_str}, error={e}")
                                    
                                    if case_when_parts and primary_key_ids:
                                        case_when_sql = " ".join(case_when_parts)
                                        ids_list = ",".join(map(str, primary_key_ids))
                                        
                                        update_sql = f"""
                                        UPDATE {_device_table_name}
                                        SET status = (CASE {primary_key_field}
                                            {case_when_sql}
                                            ELSE status
                                        END)
                                        WHERE {primary_key_field} IN ({ids_list})
                                        """
                                        
                                        _db_instance.execute(update_sql)
                                        _db_instance.commit()
                                        updated_count += len(primary_key_ids)
                                        
                                        logger.info(f"âœ“ [è®¾å¤‡çŠ¶æ€æ‰¹é‡æ›´æ–°] æ‰¹æ¬¡ {current_batch}/{total_batches} å®Œæˆï¼ˆ{len(primary_key_ids)}ä¸ªè®¾å¤‡ï¼‰")
                                    
                                except Exception as batch_error:
                                    logger.error(f"âŒ [è®¾å¤‡çŠ¶æ€æ‰¹é‡æ›´æ–°] æ‰¹æ¬¡ {current_batch} å¤±è´¥: {batch_error}")
                                    import traceback
                                    logger.error(traceback.format_exc())
                            
                            # æ›´æ–°å®Œæˆåï¼Œæ¸…ç†Redisä¸­çš„è®¾å¤‡çŠ¶æ€é˜Ÿåˆ—
                            _redis.delete(REDIS_DEVICE_STATUS_KEY)
                            logger.info(f"âœ… [è®¾å¤‡çŠ¶æ€æ‰¹é‡æ›´æ–°] å®Œæˆ {updated_count}/{update_count} ä¸ªè®¾å¤‡çŠ¶æ€æ›´æ–°ï¼ŒRedisé˜Ÿåˆ—å·²æ¸…ç†")
                        
                except Exception as status_error:
                    logger.error(f"âŒ [è®¾å¤‡çŠ¶æ€æ‰¹é‡æ›´æ–°] å¤„ç†å¤±è´¥: {status_error}")
                    import traceback
                    logger.error(traceback.format_exc())
                
                # è‡ªåŠ¨æ¸…ç†åƒµå°¸è®¾å¤‡ï¼ˆå¦‚æœå­˜åœ¨ä¸”è¶…è¿‡é˜ˆå€¼ï¼‰
                # åªæœ‰å½“åƒµå°¸è®¾å¤‡æ•°é‡è¶…è¿‡ä¸€å®šé˜ˆå€¼æ—¶æ‰æ¸…ç†ï¼Œé¿å…è¯¯æ€æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
                zombie_threshold = max(50, int(running * 0.3))  # é˜ˆå€¼ï¼š50ä¸ªæˆ–è¿è¡Œä¸­ä»»åŠ¡çš„30%
                
                if zombie_devices > zombie_threshold:
                    try:
                        logger.warning(f"ğŸ”§ [åƒµå°¸è®¾å¤‡æ¸…ç†] åƒµå°¸è®¾å¤‡æ•°é‡({zombie_devices})è¶…è¿‡é˜ˆå€¼({zombie_threshold})ï¼Œå¼€å§‹æ¸…ç†...")
                        
                        # ç­–ç•¥ï¼šé‡ç½®æ‰€æœ‰status=1ä¸”update_timeè¶…è¿‡2åˆ†é’Ÿçš„è®¾å¤‡
                        # è¿™äº›è®¾å¤‡å¾ˆå¯èƒ½æ˜¯ä»»åŠ¡å¤±è´¥ä½†çŠ¶æ€æœªé‡ç½®çš„åƒµå°¸è®¾å¤‡
                        import time
                        five_minutes_ago = int(time.time()) - 120
                        
                        cleanup_sql = f"""
                        UPDATE {_device_table_name}
                        SET status = 0
                        WHERE status = 1 
                        AND update_time < %s
                        """
                        
                        result = _db_instance.execute(cleanup_sql, params=(five_minutes_ago,), fetch=False)
                        _db_instance.commit()
                        
                        # è·å–å½±å“çš„è¡Œæ•°
                        cleaned_count = result if isinstance(result, int) else 0
                        
                        if cleaned_count > 0:
                            logger.info(f"âœ… [åƒµå°¸è®¾å¤‡æ¸…ç†] æˆåŠŸæ¸…ç† {cleaned_count} ä¸ªåƒµå°¸è®¾å¤‡ï¼ˆupdate_time > 5åˆ†é’Ÿï¼‰")
                        else:
                            logger.info(f"ğŸ’¡ [åƒµå°¸è®¾å¤‡æ¸…ç†] æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„åƒµå°¸è®¾å¤‡ï¼ˆupdate_time > 5åˆ†é’Ÿï¼‰ï¼Œå¯èƒ½æ˜¯ä»»åŠ¡åˆšå¼€å§‹")
                        
                    except Exception as cleanup_error:
                        logger.error(f"âŒ [åƒµå°¸è®¾å¤‡æ¸…ç†] æ¸…ç†å¤±è´¥: {cleanup_error}")
                        import traceback
                        logger.error(traceback.format_exc())
                
            except Exception as e:
                logger.error(f"[ç›‘æ§çº¿ç¨‹] æŸ¥è¯¢è®¾å¤‡çŠ¶æ€å¤±è´¥: {e}")
                
        except Exception as e:
            logger.error(f"[ç›‘æ§çº¿ç¨‹] è¿è¡Œå¼‚å¸¸: {e}")
            import traceback
            logger.error(traceback.format_exc())
    
    logger.info("[ç›‘æ§çº¿ç¨‹] è®¾å¤‡çŠ¶æ€ç›‘æ§å·²åœæ­¢")


def set_device_status_in_redis(primary_key_value: int, target_status: int) -> bool:
    """
    è®¾ç½®è®¾å¤‡ç›®æ ‡çŠ¶æ€åˆ°Redisï¼ˆæ‰¹é‡æ›´æ–°é˜Ÿåˆ—ï¼‰
    
    Args:
        primary_key_value: è®¾å¤‡ä¸»é”®ID
        target_status: ç›®æ ‡çŠ¶æ€ï¼ˆ0=å¯ç”¨, 4=å¼‚å¸¸ç­‰ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return False
    
    try:
        # ä½¿ç”¨HSETè®¾ç½®è®¾å¤‡çš„ç›®æ ‡çŠ¶æ€
        # å¦‚æœåŒä¸€è®¾å¤‡æœ‰å¤šæ¬¡çŠ¶æ€å˜æ›´ï¼Œåªä¿ç•™æœ€åä¸€æ¬¡ï¼ˆè¦†ç›–ï¼‰
        _redis.hset(REDIS_DEVICE_STATUS_KEY, str(primary_key_value), str(target_status))
        logger.debug(f"[Redis] è®¾å¤‡ primary_key={primary_key_value} ç›®æ ‡çŠ¶æ€={target_status} å·²è®°å½•åˆ°Redisé˜Ÿåˆ—")
        return True
    except Exception as e:
        logger.error(f"[Redis] è®°å½•è®¾å¤‡çŠ¶æ€å¤±è´¥: primary_key={primary_key_value}, status={target_status}, error={e}")
        return False


def increment_device_play_in_redis(primary_key_value: int, amount: int = 1) -> bool:
    """
    å¢åŠ è®¾å¤‡æ’­æ”¾æ¬¡æ•°åˆ°Redis
    
    Args:
        primary_key_value: è®¾å¤‡ä¸»é”®ID
        amount: å¢é‡ï¼ˆé»˜è®¤ä¸º1ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return False
    
    try:
        _redis.hincrby(REDIS_DEVICE_PLAY_KEY, str(primary_key_value), amount)
        return True
    except Exception as e:
        logger.error(f"[Redis] å¢åŠ è®¾å¤‡æ’­æ”¾æ¬¡æ•°å¤±è´¥: primary_key_id={primary_key_value}, error={e}")
        return False


def increment_order_complete_in_redis(order_id: int, amount: int = 1) -> bool:
    """
    å¢åŠ è®¢å•å®Œæˆæ¬¡æ•°åˆ°Redisï¼ŒåŒæ—¶æ›´æ–°çˆ¶è®¢å•å®Œæˆæ¬¡æ•°
    
    Args:
        order_id: è®¢å•ID
        amount: å¢é‡ï¼ˆé»˜è®¤ä¸º1ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return False
    
    try:
        _redis.hincrby(REDIS_ORDER_COMPLETE_KEY, str(order_id), amount)
        
        # å¦‚æœè®¢å•æœ‰ parent_order_idï¼ŒåŒæ—¶æ›´æ–°çˆ¶è®¢å•å®Œæˆæ¬¡æ•°
        order_info = get_order_info_from_redis(order_id)
        if order_info:
            parent_order_id = order_info.get('parent_order_id')
            if parent_order_id:
                increment_parent_order_complete_in_redis(parent_order_id, amount)
                logger.debug(f"[è®¢å•å®Œæˆ] è®¢å• {order_id} å®Œæˆï¼Œçˆ¶è®¢å• {parent_order_id} å®Œæˆæ¬¡æ•°+{amount}")
        
        return True
    except Exception as e:
        logger.error(f"[Redis] å¢åŠ è®¢å•å®Œæˆæ¬¡æ•°å¤±è´¥: order_id={order_id}, error={e}")
        return False


def get_order_complete_from_redis(order_id: int) -> int:
    """
    ä»Redisè·å–è®¢å•å®Œæˆæ¬¡æ•°
    
    Args:
        order_id: è®¢å•ID
    
    Returns:
        è®¢å•å®Œæˆæ¬¡æ•°ï¼ˆå¦‚æœRedisä¸­æ²¡æœ‰ï¼Œè¿”å›0ï¼‰
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return 0
    
    try:
        value = _redis.hget(REDIS_ORDER_COMPLETE_KEY, str(order_id))
        if value is None:
            return 0
        return int(value)
    except Exception as e:
        logger.error(f"[Redis] è·å–è®¢å•å®Œæˆæ¬¡æ•°å¤±è´¥: order_id={order_id}, error={e}")
        return 0


def increment_parent_order_complete_in_redis(parent_order_id: int, amount: int = 1) -> bool:
    """
    å¢åŠ çˆ¶è®¢å•å®Œæˆæ¬¡æ•°åˆ°Redis
    
    Args:
        parent_order_id: çˆ¶è®¢å•ID
        amount: å¢é‡ï¼ˆé»˜è®¤ä¸º1ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return False
    
    try:
        # å¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå­˜åœ¨åˆ™å¢åŠ 
        if not _redis.hexists(REDIS_PARENT_ORDER_COMPLETE_KEY, str(parent_order_id)):
            _redis.hset(REDIS_PARENT_ORDER_COMPLETE_KEY, str(parent_order_id), amount)
        else:
            _redis.hincrby(REDIS_PARENT_ORDER_COMPLETE_KEY, str(parent_order_id), amount)
        return True
    except Exception as e:
        logger.error(f"[Redis] å¢åŠ çˆ¶è®¢å•å®Œæˆæ¬¡æ•°å¤±è´¥: parent_order_id={parent_order_id}, error={e}")
        return False


def get_parent_order_complete_from_redis(parent_order_id: int) -> int:
    """
    ä»Redisè·å–çˆ¶è®¢å•å®Œæˆæ¬¡æ•°
    
    Args:
        parent_order_id: çˆ¶è®¢å•ID
    
    Returns:
        çˆ¶è®¢å•å®Œæˆæ¬¡æ•°ï¼ˆå¦‚æœRedisä¸­æ²¡æœ‰ï¼Œè¿”å›0ï¼‰
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return 0
    
    try:
        value = _redis.hget(REDIS_PARENT_ORDER_COMPLETE_KEY, str(parent_order_id))
        if value is None:
            return 0
        return int(value)
    except Exception as e:
        logger.error(f"[Redis] è·å–çˆ¶è®¢å•å®Œæˆæ¬¡æ•°å¤±è´¥: parent_order_id={parent_order_id}, error={e}")
        return 0


def check_and_update_parent_order_completion(order_id: int, db: MySQLDB) -> bool:
    """
    æ£€æŸ¥å¹¶æ›´æ–°çˆ¶è®¢å•å®ŒæˆçŠ¶æ€
    
    Args:
        order_id: å­è®¢å•ID
        db: æ•°æ®åº“å®ä¾‹
    
    Returns:
        æ˜¯å¦æ›´æ–°äº†çˆ¶è®¢å•çŠ¶æ€
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return False
    
    try:
        # 1. ä»Redisè·å–è®¢å•ä¿¡æ¯ï¼ŒæŸ¥æ‰¾ parent_order_id
        order_info = get_order_info_from_redis(order_id)
        if not order_info:
            logger.warning(f"[çˆ¶è®¢å•æ£€æŸ¥] è®¢å• {order_id} åœ¨Redisä¸­ä¸å­˜åœ¨ï¼Œè·³è¿‡çˆ¶è®¢å•æ£€æŸ¥")
            return False
        
        parent_order_id = order_info.get('parent_order_id')
        if not parent_order_id:
            # æ²¡æœ‰çˆ¶è®¢å•ï¼Œä¸éœ€è¦æ£€æŸ¥
            return False
        
        # 2. ä»Redisè·å–çˆ¶è®¢å•çš„ sub_order_numï¼ˆè¿™ä¸ªå€¼æ¥è‡ªå­è®¢å•çš„ sub_order_numï¼‰
        sub_order_num_value = _redis.hget(REDIS_PARENT_ORDER_SUB_ORDER_NUM_KEY, str(parent_order_id))
        if sub_order_num_value is None:
            logger.warning(f"[çˆ¶è®¢å•æ£€æŸ¥] çˆ¶è®¢å• {parent_order_id} çš„ sub_order_num æœªåœ¨Redisä¸­æ‰¾åˆ°ï¼Œå°è¯•ä»å½“å‰è®¢å•è¯»å–...")
            # å°è¯•ä»å½“å‰è®¢å•ï¼ˆå­è®¢å•ï¼‰è¯»å– sub_order_num
            try:
                sub_order_num = order_info.get('sub_order_num', 0) or 0
                if sub_order_num > 0:
                    _redis.hset(REDIS_PARENT_ORDER_SUB_ORDER_NUM_KEY, str(parent_order_id), sub_order_num)
                    logger.debug(f"[çˆ¶è®¢å•æ£€æŸ¥] âœ“ ä»å½“å‰è®¢å• {order_id} è¯»å– sub_order_num={sub_order_num} å¹¶å­˜å…¥ Redisï¼ˆkey=parent_order_id={parent_order_id}ï¼‰")
                else:
                    logger.warning(f"[çˆ¶è®¢å•æ£€æŸ¥] å½“å‰è®¢å• {order_id} çš„ sub_order_num={sub_order_num} <= 0ï¼Œè·³è¿‡çˆ¶è®¢å•æ£€æŸ¥")
                    return False
            except Exception as e:
                logger.error(f"[çˆ¶è®¢å•æ£€æŸ¥] ä»å½“å‰è®¢å• {order_id} è¯»å– sub_order_num å¤±è´¥: {e}")
                return False
        else:
            sub_order_num = int(sub_order_num_value)
        
        # ç¡®ä¿ sub_order_num æœ‰å€¼
        if sub_order_num <= 0:
            logger.debug(f"[çˆ¶è®¢å•æ£€æŸ¥] çˆ¶è®¢å• {parent_order_id} çš„ sub_order_num={sub_order_num} <= 0ï¼Œæ— éœ€æ£€æŸ¥å®ŒæˆçŠ¶æ€")
            return False
        
        # 3. è·å–çˆ¶è®¢å•çš„å½“å‰å®Œæˆæ¬¡æ•°
        parent_complete_num = get_parent_order_complete_from_redis(parent_order_id)
        
        logger.debug(f"[çˆ¶è®¢å•æ£€æŸ¥] çˆ¶è®¢å• {parent_order_id}: å®Œæˆæ¬¡æ•°={parent_complete_num}, éœ€è¦å®Œæˆæ¬¡æ•°={sub_order_num}")
        
        # 4. æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å®Œæˆæ¡ä»¶ï¼ˆå®Œæˆæ¬¡æ•°å¤§äºç­‰äº sub_order_numï¼‰
        if parent_complete_num >= sub_order_num:
            # 5. æ›´æ–° uni_order è¡¨ä¸­æ‰€æœ‰ parent_order_id = parent_order_id çš„è®°å½•çš„ status = 2
            try:
                db.update("uni_order", {"status": 2}, "parent_order_id = %s", (parent_order_id,))
                db.commit()
                logger.info(f"[çˆ¶è®¢å•æ£€æŸ¥] âœ… çˆ¶è®¢å• {parent_order_id} å·²å®Œæˆï¼ˆå®Œæˆæ¬¡æ•°={parent_complete_num} >= sub_order_num={sub_order_num}ï¼‰ï¼Œå·²æ›´æ–° uni_order è¡¨ä¸­æ‰€æœ‰ parent_order_id={parent_order_id} çš„è®°å½•çŠ¶æ€ä¸º 2")
                
                # 6. åŒæ—¶æ›´æ–° uni_job_order è¡¨ä¸­ order_id = parent_order_id çš„è®°å½•çš„ status = 2 å’Œ complate_time
                try:
                    db.update("uni_job_order", {"status": 2, "complate_time": datetime.now()}, "order_id = %s", (parent_order_id,))
                    db.commit()
                    logger.info(f"[çˆ¶è®¢å•æ£€æŸ¥] âœ… å·²æ›´æ–° uni_job_order è¡¨ä¸­ order_id={parent_order_id} çš„è®°å½•çŠ¶æ€ä¸º 2ï¼Œå¹¶æ›´æ–°å®Œæˆæ—¶é—´")
                except Exception as job_e:
                    logger.warning(f"[çˆ¶è®¢å•æ£€æŸ¥] æ›´æ–° uni_job_order è¡¨å¤±è´¥ï¼ˆå¯èƒ½è¡¨ä¸å­˜åœ¨æˆ–è®°å½•ä¸å­˜åœ¨ï¼‰: {job_e}")
                
                return True
            except Exception as e:
                logger.error(f"[çˆ¶è®¢å•æ£€æŸ¥] æ›´æ–°çˆ¶è®¢å• {parent_order_id} çŠ¶æ€å¤±è´¥: {e}")
                import traceback
                logger.error(traceback.format_exc())
                return False
        
        return False
        
    except Exception as e:
        logger.error(f"[çˆ¶è®¢å•æ£€æŸ¥] æ£€æŸ¥çˆ¶è®¢å•å®ŒæˆçŠ¶æ€å¤±è´¥: order_id={order_id}, error={e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def set_order_num_to_redis(order_id: int, order_num: int) -> bool:
    """
    è®¾ç½®è®¢å•æ€»æ•°åˆ°Redisï¼ˆç¼“å­˜ï¼Œé¿å…é¢‘ç¹æŸ¥åº“ï¼‰
    
    Args:
        order_id: è®¢å•ID
        order_num: è®¢å•æ€»æ•°
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return False
    
    try:
        _redis.hset(REDIS_ORDER_NUM_KEY, str(order_id), order_num)
        logger.debug(f"âœ“ è®¢å• {order_id} æ€»æ•°å·²ç¼“å­˜åˆ°Redis: order_num={order_num}")
        return True
    except Exception as e:
        logger.error(f"[Redis] è®¾ç½®è®¢å•æ€»æ•°å¤±è´¥: order_id={order_id}, error={e}")
        return False


def get_order_num_from_redis(order_id: int) -> Optional[int]:
    """
    ä»Redisè·å–è®¢å•æ€»æ•°
    
    Args:
        order_id: è®¢å•ID
    
    Returns:
        è®¢å•æ€»æ•°ï¼ˆå¦‚æœRedisä¸­æ²¡æœ‰ï¼Œè¿”å›Noneï¼Œè¡¨ç¤ºéœ€è¦ä»æ•°æ®åº“è·å–ï¼‰
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return None
    
    try:
        value = _redis.hget(REDIS_ORDER_NUM_KEY, str(order_id))
        if value is None:
            return None
        return int(value)
    except Exception as e:
        logger.error(f"[Redis] è·å–è®¢å•æ€»æ•°å¤±è´¥: order_id={order_id}, error={e}")
        return None


def load_orders_to_redis(db: MySQLDB) -> int:
    """
    ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰å¾…å¤„ç†è®¢å•åˆ°Redisï¼ˆå¢é‡åŠ è½½ï¼‰
    å¦‚æœRedisä¸­å·²æœ‰è®¢å•æ•°æ®åˆ™ä¿ç•™ï¼Œæ²¡æœ‰æ‰ä»æ•°æ®åº“åŠ è½½
    
    Args:
        db: æ•°æ®åº“å®ä¾‹
    
    Returns:
        åŠ è½½çš„è®¢å•æ•°é‡
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return 0
    
    try:
        # æŸ¥è¯¢æ‰€æœ‰å¾…å¤„ç†è®¢å•ï¼ˆstatus IN (0, 1)ï¼‰
        orders = db.select(
            "uni_order",
            where="status IN (0, 1)",
            order_by="id ASC"
        )
        
        if not orders:
            logger.warning("[è®¢å•åŠ è½½] æ²¡æœ‰æ‰¾åˆ°å¾…å¤„ç†è®¢å•")
            return 0
        
        logger.info(f"[è®¢å•åŠ è½½] ä»æ•°æ®åº“æŸ¥è¯¢åˆ° {len(orders)} ä¸ªå¾…å¤„ç†è®¢å•ï¼Œå¼€å§‹æ£€æŸ¥å¹¶åŠ è½½åˆ°Redis...")
        
        loaded_count = 0
        completed_count = 0
        skipped_count = 0  # Redisä¸­å·²æœ‰çš„è®¢å•
        
        for order in orders:
            order_id = order['id']
            order_num = order.get('order_num', 0) or 0
            complete_num = order.get('complete_num', 0) or 0
            order_status = order.get('status', 0)
            
            # ğŸ” å…³é”®ï¼šæ£€æŸ¥Redisä¸­æ˜¯å¦å·²æœ‰è¯¥è®¢å•
            redis_has_order = _redis.hexists(REDIS_ORDER_INFO_KEY, str(order_id))
            
            if redis_has_order:
                # Redisä¸­å·²æœ‰è¯¥è®¢å•ï¼Œä¿ç•™Redisæ•°æ®ï¼ˆå¯èƒ½åŒ…å«è¿è¡Œä¸­çš„è¿›åº¦ï¼‰
                redis_complete_num = get_order_complete_from_redis(order_id)
                logger.info(f"[è®¢å•åŠ è½½] ğŸ”„ è®¢å• {order_id} å·²åœ¨Redisä¸­ï¼Œä¿ç•™Redisæ•°æ®ï¼ˆcomplete_num={redis_complete_num}ï¼Œæ•°æ®åº“={complete_num}ï¼‰")
                skipped_count += 1
                
                # å¦‚æœè®¢å•æœ‰ parent_order_idï¼Œç¡®ä¿çˆ¶è®¢å•ç›¸å…³æ•°æ®å·²å­˜å…¥ Redis
                parent_order_id = order.get('parent_order_id')
                if parent_order_id:
                    # ç›´æ¥è¯»å–å½“å‰è®¢å•ï¼ˆå­è®¢å•ï¼‰çš„ sub_order_num
                    sub_order_num = order.get('sub_order_num', 0) or 0
                    if sub_order_num > 0:
                        # æ£€æŸ¥ sub_order_num æ˜¯å¦å·²å­˜å…¥ Redisï¼ˆä»¥ parent_order_id ä¸º keyï¼‰
                        if not _redis.hexists(REDIS_PARENT_ORDER_SUB_ORDER_NUM_KEY, str(parent_order_id)):
                            _redis.hset(REDIS_PARENT_ORDER_SUB_ORDER_NUM_KEY, str(parent_order_id), sub_order_num)
                            logger.debug(f"[è®¢å•åŠ è½½] âœ“ è®¢å• {order_id} çš„ sub_order_num={sub_order_num} å·²å­˜å…¥ Redisï¼ˆkey=parent_order_id={parent_order_id}ï¼‰")
                    
                    # ç¡®ä¿çˆ¶è®¢å•å®Œæˆæ¬¡æ•°å·²åˆå§‹åŒ–ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
                    if not _redis.hexists(REDIS_PARENT_ORDER_COMPLETE_KEY, str(parent_order_id)):
                        _redis.hset(REDIS_PARENT_ORDER_COMPLETE_KEY, str(parent_order_id), 0)
                        logger.debug(f"[è®¢å•åŠ è½½] âœ“ åˆå§‹åŒ–çˆ¶è®¢å• {parent_order_id} çš„å®Œæˆæ¬¡æ•°ä¸º 0")
                
                # æ£€æŸ¥Redisä¸­çš„è®¢å•æ˜¯å¦å·²å®Œæˆ
                if order_num > 0 and redis_complete_num >= order_num:
                    logger.info(f"[è®¢å•åŠ è½½] ğŸ‰ è®¢å• {order_id} åœ¨Redisä¸­å·²å®Œæˆï¼ˆ{redis_complete_num}/{order_num}ï¼‰ï¼Œæ›´æ–°æ•°æ®åº“çŠ¶æ€")
                    db.update("uni_order", {"status": 2}, "id = %s", (order_id,))
                    db.commit()
                    completed_count += 1
                    # æ›´æ–°Redisä¸­çš„çŠ¶æ€
                    order['status'] = 2
                    order_info_json = json.dumps(order, ensure_ascii=False, default=str)
                    _redis.hset(REDIS_ORDER_INFO_KEY, str(order_id), order_info_json)
                
                continue
            
            # æ£€æŸ¥æ•°æ®åº“ä¸­è®¢å•æ˜¯å¦å·²ç»å®Œæˆï¼ˆä½†çŠ¶æ€æœªæ›´æ–°ï¼‰
            is_completed = (order_num > 0 and complete_num >= order_num)
            
            if is_completed:
                logger.info(f"[è®¢å•åŠ è½½] ğŸ‰ è®¢å• {order_id} åœ¨æ•°æ®åº“ä¸­å·²å®Œæˆï¼ˆcomplete_num={complete_num} >= order_num={order_num}ï¼‰ï¼Œæ›´æ–°çŠ¶æ€ä¸º2")
                # æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸º2ï¼ˆå·²å®Œæˆï¼‰
                db.update("uni_order", {"status": 2}, "id = %s", (order_id,))
                db.commit()
                
                # æ›´æ–°è®¢å•å¯¹è±¡ä¸­çš„çŠ¶æ€
                order['status'] = 2
                order_status = 2
                completed_count += 1
                
                # å·²å®Œæˆçš„è®¢å•ä¸åŠ è½½åˆ°Redisï¼ˆå› ä¸ºä¸å†éœ€è¦å¤„ç†ï¼‰
                logger.info(f"[è®¢å•åŠ è½½] â­ï¸  è®¢å• {order_id} å·²å®Œæˆï¼Œè·³è¿‡åŠ è½½åˆ°Redis")
                continue
            
            # Redisä¸­æ²¡æœ‰ï¼Œä»æ•°æ®åº“åŠ è½½
            # 1. å­˜å‚¨è®¢å•å®Œæ•´ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼‰
            order_info_json = json.dumps(order, ensure_ascii=False, default=str)
            _redis.hset(REDIS_ORDER_INFO_KEY, str(order_id), order_info_json)
            
            # 2. å­˜å‚¨è®¢å•æ€»æ•°
            _redis.hset(REDIS_ORDER_NUM_KEY, str(order_id), order_num)
            
            # 3. åˆå§‹åŒ–è®¢å•å®Œæˆæ¬¡æ•°ï¼ˆä½¿ç”¨æ•°æ®åº“ä¸­çš„å€¼ï¼‰
            _redis.hset(REDIS_ORDER_COMPLETE_KEY, str(order_id), complete_num)
            
            # 4. å¦‚æœè®¢å•æœ‰ parent_order_idï¼Œå¤„ç†çˆ¶è®¢å•ç›¸å…³æ•°æ®
            parent_order_id = order.get('parent_order_id')
            if parent_order_id:
                # 4.1. ç›´æ¥è¯»å–å½“å‰è®¢å•ï¼ˆå­è®¢å•ï¼‰çš„ sub_order_num
                sub_order_num = order.get('sub_order_num', 0) or 0
                if sub_order_num > 0:
                    # å­˜å‚¨å­è®¢å•çš„ sub_order_num åˆ° Redisï¼ˆä»¥ parent_order_id ä¸º keyï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå­˜åœ¨åˆ™ä¿ç•™ï¼‰
                    if not _redis.hexists(REDIS_PARENT_ORDER_SUB_ORDER_NUM_KEY, str(parent_order_id)):
                        _redis.hset(REDIS_PARENT_ORDER_SUB_ORDER_NUM_KEY, str(parent_order_id), sub_order_num)
                        logger.debug(f"[è®¢å•åŠ è½½] âœ“ è®¢å• {order_id} çš„ sub_order_num={sub_order_num} å·²å­˜å…¥ Redisï¼ˆkey=parent_order_id={parent_order_id}ï¼‰")
                
                # åˆå§‹åŒ–çˆ¶è®¢å•å®Œæˆæ¬¡æ•°ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå­˜åœ¨åˆ™ä¿ç•™ï¼‰
                if not _redis.hexists(REDIS_PARENT_ORDER_COMPLETE_KEY, str(parent_order_id)):
                    _redis.hset(REDIS_PARENT_ORDER_COMPLETE_KEY, str(parent_order_id), 0)
                    logger.debug(f"[è®¢å•åŠ è½½] âœ“ åˆå§‹åŒ–çˆ¶è®¢å• {parent_order_id} çš„å®Œæˆæ¬¡æ•°ä¸º 0")
            
            loaded_count += 1
            logger.debug(f"[è®¢å•åŠ è½½] âœ“ è®¢å• {order_id}: order_num={order_num}, complete_num={complete_num}, status={order_status}ï¼ˆä»æ•°æ®åº“åŠ è½½ï¼‰")
        
        logger.info(f"[è®¢å•åŠ è½½] âœ… åŠ è½½å®Œæˆï¼šæ–°åŠ è½½={loaded_count}, Rediså·²æœ‰={skipped_count}, å·²å®Œæˆ={completed_count}, æ€»è®¡={len(orders)}")
        return loaded_count + skipped_count  # è¿”å›æ€»çš„æœ‰æ•ˆè®¢å•æ•°
        
    except Exception as e:
        logger.error(f"[è®¢å•åŠ è½½] åŠ è½½è®¢å•åˆ°Rediså¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 0


def get_order_info_from_redis(order_id: int) -> Optional[Dict[str, Any]]:
    """
    ä»Redisè·å–è®¢å•å®Œæ•´ä¿¡æ¯
    
    Args:
        order_id: è®¢å•ID
    
    Returns:
        è®¢å•ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return None
    
    try:
        order_info_json = _redis.hget(REDIS_ORDER_INFO_KEY, str(order_id))
        if order_info_json is None:
            return None
        
        order_info = json.loads(order_info_json)
        return order_info
    except Exception as e:
        logger.error(f"[Redis] è·å–è®¢å•ä¿¡æ¯å¤±è´¥: order_id={order_id}, error={e}")
        return None


def get_all_pending_orders_from_redis() -> List[Dict[str, Any]]:
    """
    ä»Redisè·å–æ‰€æœ‰å¾…å¤„ç†è®¢å•
    
    Returns:
        è®¢å•åˆ—è¡¨
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return []
    
    try:
        # è·å–æ‰€æœ‰è®¢å•ä¿¡æ¯
        all_orders_data = _redis.hgetall(REDIS_ORDER_INFO_KEY)
        if not all_orders_data:
            return []
        
        orders = []
        for order_id_str, order_info_json in all_orders_data.items():
            try:
                order_info = json.loads(order_info_json)
                # åªè¿”å›å¾…å¤„ç†è®¢å•ï¼ˆstatus IN (0, 1)ï¼‰
                if order_info.get('status', 0) in (0, 1):
                    orders.append(order_info)
            except Exception as e:
                logger.error(f"[Redis] è§£æè®¢å• {order_id_str} ä¿¡æ¯å¤±è´¥: {e}")
        
        # æŒ‰è®¢å•IDæ’åº
        orders.sort(key=lambda x: x.get('id', 0))
        return orders
        
    except Exception as e:
        logger.error(f"[Redis] è·å–æ‰€æœ‰å¾…å¤„ç†è®¢å•å¤±è´¥: {e}")
        return []


def check_and_update_order_completion(order_id: int, db: MySQLDB) -> Tuple[bool, int, int]:
    """
    æ£€æŸ¥è®¢å•æ˜¯å¦å®Œæˆï¼Œå¦‚æœå®Œæˆåˆ™æ›´æ–°è®¢å•çŠ¶æ€ä¸º2ï¼Œå¹¶åˆ·æ–°Redisåˆ°æ•°æ®åº“
    å®Œå…¨åŸºäº Redis æ•°æ®ï¼Œä¸æŸ¥è¯¢æ•°æ®åº“
    
    Args:
        order_id: è®¢å•ID
        db: æ•°æ®åº“å®ä¾‹
    
    Returns:
        (æ˜¯å¦å®Œæˆ, order_num, complete_num)
    """
    global _order_completed_flag, _order_completed_lock
    
    try:
        # 0. æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å…¶ä»–æ£€æŸ¥å®Œæˆäº†è®¢å•
        with _order_completed_lock:
            if _order_completed_flag:
                logger.debug(f"[è®¢å•å®Œæˆæ£€æŸ¥] è®¢å•å·²è¢«å…¶ä»–æ£€æŸ¥æ ‡è®°ä¸ºå®Œæˆï¼Œè·³è¿‡æœ¬æ¬¡æ£€æŸ¥")
                return False, 0, 0
        
        # 1. ä»Redisè·å–è®¢å•ä¿¡æ¯
        order_info = get_order_info_from_redis(order_id)
        if not order_info:
            logger.warning(f"[è®¢å•å®Œæˆæ£€æŸ¥] è®¢å• {order_id} åœ¨Redisä¸­ä¸å­˜åœ¨ï¼Œå°è¯•ä»æ•°æ®åº“é‡æ–°åŠ è½½...")
            # ä»æ•°æ®åº“é‡æ–°åŠ è½½è®¢å•ä¿¡æ¯åˆ°Redis
            try:
                order_info = db.select_one("uni_order", where="id = %s", where_params=(order_id,))
                if order_info:
                    # ä¿å­˜è®¢å•ä¿¡æ¯åˆ°Redis
                    order_info_json = json.dumps(order_info, ensure_ascii=False, default=str)
                    _redis.hset(REDIS_ORDER_INFO_KEY, str(order_id), order_info_json)
                    
                    # ä¿å­˜order_numåˆ°Redis
                    order_num = order_info.get('order_num', 0) or 0
                    _redis.hset(REDIS_ORDER_NUM_KEY, str(order_id), order_num)
                    
                    # ä¿å­˜complete_numåˆ°Redis
                    complete_num = order_info.get('complete_num', 0) or 0
                    _redis.hset(REDIS_ORDER_COMPLETE_KEY, str(order_id), complete_num)
                    
                    logger.info(f"[è®¢å•å®Œæˆæ£€æŸ¥] âœ… è®¢å• {order_id} ä¿¡æ¯å·²é‡æ–°åŠ è½½åˆ°Redis: order_num={order_num}, complete_num={complete_num}")
                else:
                    logger.error(f"[è®¢å•å®Œæˆæ£€æŸ¥] è®¢å• {order_id} åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨")
                    return False, 0, 0
            except Exception as reload_error:
                logger.error(f"[è®¢å•å®Œæˆæ£€æŸ¥] ä»æ•°æ®åº“é‡æ–°åŠ è½½è®¢å• {order_id} å¤±è´¥: {reload_error}")
                return False, 0, 0
        
        # 2. ä»Redisè·å–è®¢å•æ€»æ•°å’ŒçŠ¶æ€
        order_num = order_info.get('order_num', 0) or 0
        order_status = order_info.get('status', 0)
        
        # 3. ä»Redisè·å–å®Œæˆæ¬¡æ•°
        current_complete_num = get_order_complete_from_redis(order_id)
        
        logger.debug(f"[è®¢å•å®Œæˆæ£€æŸ¥] è®¢å• {order_id}: order_num={order_num}(Redis), "
                    f"complete_num={current_complete_num}(Redis), çŠ¶æ€={order_status}(Redis)")
        
        # 4. åˆ¤æ–­è®¢å•æ˜¯å¦å®Œæˆï¼ˆå®Œå…¨åŸºäº Redis æ•°æ®ï¼‰
        if order_num > 0 and current_complete_num >= order_num and order_status != 2:
            # è®¾ç½®å®Œæˆæ ‡å¿—ï¼Œé˜»æ­¢å…¶ä»–æ£€æŸ¥
            with _order_completed_lock:
                if _order_completed_flag:
                    logger.debug(f"[è®¢å•å®Œæˆæ£€æŸ¥] è®¢å•å·²è¢«å…¶ä»–æ£€æŸ¥æ ‡è®°ä¸ºå®Œæˆï¼Œè·³è¿‡æ›´æ–°")
                    return False, 0, 0
                _order_completed_flag = True
                logger.info(f"[è®¢å•å®Œæˆæ£€æŸ¥] âœ“ è®¾ç½®è®¢å•å®Œæˆæ ‡å¿—ï¼Œå–æ¶ˆå…¶ä»–æ£€æŸ¥")
            logger.info(f"[è®¢å•å®Œæˆæ£€æŸ¥] âœ“ è®¢å• {order_id} å·²å®Œæˆï¼"
                       f"å®Œæˆæ•°={current_complete_num}/{order_num}ï¼ˆæ¥è‡ªRedisï¼‰ï¼Œå¼€å§‹æ›´æ–°çŠ¶æ€...")
            
            # 5. ç«‹å³åˆ·æ–° Redis è®¾å¤‡æ•°æ®åˆ°æ•°æ®åº“
            global _device_table_name
            if _device_table_name:
                logger.info(f"[è®¢å•å®Œæˆæ£€æŸ¥] æ­£åœ¨åˆ·æ–° Redis è®¾å¤‡æ•°æ®åˆ°æ•°æ®åº“...")
                flush_stats = flush_redis_to_mysql(db, _device_table_name)
                logger.info(f"[è®¢å•å®Œæˆæ£€æŸ¥] Redis åˆ·æ–°å®Œæˆ: {flush_stats}")
                
                # åˆ·æ–°åæ¸…ç†æ‰€æœ‰Redisç¼“å­˜ï¼ˆclear_orders=True: åŒ…æ‹¬è®¢å•ç¼“å­˜ï¼‰
                if flush_stats['devices_updated'] > 0:
                    clear_redis_cache(clear_orders=True)
                    logger.info(f"[è®¢å•å®Œæˆæ£€æŸ¥] Redisç¼“å­˜å·²æ¸…ç†")
            else:
                logger.warning(f"[è®¢å•å®Œæˆæ£€æŸ¥] è®¾å¤‡è¡¨åæœªè®¾ç½®ï¼Œè·³è¿‡ Redis åˆ·æ–°")
            
            # 6. æ›´æ–°è®¢å•çŠ¶æ€ä¸º2ï¼ˆå·²å®Œæˆï¼‰ï¼ŒåŒæ—¶æ›´æ–°complete_numï¼ˆä»Redisè¯»å–ï¼‰
            db.update("uni_order", {"status": 2, "complete_num": current_complete_num}, "id = %s", (order_id,))
            db.commit()
            logger.info(f"[è®¢å•å®Œæˆæ£€æŸ¥] âœ“ è®¢å• {order_id} æ•°æ®åº“çŠ¶æ€å·²æ›´æ–°ä¸º 2ï¼ˆå·²å®Œæˆï¼‰ï¼Œcomplete_num={current_complete_num}ï¼ˆæ¥è‡ªRedisï¼‰")
            
            # 7. æ›´æ–°Redisä¸­çš„è®¢å•çŠ¶æ€å’Œcomplete_num
            order_info['status'] = 2
            order_info['complete_num'] = current_complete_num
            order_info_json = json.dumps(order_info, ensure_ascii=False, default=str)
            _redis.hset(REDIS_ORDER_INFO_KEY, str(order_id), order_info_json)
            logger.info(f"[è®¢å•å®Œæˆæ£€æŸ¥] âœ“ è®¢å• {order_id} RedisçŠ¶æ€å·²æ›´æ–°ä¸º 2ï¼ˆå·²å®Œæˆï¼‰ï¼Œcomplete_num={current_complete_num}")
            
            # 8. æ£€æŸ¥å¹¶æ›´æ–°çˆ¶è®¢å•å®ŒæˆçŠ¶æ€
            check_and_update_parent_order_completion(order_id, db)
            
            return True, order_num, current_complete_num
        
        return False, order_num, current_complete_num
        
    except Exception as e:
        logger.error(f"[è®¢å•å®Œæˆæ£€æŸ¥] æ£€æŸ¥è®¢å• {order_id} å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False, 0, 0


def flush_redis_to_mysql(db_instance: MySQLDB, device_table_name: str) -> Dict[str, int]:
    """
    æ‰¹é‡åˆ·æ–°Redisè®¾å¤‡æ•°æ®åˆ°MySQL
    æ³¨æ„ï¼šè®¢å•çš„complete_numåªåœ¨è®¢å•å®Œæˆæ—¶æ›´æ–°ï¼Œä¸åœ¨æ­¤æ‰¹é‡åˆ·æ–°
    
    Args:
        db_instance: æ•°æ®åº“å®ä¾‹
        device_table_name: è®¾å¤‡è¡¨å
    
    Returns:
        åˆ·æ–°ç»Ÿè®¡ä¿¡æ¯: {"devices_updated": 0, "devices_failed": 0}
    """
    global _redis
    stats = {
        "devices_updated": 0,
        "devices_failed": 0
    }
    
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•åˆ·æ–°æ•°æ®")
        return stats
    
    start_time = time.time()
    logger.info(f"[Redisåˆ·æ–°] å¼€å§‹æ‰¹é‡åˆ·æ–°Redisè®¾å¤‡æ•°æ®åˆ°MySQL...")
    
    # 1. åˆ·æ–°è®¾å¤‡æ’­æ”¾æ¬¡æ•°
    try:
        device_play_data = _redis.hgetall(REDIS_DEVICE_PLAY_KEY)
        if device_play_data:
            total_devices = len(device_play_data)
            logger.info(f"[Redisåˆ·æ–°] å‘ç° {total_devices} ä¸ªè®¾å¤‡éœ€è¦æ›´æ–°æ’­æ”¾æ¬¡æ•°")
            
            # è·å–ä¸»é”®å­—æ®µå
            primary_key_field = get_table_primary_key_field(db_instance, device_table_name)
            
            # æ‰¹é‡æ›´æ–°ï¼šä½¿ç”¨CASE WHENè¯­å¥ï¼Œæ¯æ‰¹200ä¸ªï¼ˆå‡å°æ‰¹æ¬¡é¿å…å•æ¬¡SQLè¿‡é•¿ï¼‰
            batch_size = 1000
            device_items = list(device_play_data.items())
            total_batches = (total_devices + batch_size - 1) // batch_size
            
            logger.info(f"[Redisåˆ·æ–°] è®¾å¤‡æ•°æ®å°†åˆ†ä¸º {total_batches} æ‰¹æ¬¡å¤„ç†ï¼Œæ¯æ‰¹ {batch_size} ä¸ª")
            
            for batch_idx in range(0, total_devices, batch_size):
                batch_data = device_items[batch_idx:batch_idx + batch_size]
                current_batch = batch_idx // batch_size + 1
                batch_start_time = time.time()
                
                try:
                    # æ„å»ºCASE WHENè¯­å¥è¿›è¡Œæ‰¹é‡æ›´æ–°
                    case_when_parts = []
                    primary_key_ids = []
                    
                    for primary_key_id_str, increment_str in batch_data:
                        try:
                            primary_key_id = int(primary_key_id_str)
                            increment = int(increment_str)
                            if increment > 0:
                                case_when_parts.append(f"WHEN {primary_key_id} THEN {increment}")
                                primary_key_ids.append(primary_key_id)
                        except (ValueError, TypeError) as e:
                            logger.error(f"[Redisåˆ·æ–°] æ•°æ®æ ¼å¼é”™è¯¯: primary_key_id={primary_key_id_str}, increment={increment_str}, error={e}")
                            stats["devices_failed"] += 1
                    
                    if case_when_parts and primary_key_ids:
                        # æ„å»ºæ‰¹é‡æ›´æ–°SQL
                        case_when_sql = " ".join(case_when_parts)
                        ids_list = ",".join(map(str, primary_key_ids))
                        
                        update_sql = f"""
                        UPDATE {device_table_name}
                        SET play_num = play_num + (CASE {primary_key_field}
                            {case_when_sql}
                            ELSE 0
                        END)
                        WHERE {primary_key_field} IN ({ids_list})
                        """
                        
                        # æ‰§è¡Œæ‰¹é‡æ›´æ–°
                        logger.info(f"[Redisåˆ·æ–°] æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {current_batch}/{total_batches}ï¼ˆè®¾å¤‡æ•°: {len(primary_key_ids)}ï¼‰")
                        db_instance.execute(update_sql)
                        
                        # æ¯æ‰¹ç«‹å³commitï¼Œé¿å…é•¿äº‹åŠ¡é”å®š
                        db_instance.commit()
                        
                        batch_elapsed = time.time() - batch_start_time
                        stats["devices_updated"] += len(primary_key_ids)
                        logger.info(f"[Redisåˆ·æ–°] âœ“ æ‰¹æ¬¡ {current_batch}/{total_batches} å®Œæˆï¼Œè€—æ—¶ {batch_elapsed:.2f}ç§’ï¼ˆå·²å®Œæˆ: {stats['devices_updated']}/{total_devices}ï¼‰")
                        
                        # æ‰¹æ¬¡é—´çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…æ•°æ®åº“å‹åŠ›è¿‡å¤§ï¼ˆ50msï¼‰
                        if current_batch < total_batches:
                            time.sleep(0.05)
                        
                except Exception as e:
                    logger.error(f"[Redisåˆ·æ–°] âœ— æ‰¹é‡æ›´æ–°è®¾å¤‡æ’­æ”¾æ¬¡æ•°å¤±è´¥ï¼ˆæ‰¹æ¬¡{current_batch}/{total_batches}ï¼‰: {e}")
                    stats["devices_failed"] += len(batch_data)
                    import traceback
                    logger.error(traceback.format_exc())
                    
                    # å¤±è´¥æ—¶ä¹Ÿå°è¯•commitï¼Œé¿å…åç»­æ‰¹æ¬¡å—å½±å“
                    try:
                        db_instance.commit()
                    except:
                        pass
            
            logger.info(f"[Redisåˆ·æ–°] è®¾å¤‡æ’­æ”¾æ¬¡æ•°æ›´æ–°å®Œæˆ: æˆåŠŸ={stats['devices_updated']}, å¤±è´¥={stats['devices_failed']}")
    except Exception as e:
        logger.error(f"[Redisåˆ·æ–°] åˆ·æ–°è®¾å¤‡æ’­æ”¾æ¬¡æ•°æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())
    
    # 2. åˆ·æ–°è®¾å¤‡çŠ¶æ€å˜æ›´
    try:
        status_updates = _redis.hgetall(REDIS_DEVICE_STATUS_KEY)
        if status_updates:
            total_status_updates = len(status_updates)
            logger.info(f"[Redisåˆ·æ–°] å‘ç° {total_status_updates} ä¸ªè®¾å¤‡éœ€è¦æ›´æ–°çŠ¶æ€")
            
            # æŒ‰æ‰¹æ¬¡å¤„ç†ï¼ˆæ¯æ‰¹200ä¸ªï¼‰
            batch_size = 1000
            status_items = list(status_updates.items())
            total_batches = (total_status_updates + batch_size - 1) // batch_size
            status_updated_count = 0
            
            for batch_idx in range(0, total_status_updates, batch_size):
                batch_data = status_items[batch_idx:batch_idx + batch_size]
                current_batch = batch_idx // batch_size + 1
                
                try:
                    # è·å–ä¸»é”®å­—æ®µå
                    primary_key_field = get_table_primary_key_field(db_instance, device_table_name)
                    
                    # æ„å»ºCASE WHENæ‰¹é‡æ›´æ–°SQL
                    case_when_parts = []
                    primary_key_ids = []
                    
                    for primary_key_str, target_status_str in batch_data:
                        try:
                            primary_key_id = int(primary_key_str)
                            target_status = int(target_status_str)
                            case_when_parts.append(f"WHEN {primary_key_id} THEN {target_status}")
                            primary_key_ids.append(primary_key_id)
                        except (ValueError, TypeError) as e:
                            logger.error(f"[Redisåˆ·æ–°] è®¾å¤‡çŠ¶æ€æ•°æ®æ ¼å¼é”™è¯¯: primary_key={primary_key_str}, status={target_status_str}, error={e}")
                    
                    if case_when_parts and primary_key_ids:
                        case_when_sql = " ".join(case_when_parts)
                        ids_list = ",".join(map(str, primary_key_ids))
                        
                        update_sql = f"""
                        UPDATE {device_table_name}
                        SET status = (CASE {primary_key_field}
                            {case_when_sql}
                            ELSE status
                        END)
                        WHERE {primary_key_field} IN ({ids_list})
                        """
                        
                        logger.info(f"[Redisåˆ·æ–°] æ­£åœ¨å¤„ç†è®¾å¤‡çŠ¶æ€æ‰¹æ¬¡ {current_batch}/{total_batches}ï¼ˆè®¾å¤‡æ•°: {len(primary_key_ids)}ï¼‰")
                        db_instance.execute(update_sql)
                        db_instance.commit()
                        status_updated_count += len(primary_key_ids)
                        logger.info(f"[Redisåˆ·æ–°] âœ“ è®¾å¤‡çŠ¶æ€æ‰¹æ¬¡ {current_batch}/{total_batches} å®Œæˆï¼ˆå·²å®Œæˆ: {status_updated_count}/{total_status_updates}ï¼‰")
                        
                        # æ‰¹æ¬¡é—´çŸ­æš‚å»¶è¿Ÿ
                        if current_batch < total_batches:
                            time.sleep(0.05)
                    
                except Exception as batch_error:
                    logger.error(f"[Redisåˆ·æ–°] âœ— æ‰¹é‡æ›´æ–°è®¾å¤‡çŠ¶æ€å¤±è´¥ï¼ˆæ‰¹æ¬¡{current_batch}/{total_batches}ï¼‰: {batch_error}")
                    import traceback
                    logger.error(traceback.format_exc())
                    
                    try:
                        db_instance.commit()
                    except:
                        pass
            
            stats['status_updated'] = status_updated_count
            logger.info(f"[Redisåˆ·æ–°] è®¾å¤‡çŠ¶æ€æ›´æ–°å®Œæˆ: æˆåŠŸ={status_updated_count}/{total_status_updates}")
    except Exception as e:
        logger.error(f"[Redisåˆ·æ–°] åˆ·æ–°è®¾å¤‡çŠ¶æ€æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())
        stats['status_updated'] = 0
    
    elapsed = time.time() - start_time
    logger.info(f"[Redisåˆ·æ–°] æ‰¹é‡åˆ·æ–°å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    logger.info(f"[Redisåˆ·æ–°] ç»Ÿè®¡: è®¾å¤‡æ’­æ”¾æ¬¡æ•°æ›´æ–°={stats['devices_updated']}/{stats['devices_updated']+stats['devices_failed']}, "
                f"è®¾å¤‡çŠ¶æ€æ›´æ–°={stats.get('status_updated', 0)}")
    
    return stats


def clear_redis_cache(clear_orders: bool = True) -> bool:
    """
    æ¸…ç†Redisç¼“å­˜ï¼ˆåœ¨åˆ·æ–°åˆ°MySQLåè°ƒç”¨ï¼‰
    
    Args:
        clear_orders: æ˜¯å¦æ¸…ç†è®¢å•ç›¸å…³ç¼“å­˜ï¼ˆé»˜è®¤Trueï¼‰ã€‚
                      ç¨‹åºå¯åŠ¨æ—¶è®¾ä¸ºFalseï¼Œåªæ¸…ç†è®¾å¤‡ç¼“å­˜ï¼›
                      è®¢å•å®Œæˆæ—¶è®¾ä¸ºTrueï¼Œæ¸…ç†æ‰€æœ‰ç¼“å­˜ã€‚
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    global _redis
    if _redis is None:
        logger.error("[Redis] Rediså®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return False
    
    try:
        logger.info(f"[Redisæ¸…ç†] å¼€å§‹æ¸…ç†Redisç¼“å­˜...ï¼ˆæ¸…ç†è®¢å•: {clear_orders}ï¼‰")
        
        # åˆ é™¤è®¾å¤‡æ’­æ”¾æ¬¡æ•°ç¼“å­˜
        if _redis.exists(REDIS_DEVICE_PLAY_KEY):
            _redis.delete(REDIS_DEVICE_PLAY_KEY)
            logger.info(f"[Redisæ¸…ç†] å·²æ¸…ç†è®¾å¤‡æ’­æ”¾æ¬¡æ•°ç¼“å­˜: {REDIS_DEVICE_PLAY_KEY}")
        
        # åˆ é™¤è®¾å¤‡çŠ¶æ€æ›´æ–°é˜Ÿåˆ—
        if _redis.exists(REDIS_DEVICE_STATUS_KEY):
            _redis.delete(REDIS_DEVICE_STATUS_KEY)
            logger.info(f"[Redisæ¸…ç†] å·²æ¸…ç†è®¾å¤‡çŠ¶æ€æ›´æ–°é˜Ÿåˆ—: {REDIS_DEVICE_STATUS_KEY}")
        
        # åªåœ¨è®¢å•å®Œæˆæ—¶æ¸…ç†è®¢å•ç¼“å­˜
        if clear_orders:
            # åˆ é™¤è®¢å•å®Œæˆæ¬¡æ•°ç¼“å­˜
            if _redis.exists(REDIS_ORDER_COMPLETE_KEY):
                _redis.delete(REDIS_ORDER_COMPLETE_KEY)
                logger.info(f"[Redisæ¸…ç†] å·²æ¸…ç†è®¢å•å®Œæˆæ¬¡æ•°ç¼“å­˜: {REDIS_ORDER_COMPLETE_KEY}")
            
            # åˆ é™¤è®¢å•æ€»æ•°ç¼“å­˜
            if _redis.exists(REDIS_ORDER_NUM_KEY):
                _redis.delete(REDIS_ORDER_NUM_KEY)
                logger.info(f"[Redisæ¸…ç†] å·²æ¸…ç†è®¢å•æ€»æ•°ç¼“å­˜: {REDIS_ORDER_NUM_KEY}")
            
            # åˆ é™¤è®¢å•ä¿¡æ¯ç¼“å­˜
            if _redis.exists(REDIS_ORDER_INFO_KEY):
                _redis.delete(REDIS_ORDER_INFO_KEY)
                logger.info(f"[Redisæ¸…ç†] å·²æ¸…ç†è®¢å•ä¿¡æ¯ç¼“å­˜: {REDIS_ORDER_INFO_KEY}")
        else:
            logger.debug("[Redisæ¸…ç†] ä¿ç•™è®¢å•ç¼“å­˜ï¼ˆåªåœ¨è®¢å•å®Œæˆæ—¶æ¸…ç†ï¼‰")
        
        logger.info("[Redisæ¸…ç†] Redisç¼“å­˜æ¸…ç†å®Œæˆ")
        return True
    except Exception as e:
        logger.error(f"[Redisæ¸…ç†] æ¸…ç†Redisç¼“å­˜å¤±è´¥: {e}")
        return False


def parse_video_ids(order_info: str) -> List[str]:
    """
    è§£æè®¢å•ä¿¡æ¯ä¸­çš„è§†é¢‘IDåˆ—è¡¨
    
    Args:
        order_info: è®¢å•ä¿¡æ¯ï¼Œæ ¼å¼å¦‚ "1,2,3"
    
    Returns:
        è§†é¢‘IDåˆ—è¡¨
    """
    if not order_info:
        return []
    return [vid.strip() for vid in order_info.split(',') if vid.strip()]


def get_table_create_time_field(db: MySQLDB, table_name: str) -> str:
    """
    è·å–è¡¨çš„æ—¶é—´å­—æ®µåï¼ˆå¯èƒ½æ˜¯ device_create_time æˆ– devcie_create_timeï¼‰
    
    Args:
        db: æ•°æ®åº“è¿æ¥
        table_name: è¡¨å
    
    Returns:
        å­—æ®µå
    """
    try:
        sql = f"DESCRIBE {table_name}"
        result = db.execute(sql, fetch=True)
        if result:
            columns = [row['Field'] for row in result]
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ device_create_time æˆ– devcie_create_time
            if 'device_create_time' in columns:
                return 'device_create_time'
            elif 'devcie_create_time' in columns:
                return 'devcie_create_time'
            else:
                logger.warning(f"è¡¨ {table_name} ä¸­æœªæ‰¾åˆ° device_create_time æˆ– devcie_create_time å­—æ®µ")
                return 'device_create_time'  # é»˜è®¤è¿”å›
        return 'device_create_time'
    except Exception as e:
        logger.error(f"è·å–è¡¨ {table_name} çš„å­—æ®µä¿¡æ¯å¤±è´¥: {e}")
        return 'device_create_time'  # é»˜è®¤è¿”å›


def get_table_primary_key_field(db: MySQLDB, table_name: str) -> str:
    """
    è·å–è¡¨çš„ä¸»é”®å­—æ®µå
    æ‰€æœ‰è¡¨çš„ä¸»é”®å­—æ®µéƒ½ä¸º 'id'
    
    Args:
        db: æ•°æ®åº“è¿æ¥ï¼ˆä¿ç•™å‚æ•°ä»¥ä¿æŒæ¥å£å…¼å®¹æ€§ï¼‰
        table_name: è¡¨åï¼ˆä¿ç•™å‚æ•°ä»¥ä¿æŒæ¥å£å…¼å®¹æ€§ï¼‰
    
    Returns:
        ä¸»é”®å­—æ®µå 'id'
    """
    # æ‰€æœ‰è¡¨çš„ä¸»é”®å­—æ®µéƒ½ä¸º 'id'ï¼Œç›´æ¥è¿”å›ï¼Œé¿å…æ•°æ®åº“æŸ¥è¯¢
    return 'id'


def reset_device_status(db: MySQLDB, table_name: str = "uni_devices_1"):
    """
    é‡ç½®è®¾å¤‡çŠ¶æ€ï¼šå°†æ‰€æœ‰ status in (1,3) çš„è®¾å¤‡æ›´æ–°ä¸º status = 0
    åŒ…æ‹¬ï¼š
    - status=1: è¿›è¡Œä¸­çš„è®¾å¤‡
    - status=3: å·²å®Œæˆçš„è®¾å¤‡
    
    Args:
        db: æ•°æ®åº“è¿æ¥
        table_name: è¡¨å
    """
    try:
        sql = f"""
            UPDATE {table_name}
            SET status = 0
            WHERE status = 1 OR status = 3
        """
        with db.get_cursor() as cursor:
            cursor.execute(sql)
            affected_rows = cursor.rowcount
        logger.info(f"è¡¨ {table_name} é‡ç½®è®¾å¤‡çŠ¶æ€å®Œæˆï¼ˆstatus 1,3 -> 0ï¼‰ï¼Œå½±å“è¡Œæ•°: {affected_rows}")
        return affected_rows
    except Exception as e:
        logger.error(f"é‡ç½®è¡¨ {table_name} è®¾å¤‡çŠ¶æ€å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 0


def get_devices_from_table(
    db: MySQLDB,
    table_name: str,
    limit: int = 1000,
    status: int = 0
) -> List[Dict[str, Any]]:
    """
    ä»è®¾å¤‡è¡¨ä¸­è·å–è®¾å¤‡æ•°æ®ï¼ˆæŒ‰ play_num å‡åºã€device_create_time é™åºã€ä¸»é”®å‡åºæ’åºï¼‰
    
    Args:
        db: æ•°æ®åº“è¿æ¥
        table_name: è¡¨åï¼ˆå¦‚ uni_devices_1ï¼‰
        limit: è·å–æ•°é‡
        status: è®¾å¤‡çŠ¶æ€ï¼ˆé»˜è®¤0ï¼‰
    
    Returns:
        è®¾å¤‡æ•°æ®åˆ—è¡¨
    """
    try:
        # è·å–æ—¶é—´å­—æ®µåå’Œä¸»é”®å­—æ®µå
        time_field = get_table_create_time_field(db, table_name)
        primary_key_field = get_table_primary_key_field(db, table_name)
        
        # æ„å»ºæŸ¥è¯¢SQLï¼šæŒ‰ play_num å‡åºã€device_create_time é™åºã€ä¸»é”®å‡åºæ’åº
        # æ·»åŠ ä¸»é”®æ’åºç¡®ä¿è·å–ä¸åŒçš„è®¾å¤‡ï¼Œé¿å…æ€»æ˜¯è·å–åŒä¸€ä¸ªè®¾å¤‡
        # ä¼˜åŒ–ï¼šåªæŸ¥è¯¢éœ€è¦çš„å­—æ®µï¼Œè€Œä¸æ˜¯ SELECT *
        # æ³¨æ„ï¼šdevice_id ä¸æ˜¯è¡¨å­—æ®µï¼Œè€Œæ˜¯ä» device_config JSON ä¸­è§£æå‡ºæ¥çš„
        # å¼ºåˆ¶ä½¿ç”¨å¤åˆç´¢å¼•ä»¥é¿å…æ–‡ä»¶æ’åº
        sql = f"""
            SELECT {primary_key_field}, device_config, play_num, status, {time_field}, update_time
            FROM {table_name} USE INDEX (idx_status_playnum_createtime)
            WHERE status = %s
            ORDER BY play_num ASC, {time_field} DESC
            LIMIT %s
        """
        
        result = db.execute(sql, (status, limit), fetch=True)
        return result or []
    except Exception as e:
        logger.error(f"ä»è¡¨ {table_name} è·å–è®¾å¤‡æ•°æ®å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return []


def update_devices_status(db: MySQLDB, device_ids: List[Any], table_name: str, status: int):
    """
    æ‰¹é‡æ›´æ–°è®¾å¤‡çŠ¶æ€
    
    Args:
        db: æ•°æ®åº“è¿æ¥
        device_ids: è®¾å¤‡ä¸»é”®IDåˆ—è¡¨
        table_name: è¡¨å
        status: è¦æ›´æ–°çš„çŠ¶æ€å€¼
    """
    if not device_ids:
        return 0
    
    try:
        primary_key_field = get_table_primary_key_field(db, table_name)
        # ä½¿ç”¨ IN å­å¥æ‰¹é‡æ›´æ–°
        placeholders = ','.join(['%s'] * len(device_ids))
        sql = f"""
            UPDATE {table_name}
            SET status = %s
            WHERE {primary_key_field} IN ({placeholders})
        """
        
        with db.get_cursor() as cursor:
            cursor.execute(sql, (status, *device_ids))
            affected_rows = cursor.rowcount
        logger.debug(f"è¡¨ {table_name} æ‰¹é‡æ›´æ–°è®¾å¤‡çŠ¶æ€å®Œæˆï¼Œå½±å“è¡Œæ•°: {affected_rows}")
        return affected_rows
    except Exception as e:
        logger.error(f"æ‰¹é‡æ›´æ–°è¡¨ {table_name} è®¾å¤‡çŠ¶æ€å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 0


def get_and_lock_devices(db: MySQLDB, table_name: str, limit: int, status: int = 0, max_retries: int = 3) -> List[Dict[str, Any]]:
    """
    åœ¨äº‹åŠ¡ä¸­è·å–è®¾å¤‡å¹¶æ›´æ–°çŠ¶æ€ä¸º1ï¼ˆè¿›è¡Œä¸­ï¼‰
    ä½¿ç”¨äº‹åŠ¡ç¡®ä¿åŸå­æ€§ï¼šå…ˆè·å–è®¾å¤‡ï¼Œç„¶åæ›´æ–°çŠ¶æ€
    æ”¯æŒé‡è¯•æœºåˆ¶ï¼Œåº”å¯¹é”ç­‰å¾…è¶…æ—¶
    ä¸€æ¬¡æ€§è·å–æ‰€æœ‰è®¾å¤‡ï¼Œä¸å†åˆ†æ‰¹å¤„ç†
    
    Args:
        db: æ•°æ®åº“è¿æ¥
        table_name: è¡¨å
        limit: è·å–æ•°é‡
        status: ç­›é€‰çš„è®¾å¤‡çŠ¶æ€ï¼ˆé»˜è®¤0ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
    
    Returns:
        è®¾å¤‡æ•°æ®åˆ—è¡¨ï¼ˆå·²æ›´æ–°çŠ¶æ€ä¸º1ï¼‰
    """
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            start_time = time.time()
            # è·å–æ—¶é—´å­—æ®µåå’Œä¸»é”®å­—æ®µå
            time_field = get_table_create_time_field(db, table_name)
            primary_key_field = get_table_primary_key_field(db, table_name)
            
            # å¼€å§‹äº‹åŠ¡
            conn = db._get_connection()
            # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
            try:
                conn.ping(reconnect=False)
            except Exception as e:
                logger.warning(f"[get_and_lock_devices] æ•°æ®åº“è¿æ¥æ— æ•ˆï¼Œå°è¯•é‡æ–°è¿æ¥: {e}")
                db._close_connection()
                conn = db._get_connection()
            
            original_autocommit = conn.get_autocommit() if hasattr(conn, 'get_autocommit') else (conn.autocommit if isinstance(conn.autocommit, bool) else False)
            conn.autocommit(False)
            
            try:
                with db.get_cursor(conn) as cursor:  # ä¼ é€’è¿æ¥ç»™ get_cursor
                    # æ­¥éª¤1ï¼šä¸€æ¬¡æ€§è·å–æ‰€æœ‰è®¾å¤‡ï¼ˆæŒ‰ play_num å‡åºã€device_create_time é™åºæ’åºï¼‰
                    # ä½¿ç”¨ä¹è§‚é”ç­–ç•¥ï¼šå…ˆ SELECT å† UPDATEï¼Œé€šè¿‡ affected_rows æ£€æŸ¥å¹¶å‘å†²çª
                    # ä¼˜åŒ–ï¼šåªæŸ¥è¯¢éœ€è¦çš„å­—æ®µï¼Œè€Œä¸æ˜¯ SELECT *
                    # å¼ºåˆ¶ä½¿ç”¨å¤åˆç´¢å¼•ä»¥é¿å…æ–‡ä»¶æ’åº
                    select_sql = f"""
                        SELECT {primary_key_field}, device_config, play_num, status, {time_field}, update_time
                        FROM {table_name} USE INDEX (idx_status_playnum_createtime)
                        WHERE status = %s
                        ORDER BY play_num ASC, {time_field} DESC
                        LIMIT %s
                    """
                    select_start = time.time()
                    logger.info(f"[get_and_lock_devices] æ­£åœ¨ä¸€æ¬¡æ€§è·å– {limit} ä¸ªè®¾å¤‡ï¼Œè¡¨: {table_name}")
                    cursor.execute(select_sql, (status, limit))
                    devices = cursor.fetchall()
                    select_elapsed = time.time() - select_start
                    
                    # è®°å½•æŸ¥è¯¢è€—æ—¶
                    if select_elapsed > 10.0:
                        logger.warning(f"[get_and_lock_devices] SELECTæŸ¥è¯¢è€—æ—¶: {select_elapsed:.3f}ç§’, æ•°é‡: {limit}, è¡¨: {table_name}")
                    elif select_elapsed > 5.0:
                        logger.info(f"[get_and_lock_devices] SELECTæŸ¥è¯¢è€—æ—¶: {select_elapsed:.3f}ç§’, æ•°é‡: {limit}")
                    else:
                        logger.info(f"[get_and_lock_devices] SELECTæŸ¥è¯¢è€—æ—¶: {select_elapsed:.3f}ç§’")
                
                    if not devices:
                        conn.rollback()
                        if hasattr(conn, 'close'):
                            conn.close()
                        logger.info(f"[get_and_lock_devices] æ²¡æœ‰å¯ç”¨è®¾å¤‡ (status={status})ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                        return []
                    
                    # æ­¥éª¤2ï¼šè·å–è®¾å¤‡IDåˆ—è¡¨
                    device_ids = [device.get(primary_key_field) for device in devices if device.get(primary_key_field) is not None]
                    
                    if not device_ids:
                        conn.rollback()
                        if hasattr(conn, 'close'):
                            conn.close()
                        logger.warning(f"[get_and_lock_devices] è®¾å¤‡ä¸»é”®å€¼ä¸ºç©ºï¼Œè¿”å›ç©ºåˆ—è¡¨")
                        return []
                    
                    # æ­¥éª¤3ï¼šæ›´æ–°è®¾å¤‡çŠ¶æ€ä¸º1ï¼ˆè¿›è¡Œä¸­ï¼‰
                    # æ·»åŠ  status = 0 æ¡ä»¶ï¼Œé¿å…æ›´æ–°å·²è¢«å…¶ä»–è¿›ç¨‹æ”¹å˜çš„è®¾å¤‡ï¼ˆä¹è§‚é”ï¼‰
                    placeholders = ','.join(['%s'] * len(device_ids))
                    update_sql = f"""
                        UPDATE {table_name}
                        SET status = 1
                        WHERE {primary_key_field} IN ({placeholders})
                        AND status = 0
                    """
                    cursor.execute(update_sql, device_ids)
                    affected_rows = cursor.rowcount
                    
                    if affected_rows != len(device_ids):
                        logger.warning(f"æ›´æ–°è®¾å¤‡çŠ¶æ€æ—¶ï¼Œé¢„æœŸæ›´æ–° {len(device_ids)} ä¸ªï¼Œå®é™…æ›´æ–° {affected_rows} ä¸ªï¼ˆå¯èƒ½å­˜åœ¨å¹¶å‘ç«äº‰ï¼‰")
                        # ä¸å›æ»šï¼Œæäº¤å®é™…æ›´æ–°çš„è®¾å¤‡
                        if affected_rows == 0:
                            # æ‰€æœ‰è®¾å¤‡éƒ½è¢«å…¶ä»–è¿›ç¨‹æŠ¢å äº†ï¼Œå›æ»šå¹¶é‡è¯•
                            conn.rollback()
                            if hasattr(conn, 'close'):
                                conn.close()
                            logger.warning(f"[get_and_lock_devices] æ‰€æœ‰è®¾å¤‡éƒ½è¢«å…¶ä»–è¿›ç¨‹æŠ¢å ï¼Œå°†é‡è¯• (attempt {retry_count + 1}/{max_retries})")
                            retry_count += 1
                            time.sleep(0.1 * retry_count)  # æŒ‡æ•°é€€é¿
                            continue
                    
                    # æäº¤äº‹åŠ¡
                    conn.commit()
                    
                    # å¦‚æœæ›´æ–°çš„è¡Œæ•°å°‘äºé¢„æœŸï¼Œåªè¿”å›æˆåŠŸæ›´æ–°çš„è®¾å¤‡
                    if affected_rows < len(devices):
                        logger.warning(f"åªæœ‰ {affected_rows}/{len(devices)} ä¸ªè®¾å¤‡æˆåŠŸæ›´æ–°ï¼Œè¿”å›å®é™…æˆåŠŸçš„è®¾å¤‡")
                        # ç®€åŒ–å¤„ç†ï¼šè¿”å›å‰ affected_rows ä¸ªè®¾å¤‡
                        devices = devices[:affected_rows]
                    
                    total_elapsed = time.time() - start_time
                    logger.info(f"[get_and_lock_devices] æˆåŠŸè·å–å¹¶é”å®š {len(devices)} ä¸ªè®¾å¤‡ï¼Œæ€»è€—æ—¶ {total_elapsed:.2f}ç§’")
                    
                    return devices
                
            except Exception as e:
                conn.rollback()
                # æ£€æŸ¥æ˜¯å¦æ˜¯é”ç­‰å¾…è¶…æ—¶
                if hasattr(e, 'args') and len(e.args) > 0 and (1205 in str(e.args) or 'Lock wait timeout' in str(e)):
                    logger.warning(f"[get_and_lock_devices] é”ç­‰å¾…è¶…æ—¶ï¼Œå°†é‡è¯• (attempt {retry_count + 1}/{max_retries})")
                    retry_count += 1
                    time.sleep(0.5 * retry_count)  # æŒ‡æ•°é€€é¿
                    continue
                else:
                    raise e
            finally:
                # æ¢å¤åŸæ¥çš„ autocommit è®¾ç½®
                conn.autocommit(original_autocommit)
                # å½’è¿˜è¿æ¥ï¼ˆå¦‚æœæ˜¯ ConnectionWrapperï¼‰
                if hasattr(conn, 'close'):
                    conn.close()
            
        except Exception as e:
            logger.error(f"åœ¨äº‹åŠ¡ä¸­è·å–å¹¶é”å®šè®¾å¤‡å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
    
    # é‡è¯•æ¬¡æ•°ç”¨å°½
    logger.error(f"[get_and_lock_devices] é‡è¯•æ¬¡æ•°ç”¨å°½ ({max_retries} æ¬¡)ï¼Œè¿”å›ç©ºåˆ—è¡¨")
    return []


def parse_device_config(device_config: str) -> Dict[str, Any]:
    """
    è§£æè®¾å¤‡é…ç½® JSON å­—ç¬¦ä¸²
    
    Args:
        device_config: JSON å­—ç¬¦ä¸²
    
    Returns:
        è§£æåçš„è®¾å¤‡é…ç½®å­—å…¸
    """
    try:
        if not device_config:
            return {}
        return json.loads(device_config)
    except Exception as e:
        logger.warning(f"è§£æ device_config å¤±è´¥: {e}")
        return {}


async def play_video_task(
    aweme_id: str,
    device: Dict[str, Any],
    device_id: str,
    device_table: str,
    primary_key_value: Any,
    db: MySQLDB,
    api: TikTokAPI,
    http_client,
    order_id: Optional[int] = None
) -> Tuple[bool, str]:
    """
    æ’­æ”¾è§†é¢‘ä»»åŠ¡ï¼ˆå¼‚æ­¥ï¼‰
    
    Args:
        aweme_id: è§†é¢‘ID
        device: è®¾å¤‡ä¿¡æ¯å­—å…¸ï¼ˆä» device_config å­—æ®µè§£æå¾—åˆ°ï¼ŒåŒ…å« seedã€seed_typeã€token ç­‰å­—æ®µï¼‰
        device_id: è®¾å¤‡IDï¼ˆç”¨äºæ—¥å¿—æ ‡è¯†ï¼‰
        device_table: è®¾å¤‡æ‰€åœ¨çš„è¡¨å
        primary_key_value: ä¸»é”®å€¼ï¼ˆç”¨äºæ•°æ®åº“æ›´æ–°ï¼‰
        db: æ•°æ®åº“è¿æ¥
        api: TikTokAPI å®ä¾‹
        http_client: HttpClient å®ä¾‹
        order_id: è®¢å•IDï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™åœ¨æ’­æ”¾æˆåŠŸåç«‹å³æ›´æ–°è®¢å•çš„ complete_numï¼‰
    
    Returns:
        Tuple[æ˜¯å¦æˆåŠŸ, è®¾å¤‡ID]
    """
    flow_session = None
    session_acquired_time = None
    stage_start_time = time.time()
    
    try:
        # é˜¶æ®µ1ï¼šè·å– flow_session
        logger.debug(f"[é˜¶æ®µ1] å¼€å§‹è·å– session, device_id: {device_id}")
        stage_start = time.time()
        try:
            flow_session = await http_client.get_flow_session_async()
            session_acquired_time = time.time()
            stage_elapsed = session_acquired_time - stage_start
            if stage_elapsed > 5.0:
                logger.warning(f"[é˜¶æ®µ1] è·å–sessionè€—æ—¶è¿‡é•¿: {stage_elapsed:.2f}ç§’, device_id: {device_id}")
            else:
                logger.debug(f"[é˜¶æ®µ1] è·å–sessionæˆåŠŸ, è€—æ—¶: {stage_elapsed:.2f}ç§’")
        except Exception as e:
            logger.error(f"[é˜¶æ®µ1] è·å– flow_session å¤±è´¥ï¼Œdevice_id: {device_id}, é”™è¯¯: {e}")
            return False, device_id
        
        # æ ‡è®°æ˜¯å¦éœ€è¦æ›´æ–°æ•°æ®åº“
        need_update_db = False
        
        try:
            # é˜¶æ®µ2ï¼šè·å– seed
            logger.debug(f"[é˜¶æ®µ2] æ£€æŸ¥ seed, device_id: {device_id}")
            stage_start = time.time()
            seed = device.get('seed')
            seed_type = device.get('seed_type')
            
            # å¦‚æœ device ä¸­æ²¡æœ‰ seed æˆ– seed_typeï¼Œæˆ–è€…ä¸ºç©ºï¼Œåˆ™è¯·æ±‚è·å–
            if not seed or seed_type is None:
                logger.debug(f"[é˜¶æ®µ2] éœ€è¦è·å– seed, device_id: {device_id}")
                try:
                    seed, seed_type = await asyncio.wait_for(
                        api.get_seed_async(device, session=flow_session),
                        timeout=30.0  # 30ç§’è¶…æ—¶
                    )
                    # æ›´æ–° device å­—å…¸
                    device['seed'] = seed
                    device['seed_type'] = seed_type
                    need_update_db = True
                    stage_elapsed = time.time() - stage_start
                    logger.debug(f"[é˜¶æ®µ2] è·å– seed æˆåŠŸ, è€—æ—¶: {stage_elapsed:.2f}ç§’")
                except asyncio.TimeoutError:
                    logger.error(f"[é˜¶æ®µ2] è·å– seed è¶…æ—¶ï¼ˆ30ç§’ï¼‰ï¼Œdevice_id: {device_id}")
                    return False, device_id
            else:
                logger.debug(f"[é˜¶æ®µ2] ä½¿ç”¨ç¼“å­˜çš„ seed")
            
            # é˜¶æ®µ3ï¼šè·å– token
            logger.debug(f"[é˜¶æ®µ3] æ£€æŸ¥ token, device_id: {device_id}")
            stage_start = time.time()
            token = device.get('token')
            
            # å¦‚æœ device ä¸­æ²¡æœ‰ token æˆ–ä¸ºç©ºï¼Œåˆ™è¯·æ±‚è·å–
            if not token:
                logger.debug(f"[é˜¶æ®µ3] éœ€è¦è·å– token, device_id: {device_id}")
                try:
                    token = await asyncio.wait_for(
                        api.get_token_async(device, session=flow_session),
                        timeout=30.0  # 30ç§’è¶…æ—¶
                    )
                    # æ›´æ–° device å­—å…¸
                    device['token'] = token
                    need_update_db = True
                    stage_elapsed = time.time() - stage_start
                    logger.debug(f"[é˜¶æ®µ3] è·å– token æˆåŠŸ, è€—æ—¶: {stage_elapsed:.2f}ç§’")
                except asyncio.TimeoutError:
                    logger.error(f"[é˜¶æ®µ3] è·å– token è¶…æ—¶ï¼ˆ30ç§’ï¼‰ï¼Œdevice_id: {device_id}")
                    return False, device_id
            else:
                logger.debug(f"[é˜¶æ®µ3] ä½¿ç”¨ç¼“å­˜çš„ token")
            
            # é˜¶æ®µ4ï¼šæ›´æ–°æ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if need_update_db:
                logger.debug(f"[é˜¶æ®µ4] å¼€å§‹æ›´æ–°æ•°æ®åº“, device_id: {device_id}")
                stage_start = time.time()
                try:
                    # è·å–è¡¨çš„ä¸»é”®å­—æ®µåï¼ˆæ‰€æœ‰è¡¨éƒ½æ˜¯ 'id'ï¼‰
                    primary_key_field = get_table_primary_key_field(db, device_table)
                    
                    # ä½¿ç”¨ä¼ å…¥çš„ä¸»é”®å€¼ï¼ˆè¿™æ˜¯ä»æ•°æ®åº“è¡Œä¸­è·å–çš„çœŸå®ä¸»é”®å€¼ï¼‰
                    # éªŒè¯ä¸»é”®å€¼ä¸ä¸ºç©º
                    if primary_key_value is None:
                        logger.warning(f"è®¾å¤‡ {device_id} çš„ä¸»é”®å€¼ä¸ºç©ºï¼Œæ— æ³•æ›´æ–° device_configï¼Œprimary_key_field={primary_key_field}")
                    else:
                        # å°†æ›´æ–°åçš„ device å­—å…¸åºåˆ—åŒ–ä¸º JSON
                        try:
                            device_config_json = json.dumps(device, ensure_ascii=False)
                        except Exception as e:
                            logger.error(f"åºåˆ—åŒ– device_config å¤±è´¥: {e}, device_id: {device_id}")
                            # åºåˆ—åŒ–å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
                            device_config_json = "{}"
                        
                        # è·å–å½“å‰æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
                        update_time = int(datetime.now().timestamp())
                        
                        # éªŒè¯ update_time ä¸ä¸º None
                        if update_time is None:
                            logger.error(f"è·å– update_time å¤±è´¥ï¼Œdevice_id: {device_id}")
                            update_time = 0
                        
                        # æ›´æ–°æ•°æ®åº“çš„ device_config å’Œ update_time å­—æ®µï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œä¸é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
                        update_sql = f"""
                            UPDATE {device_table} 
                            SET device_config = %s, update_time = %s
                            WHERE {primary_key_field} = %s
                        """
                        logger.debug(f"æ‰§è¡Œæ›´æ–°SQL: UPDATE {device_table} SET device_config=..., update_time={update_time} WHERE {primary_key_field}={primary_key_value}")
                        
                        # å®šä¹‰æ•°æ®åº“æ›´æ–°å‡½æ•°ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰
                        # æ³¨æ„ï¼šä½¿ç”¨çº¿ç¨‹æœ¬åœ°å­˜å‚¨ï¼Œæ¯ä¸ªçº¿ç¨‹å¤ç”¨åŒä¸€ä¸ªè¿æ¥ï¼Œä¸éœ€è¦åˆ›å»ºæ–°è¿æ¥
                        def update_device_config():
                            try:
                                # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ db å®ä¾‹ï¼Œè¿æ¥ä¼šè‡ªåŠ¨ä½¿ç”¨çº¿ç¨‹æœ¬åœ°å­˜å‚¨
                                with db.get_cursor() as cursor:
                                    cursor.execute(update_sql, (device_config_json, update_time, primary_key_value))
                                    affected_rows = cursor.rowcount
                                    return affected_rows
                            except Exception as db_error:
                                # è®°å½•è¯¦ç»†çš„æ•°æ®åº“é”™è¯¯ä¿¡æ¯
                                error_msg = str(db_error)
                                error_type = type(db_error).__name__
                                logger.error(f"æ•°æ®åº“æ›´æ–°æ“ä½œå¤±è´¥: {error_type}: {error_msg}")
                                logger.error(f"SQL: {update_sql}")
                                logger.error(f"å‚æ•°: device_config_jsoné•¿åº¦={len(device_config_json)}, update_time={update_time}, primary_key_value={primary_key_value} (ç±»å‹: {type(primary_key_value).__name__})")
                                logger.error(f"è¡¨å: {device_table}, ä¸»é”®å­—æ®µ: {primary_key_field}")
                                # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å¤–å±‚å¤„ç†
                                raise
                        
                        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œæ•°æ®åº“æ›´æ–°
                        loop = asyncio.get_running_loop()
                        try:
                            affected_rows = await loop.run_in_executor(None, update_device_config)
                            
                            # å¤„ç† affected_rows å¯èƒ½ä¸º None çš„æƒ…å†µ
                            affected_rows = affected_rows if affected_rows is not None else 0
                            stage_elapsed = time.time() - stage_start
                            if affected_rows > 0:
                                logger.debug(f"[é˜¶æ®µ4] æ›´æ–°æ•°æ®åº“æˆåŠŸ, è€—æ—¶: {stage_elapsed:.2f}ç§’")
                            else:
                                logger.warning(f"[é˜¶æ®µ4] æ›´æ–°æ•°æ®åº“å¤±è´¥, è€—æ—¶: {stage_elapsed:.2f}ç§’, å½±å“è¡Œæ•°: {affected_rows}")
                        except Exception as update_error:
                            # æ›´æ–°å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œåªè®°å½•é”™è¯¯
                            error_msg = str(update_error)
                            error_type = type(update_error).__name__
                            logger.error(f"æ›´æ–°è®¾å¤‡ {device_id} çš„ device_config å¤±è´¥: {error_type}: {error_msg}")
                            logger.error(f"è®¾å¤‡ä¿¡æ¯: device_id={device_id}, device_table={device_table}, primary_key_value={primary_key_value}")
                            import traceback
                            logger.error(traceback.format_exc())
                            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­æ‰§è¡Œæ’­æ”¾æµç¨‹
                except Exception as e:
                    # å¤–å±‚å¼‚å¸¸å¤„ç†ï¼Œç¡®ä¿ä¸å½±å“ä¸»æµç¨‹
                    error_msg = str(e)
                    error_type = type(e).__name__
                    logger.error(f"æ›´æ–°è®¾å¤‡ {device_id} çš„ device_config æ—¶å‘ç”Ÿå¼‚å¸¸: {error_type}: {error_msg}")
                    import traceback
                    logger.error(traceback.format_exc())
                    # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­æ‰§è¡Œæ’­æ”¾æµç¨‹
            
            # é˜¶æ®µ5ï¼šè°ƒç”¨ stats æ¥å£æ’­æ”¾è§†é¢‘
            # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…ç¬æ—¶å¹¶å‘è¿‡é«˜ï¼ˆä½¿ç”¨å…¨å±€é…ç½®ï¼‰
            delay = random.uniform(_request_delay_min, _request_delay_max)
            await asyncio.sleep(delay)
            
            logger.debug(f"[é˜¶æ®µ5] å¼€å§‹ stats è¯·æ±‚, device_id: {device_id}, aweme_id: {aweme_id}, å»¶è¿Ÿ: {delay*1000:.0f}ms")
            stage_start = time.time()
            signcount = random.randint(200, 300)  # éšæœºç­¾åè®¡æ•°
            try:
                result = await asyncio.wait_for(
                    api.stats_async(
                aweme_id=aweme_id,
                seed=seed,
                seed_type=seed_type,
                token=token,
                device=device,
                signcount=signcount,
                session=flow_session
                    ),
                    timeout=_stats_timeout  # ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
                )
                stage_elapsed = time.time() - stage_start
                logger.debug(f"[é˜¶æ®µ5] stats è¯·æ±‚å®Œæˆ, è€—æ—¶: {stage_elapsed:.2f}ç§’, ç»“æœ: {'æˆåŠŸ' if result else 'å¤±è´¥'}")
            except asyncio.TimeoutError:
                stage_elapsed = time.time() - stage_start
                logger.error(f"[é˜¶æ®µ5] stats è¯·æ±‚è¶…æ—¶ï¼ˆ{_stats_timeout}ç§’ï¼‰ï¼Œdevice_id: {device_id}, aweme_id: {aweme_id}, è€—æ—¶: {stage_elapsed:.2f}ç§’")
                logger.error(f"[é˜¶æ®µ5] è¶…æ—¶åˆ†æï¼šå¯èƒ½æ˜¯HTTPè¿æ¥å¡ä½æˆ–ä»£ç†æ— å“åº”")
                result = ""
            
            # å¦‚æœè¿”å›ç»“æœä¸ä¸ºç©ºï¼Œè¡¨ç¤ºæˆåŠŸ
            success = result != "" if result else False
            
            # é˜¶æ®µ6ï¼šæ›´æ–°æ’­æ”¾ç»Ÿè®¡ï¼ˆä½¿ç”¨Redisç¼“å­˜ï¼Œå‡å°‘æ•°æ®åº“å†™å‹åŠ›ï¼‰
            logger.debug(f"[é˜¶æ®µ6] å¼€å§‹æ›´æ–°æ’­æ”¾ç»Ÿè®¡, device_id: {device_id}, primary_key: {primary_key_value}")
            stage_start = time.time()
            try:
                # 1. æ›´æ–°è®¾å¤‡æ’­æ”¾æ¬¡æ•°åˆ°Redisï¼ˆä½¿ç”¨ä¸»é”®IDï¼Œå¼‚æ­¥æ“ä½œï¼Œæå¿«ï¼‰
                increment_device_play_in_redis(primary_key_value, amount=1)
                logger.debug(f"âœ“ è®¾å¤‡ primary_key={primary_key_value} (device_id={device_id}) æ’­æ”¾æ¬¡æ•°å·²è®°å½•åˆ°Redis")
                
                # 2. å¦‚æœæ’­æ”¾æˆåŠŸä¸”æä¾›äº† order_idï¼Œæ›´æ–°è®¢å•å®Œæˆæ¬¡æ•°åˆ°Redis
                if success and order_id is not None:
                    increment_order_complete_in_redis(order_id, amount=1)
                    logger.debug(f"âœ“ è®¢å• {order_id} å®Œæˆæ¬¡æ•°å·²è®°å½•åˆ°Redis")
                    
                    # 2.1. ç«‹å³æ£€æŸ¥è®¢å•æ˜¯å¦å®Œæˆï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡ï¼‰
                    def check_order_completion():
                        try:
                            is_completed, order_num, complete_num = check_and_update_order_completion(order_id, db)
                            if is_completed:
                                logger.info(f"ğŸ‰ è®¢å• {order_id} å·²å®Œæˆï¼å®Œæˆæ•°={complete_num}/{order_num}")
                            return is_completed
                        except Exception as e:
                            logger.error(f"æ£€æŸ¥è®¢å• {order_id} å®ŒæˆçŠ¶æ€å¤±è´¥: {e}")
                            return False
                    
                    loop = asyncio.get_running_loop()
                    try:
                        # ä½¿ç”¨è¶…æ—¶é˜²æ­¢é˜»å¡ï¼Œè®¢å•æ£€æŸ¥æœ€å¤šç­‰å¾…10ç§’
                        is_completed = await asyncio.wait_for(
                            loop.run_in_executor(None, check_order_completion),
                            timeout=10.0
                        )
                        if is_completed:
                            logger.info(f"âœ“ è®¢å• {order_id} å®Œæˆæ£€æŸ¥é€šè¿‡ï¼ŒçŠ¶æ€å·²æ›´æ–°")
                    except asyncio.TimeoutError:
                        logger.warning(f"âš ï¸ è®¢å• {order_id} å®Œæˆæ£€æŸ¥è¶…æ—¶ï¼ˆ10ç§’ï¼‰ï¼Œå°†åœ¨ä¸‹æ¬¡æ£€æŸ¥")
                    except Exception as e:
                        logger.error(f"è®¢å• {order_id} å®Œæˆæ£€æŸ¥å¼‚å¸¸: {e}")
                
                # 3. æ›´æ–°è®¾å¤‡çŠ¶æ€ä¸º 0ï¼ˆå·²å®Œæˆï¼Œæ¢å¤å¯ç”¨ï¼‰- è¿™ä¸ªéœ€è¦ç«‹å³ç”Ÿæ•ˆï¼Œä»ç„¶å†™å…¥æ•°æ®åº“
                # è®¾ç½®ä¸º0è€Œä¸æ˜¯3ï¼Œè®©è®¾å¤‡å¯ä»¥é‡å¤ä½¿ç”¨
                def update_device_status():
                    primary_key_field = get_table_primary_key_field(db, device_table)
                    update_status_sql = f"""
                        UPDATE {device_table} 
                        SET status = 0
                        WHERE {primary_key_field} = %s
                    """
                    with db.get_cursor() as cursor:
                        cursor.execute(update_status_sql, (primary_key_value,))
                    logger.debug(f"è®¾å¤‡ {device_id} çŠ¶æ€å·²æ›´æ–°ä¸º 0ï¼ˆå·²å®Œæˆï¼Œæ¢å¤å¯ç”¨çŠ¶æ€ï¼Œå¯é‡å¤ä½¿ç”¨ï¼‰")
                
                # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œè®¾å¤‡çŠ¶æ€æ›´æ–°ï¼ˆä¸é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
                loop = asyncio.get_running_loop()
                await loop.run_in_executor(None, update_device_status)
                
                stage_elapsed = time.time() - stage_start
                logger.debug(f"[é˜¶æ®µ6] æ›´æ–°æ’­æ”¾ç»Ÿè®¡å®Œæˆï¼ˆRedisç¼“å­˜æ¨¡å¼ï¼‰, è€—æ—¶: {stage_elapsed:.2f}ç§’")
            except Exception as e:
                stage_elapsed = time.time() - stage_start
                logger.error(f"[é˜¶æ®µ6] æ›´æ–°ç»Ÿè®¡å¤±è´¥: {e}, è€—æ—¶: {stage_elapsed:.2f}ç§’")
                import traceback
                logger.error(traceback.format_exc())
            
            # ä»»åŠ¡å®Œæˆï¼Œè®¡ç®—æ€»è€—æ—¶
            total_elapsed = time.time() - stage_start_time
            logger.debug(f"[ä»»åŠ¡æ€»è€—æ—¶] {total_elapsed:.2f}ç§’, device_id: {device_id}, ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
            
            return success, device_id
            
        finally:
            # é˜¶æ®µ7ï¼šç¡®ä¿è®¾å¤‡çŠ¶æ€è¢«é‡ç½®ï¼ˆæ— è®ºæˆåŠŸæˆ–å¤±è´¥ï¼‰
            # ä½¿ç”¨Redisæ‰¹é‡æ›´æ–°æ¨¡å¼ï¼Œé¿å…å¤§é‡æ•°æ®åº“å†™å…¥å’Œçº¿ç¨‹æ± é˜»å¡
            try:
                logger.debug(f"[é˜¶æ®µ7-Finally] é‡ç½®è®¾å¤‡çŠ¶æ€, device_id: {device_id}, primary_key: {primary_key_value}")
                
                # å°†è®¾å¤‡çŠ¶æ€é‡ç½®è®°å½•åˆ°Redisï¼ˆç›®æ ‡çŠ¶æ€=0ï¼Œå¯ç”¨ï¼‰
                # ç›‘æ§çº¿ç¨‹ä¼šå®šæœŸæ‰¹é‡å¤„ç†è¿™äº›çŠ¶æ€å˜æ›´
                if primary_key_value is not None:
                    set_device_status_in_redis(primary_key_value, target_status=0)
                    logger.debug(f"âœ“ [Finally-Redis] è®¾å¤‡ {device_id} çŠ¶æ€é‡ç½®è¯·æ±‚å·²æäº¤åˆ°Redisé˜Ÿåˆ—")
                else:
                    logger.warning(f"[Finally] è®¾å¤‡ {device_id} ä¸»é”®å€¼ä¸ºNoneï¼Œæ— æ³•è®°å½•çŠ¶æ€å˜æ›´")
                        
            except Exception as e:
                logger.error(f"[Finally] é‡ç½®è®¾å¤‡çŠ¶æ€å¤±è´¥: {e}, device_id: {device_id}")
                import traceback
                logger.error(traceback.format_exc())
            
            # è®¡ç®—ä»»åŠ¡æŒæœ‰æ—¶é—´ï¼Œå¦‚æœè¿‡é•¿åˆ™è­¦å‘Š
            # æ³¨æ„ï¼šæ–°è®¾è®¡ä¸­ session ç”± http_client è‡ªåŠ¨ç®¡ç†ï¼Œæ— éœ€æ‰‹åŠ¨é‡Šæ”¾
            if session_acquired_time:
                session_hold_time = time.time() - session_acquired_time
                if session_hold_time > 60:
                    logger.warning(f"[æ€§èƒ½è­¦å‘Š] ä»»åŠ¡æ‰§è¡Œæ—¶é—´è¿‡é•¿: {session_hold_time:.1f}ç§’, device_id: {device_id}, aweme_id: {aweme_id}")
                    logger.warning(f"[æ€§èƒ½è­¦å‘Š] å»ºè®®æ£€æŸ¥æ—¥å¿—ä¸­çš„å„é˜¶æ®µè€—æ—¶ï¼Œå®šä½æ€§èƒ½ç“¶é¢ˆ")
            
    except Exception as e:
        logger.error(f"æ’­æ”¾è§†é¢‘ä»»åŠ¡å¤±è´¥: {e}, aweme_id: {aweme_id}, device_id: {device_id}")
        import traceback
        logger.error(traceback.format_exc())
        return False, device_id


async def process_order_videos(
    order_id: int,
    video_ids: List[str],
    order_num: int,
    db: MySQLDB,
    api: TikTokAPI,
    http_client,
    max_concurrent: int = 1000
) -> int:
    """
    å¤„ç†è®¢å•çš„è§†é¢‘æ’­æ”¾ä»»åŠ¡
    
    Args:
        order_id: è®¢å•ID
        video_ids: è§†é¢‘IDåˆ—è¡¨
        order_num: éœ€è¦å¤„ç†çš„æ¬¡æ•°
        db: æ•°æ®åº“è¿æ¥
        api: TikTokAPI å®ä¾‹
        http_client: HttpClient å®ä¾‹
        max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤1000ï¼‰
    
    Returns:
        æˆåŠŸå¤„ç†çš„æ¬¡æ•°
    """
    if not video_ids:
        logger.warning(f"è®¢å• {order_id} æ²¡æœ‰è§†é¢‘ID")
        return 0
    
    # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(max_concurrent)
    
    # è·å–å½“å‰å®Œæˆæ•°
    order_info = db.select_one("uni_order", where="id = %s", where_params=(order_id,))
    if not order_info:
        logger.error(f"è®¢å• {order_id} ä¸å­˜åœ¨")
        return 0
    current_complete = order_info.get('complete_num', 0) or 0
    current_play_num = order_info.get('play_num', 0) or 0
    
    # å¦‚æœ order_num > 0ï¼Œæ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
    if order_num > 0 and current_complete >= order_num:
        logger.info(f"è®¢å• {order_id} å·²å®Œæˆï¼Œcurrent_complete={current_complete}, order_num={order_num}")
        return 0
    
    # è¿˜éœ€è¦å¤„ç†çš„æ¬¡æ•°
    # å¦‚æœ order_num = 0ï¼Œè¡¨ç¤ºæ— é™åˆ¶å¤„ç†ï¼Œremaining è®¾ä¸ºä¸€ä¸ªå¾ˆå¤§çš„æ•°
    if order_num == 0:
        remaining = 999999999  # æ— é™åˆ¶å¤„ç†
        logger.info(f"è®¢å• {order_id} order_num=0ï¼Œå°†æ— é™åˆ¶å¤„ç†ï¼Œå½“å‰å®Œæˆ: {current_complete}")
    else:
        remaining = order_num - current_complete
        logger.info(f"è®¢å• {order_id} è¿˜éœ€è¦å¤„ç† {remaining} æ¬¡ï¼Œå½“å‰å®Œæˆ: {current_complete}/{order_num}")
    
    # è®¾å¤‡è¡¨åˆ—è¡¨
    device_tables = [f"uni_devices_{i}" for i in range(1, 11)]
    
    # æˆåŠŸè®¡æ•°
    success_count = 0
    processed_count = 0
    
    # ä»è®¾å¤‡è¡¨ä¸­è·å–æ•°æ®å¹¶å¤„ç†
    for table_name in device_tables:
        if processed_count >= remaining:
            break
        
        page = 1
        while processed_count < remaining:
            # ä»è¡¨ä¸­è·å–è®¾å¤‡æ•°æ®ï¼ˆä½¿ç”¨é…ç½®çš„ page_sizeï¼‰
            devices = get_devices_from_table(db, table_name, limit=_page_size, status=0)
            
            if not devices:
                logger.info(f"è¡¨ {table_name} ç¬¬ {page} é¡µæ²¡æœ‰æ•°æ®ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€å¼ è¡¨")
                break
            
            logger.info(f"ä»è¡¨ {table_name} ç¬¬ {page} é¡µè·å–åˆ° {len(devices)} ä¸ªè®¾å¤‡ï¼Œå‡†å¤‡å¤„ç†")
            
            # è®¡ç®—è¿˜éœ€è¦å¤„ç†çš„æ¬¡æ•°
            need_process = min(remaining - processed_count, len(devices))
            devices_to_process = devices[:need_process]
            
            # åˆ›å»ºå¸¦ä¿¡å·é‡æ§åˆ¶çš„å¹¶å‘ä»»åŠ¡
            async def play_with_semaphore(device_dict, aweme_id, device_id, device_table_name, primary_key_val):
                """å¸¦ä¿¡å·é‡æ§åˆ¶çš„æ’­æ”¾ä»»åŠ¡"""
                async with semaphore:
                    return await play_video_task(
                        aweme_id=aweme_id,
                        device=device_dict,
                        device_id=device_id,
                        device_table=device_table_name,
                        primary_key_value=primary_key_val,
                        db=db,
                        api=api,
                        http_client=http_client,
                        order_id=order_id
                    )
            
            tasks = []
            device_id_list = []  # ä¿å­˜è®¾å¤‡IDåˆ—è¡¨ï¼Œç”¨äºåç»­å¤„ç†å¤±è´¥è®¡æ•°
            device_table_map = {}  # ä¿å­˜è®¾å¤‡IDåˆ°è¡¨åçš„æ˜ å°„
            device_id_to_primary_key = {}  # ä¿å­˜è®¾å¤‡IDåˆ°ä¸»é”®å€¼çš„æ˜ å°„
            # å…ˆè·å–ä¸»é”®å­—æ®µåï¼ˆåªéœ€è¦è·å–ä¸€æ¬¡ï¼‰
            primary_key_field = get_table_primary_key_field(db, table_name)
            logger.debug(f"è¡¨ {table_name} çš„ä¸»é”®å­—æ®µ: {primary_key_field}")
            
            for device_row in devices_to_process:
                # ä»æ•°æ®åº“è¡Œä¸­è·å– device_config å­—æ®µï¼ˆJSONå­—ç¬¦ä¸²ï¼‰
                device_config_str = device_row.get('device_config', '')
                
                # è·å–ä¸»é”®å€¼ï¼ˆä¸»é”®å­—æ®µçš„å€¼ï¼Œé€šå¸¸æ˜¯ idï¼‰
                primary_key_value = device_row.get(primary_key_field)
                
                # éªŒè¯ä¸»é”®å€¼ä¸ä¸ºç©º
                if primary_key_value is None:
                    logger.warning(f"è®¾å¤‡è¡Œä¸­ä¸»é”®å­—æ®µ {primary_key_field} çš„å€¼ä¸º Noneï¼Œè·³è¿‡")
                    continue
                
                # ç¡®ä¿ä¸»é”®å€¼çš„ç±»å‹æ­£ç¡®ï¼ˆå¦‚æœæ˜¯æ•°å­—å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºæ•´æ•°ï¼‰
                # ä¸»é”®é€šå¸¸æ˜¯æ•´æ•°ç±»å‹
                try:
                    if isinstance(primary_key_value, str) and primary_key_value.isdigit():
                        primary_key_value = int(primary_key_value)
                    elif isinstance(primary_key_value, (int, float)):
                        primary_key_value = int(primary_key_value)
                except (ValueError, TypeError) as e:
                    logger.warning(f"è½¬æ¢ä¸»é”®å€¼ç±»å‹å¤±è´¥: {e}, primary_key_value={primary_key_value}, ç±»å‹={type(primary_key_value).__name__}")
                    # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå€¼
                
                # è§£æ device_config ä½œä¸º device å­—å…¸
                if device_config_str:
                    device_dict = parse_device_config(device_config_str)
                else:
                    # å¦‚æœ device_config ä¸ºç©ºï¼Œä½¿ç”¨ç©ºå­—å…¸
                    device_dict = {}
                    logger.warning(f"è®¾å¤‡ä¸»é”® {primary_key_value} çš„ device_config ä¸ºç©º")
                
                # ä»è§£æåçš„ device_config ä¸­è·å– device_id
                device_id = device_dict.get('device_id', '')
                if not device_id:
                    # å¦‚æœæ²¡æœ‰device_idï¼Œä½¿ç”¨ä¸»é”®å€¼ä½œä¸ºæ ‡è¯†
                    device_id = str(primary_key_value)
                
                # ä¿å­˜è®¾å¤‡IDåˆ°è¡¨åçš„æ˜ å°„
                device_table_map[device_id] = table_name
                # ä¿å­˜è®¾å¤‡IDåˆ°ä¸»é”®å€¼çš„æ˜ å°„ï¼ˆä½¿ç”¨ä¸»é”®å­—æ®µçš„å€¼ï¼Œä¸æ˜¯ device_idï¼‰
                device_id_to_primary_key[device_id] = primary_key_value
                
                logger.debug(f"è®¾å¤‡æ˜ å°„: device_id={device_id}, primary_key={primary_key_field}={primary_key_value}, table={table_name}")
                
                # éšæœºé€‰æ‹©ä¸€ä¸ªè§†é¢‘ID
                aweme_id = random.choice(video_ids)
                
                device_id_list.append(device_id)
                task = play_with_semaphore(device_dict, aweme_id, device_id, table_name, primary_key_value)
                tasks.append(task)
            
            # å¹¶å‘æ‰§è¡Œä»»åŠ¡ï¼ˆç”±ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°ï¼‰
            logger.info(f"å¼€å§‹å¹¶å‘å¤„ç† {len(tasks)} ä¸ªä»»åŠ¡ï¼ˆè®¢å• {order_id}ï¼Œæœ€å¤§å¹¶å‘ {max_concurrent}ï¼‰")
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†ç»“æœå¹¶ç»Ÿè®¡æˆåŠŸæ•°ï¼ŒåŒæ—¶è·Ÿè¸ªè®¾å¤‡å¤±è´¥æ¬¡æ•°ï¼Œå¹¶æ›´æ–°è®¾å¤‡çš„ play_num
            batch_success = 0
            for idx, result in enumerate(results):
                device_id = device_id_list[idx]
                
                # å¤„ç†å¼‚å¸¸æƒ…å†µ
                if isinstance(result, Exception):
                    logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {result}, device_id: {device_id}")
                    success = False
                else:
                    success, _ = result if isinstance(result, tuple) else (result, device_id)
                
                # play_num çš„æ›´æ–°å·²åœ¨ play_video_task ä¸­å®Œæˆï¼Œè¿™é‡Œä¸å†æ›´æ–°
                
                if success:
                    batch_success += 1
                    # æˆåŠŸæ—¶é‡ç½®å¤±è´¥è®¡æ•°
                    with _device_fail_lock:
                        if device_id in _device_fail_count:
                            _device_fail_count[device_id] = 0
                else:
                    # å¤±è´¥æ—¶å¢åŠ å¤±è´¥è®¡æ•°
                    with _device_fail_lock:
                        current_fail_count = _device_fail_count.get(device_id, 0) + 1
                        _device_fail_count[device_id] = current_fail_count
                        
                        # å¦‚æœè¿ç»­å¤±è´¥è¶…è¿‡é˜ˆå€¼ï¼Œæ ‡è®°è®¾å¤‡ä¸ºå¼‚å¸¸çŠ¶æ€
                        if current_fail_count >= _device_fail_threshold:
                            logger.warning(f"è®¾å¤‡ {device_id} è¿ç»­å¤±è´¥ {current_fail_count} æ¬¡ï¼ˆé˜ˆå€¼: {_device_fail_threshold}ï¼‰ï¼Œæ ‡è®°ä¸ºå¼‚å¸¸çŠ¶æ€")
                            # æ›´æ–°è®¾å¤‡çŠ¶æ€ä¸º 4ï¼ˆè¿ç»­å¤±è´¥å¼‚å¸¸çŠ¶æ€ï¼‰
                            try:
                                # ä»æ˜ å°„ä¸­è·å–è®¾å¤‡æ‰€åœ¨çš„è¡¨åå’Œä¸»é”®å€¼
                                device_table = device_table_map.get(device_id)
                                primary_key_value = device_id_to_primary_key.get(device_id)
                                if device_table and primary_key_value:
                                    # è·å–è¡¨çš„ä¸»é”®å­—æ®µå
                                    primary_key_field = get_table_primary_key_field(db, device_table)
                                    logger.info(f"æ­£åœ¨æ›´æ–°è¡¨ {device_table}ï¼Œä½¿ç”¨ä¸»é”®å­—æ®µ: {primary_key_field}={primary_key_value}ï¼Œè®¾å¤‡ID: {device_id}")
                                    
                                    # æ›´æ–°è®¾å¤‡çŠ¶æ€
                                    # æ³¨æ„ï¼šdb.execute() è¿”å› Noneï¼Œéœ€è¦ä½¿ç”¨æ¸¸æ ‡è·å– rowcount
                                    update_status_sql = f"""
                                        UPDATE {device_table} 
                                        SET status = 4
                                        WHERE {primary_key_field} = %s
                                    """
                                    # ä½¿ç”¨æ¸¸æ ‡ç›´æ¥æ‰§è¡Œä»¥è·å–å½±å“çš„è¡Œæ•°
                                    with db.get_cursor() as cursor:
                                        cursor.execute(update_status_sql, (primary_key_value,))
                                        affected_rows = cursor.rowcount
                                    # å¤„ç† affected_rows å¯èƒ½ä¸º None çš„æƒ…å†µ
                                    affected_rows = affected_rows if affected_rows is not None else 0
                                    if affected_rows > 0:
                                        logger.info(f"âœ“ è®¾å¤‡ {device_id} åœ¨è¡¨ {device_table} ä¸­å·²æ ‡è®°ä¸ºè¿ç»­å¤±è´¥å¼‚å¸¸çŠ¶æ€ (status=4)ï¼Œå½±å“è¡Œæ•°: {affected_rows}")
                                    else:
                                        logger.warning(f"âœ— è®¾å¤‡ {device_id} åœ¨è¡¨ {device_table} ä¸­çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œå½±å“è¡Œæ•°: {affected_rows}ï¼Œä¸»é”®å€¼: {primary_key_value}")
                                elif not device_table:
                                    logger.warning(f"è®¾å¤‡ {device_id} ä¸åœ¨æ˜ å°„ä¸­ï¼Œæ— æ³•æ›´æ–°çŠ¶æ€")
                                elif not primary_key_value:
                                    logger.warning(f"è®¾å¤‡ {device_id} çš„ä¸»é”®å€¼æœªæ‰¾åˆ°ï¼Œæ— æ³•æ›´æ–°çŠ¶æ€")
                                else:
                                    # å¦‚æœæ˜ å°„ä¸­æ²¡æœ‰ï¼Œå°è¯•åœ¨æ‰€æœ‰è®¾å¤‡è¡¨ä¸­æŸ¥æ‰¾å¹¶æ›´æ–°
                                    logger.info(f"è®¾å¤‡ {device_id} ä¸åœ¨æ˜ å°„ä¸­ï¼Œå°è¯•åœ¨æ‰€æœ‰è®¾å¤‡è¡¨ä¸­æŸ¥æ‰¾å¹¶æ›´æ–°çŠ¶æ€")
                                    for table_idx in range(1, 11):
                                        table_name = f"uni_devices_{table_idx}"
                                        try:
                                            # è·å–è¡¨çš„ä¸»é”®å­—æ®µå
                                            primary_key_field = get_table_primary_key_field(db, table_name)
                                            logger.debug(f"æ£€æŸ¥è¡¨ {table_name}ï¼Œä½¿ç”¨ä¸»é”®å­—æ®µ: {primary_key_field}")
                                            
                                            # ç›´æ¥å°è¯•æ›´æ–°è®¾å¤‡çŠ¶æ€
                                            # æ³¨æ„ï¼šdb.execute() è¿”å› Noneï¼Œéœ€è¦ä½¿ç”¨æ¸¸æ ‡è·å– rowcount
                                            update_status_sql = f"""
                                                UPDATE {table_name} 
                                                SET status = 4
                                                WHERE {primary_key_field} = %s
                                            """
                                            # ä½¿ç”¨æ¸¸æ ‡ç›´æ¥æ‰§è¡Œä»¥è·å–å½±å“çš„è¡Œæ•°
                                            with db.get_cursor() as cursor:
                                                cursor.execute(update_status_sql, (device_id,))
                                                affected_rows = cursor.rowcount
                                            # å¤„ç† affected_rows å¯èƒ½ä¸º None çš„æƒ…å†µ
                                            affected_rows = affected_rows if affected_rows is not None else 0
                                            if affected_rows > 0:
                                                logger.info(f"âœ“ è®¾å¤‡ {device_id} åœ¨è¡¨ {table_name} ä¸­å·²æ ‡è®°ä¸ºè¿ç»­å¤±è´¥å¼‚å¸¸çŠ¶æ€ (status=4)ï¼Œå½±å“è¡Œæ•°: {affected_rows}")
                                                break
                                            else:
                                                logger.debug(f"è®¾å¤‡ {device_id} åœ¨è¡¨ {table_name} ä¸­æœªæ‰¾åˆ°ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªè¡¨")
                                        except Exception as e:
                                            # è¡¨ä¸å­˜åœ¨æˆ–æŸ¥è¯¢å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªè¡¨
                                            logger.debug(f"æ£€æŸ¥è¡¨ {table_name} æ—¶å‡ºé”™: {e}")
                                            continue
                                    else:
                                        logger.error(f"è®¾å¤‡ {device_id} æœªåœ¨ä»»ä½•è®¾å¤‡è¡¨ä¸­æ‰¾åˆ°")
                            except Exception as e:
                                logger.error(f"æ›´æ–°è®¾å¤‡ {device_id} çŠ¶æ€å¤±è´¥: {e}")
                                import traceback
                                logger.error(traceback.format_exc())
            
            success_count += batch_success
            processed_count += len(tasks)
            
            # complete_num çš„æ›´æ–°å·²åœ¨ play_video_task ä¸­å®Œæˆï¼Œè¿™é‡Œåªæ£€æŸ¥è®¢å•æ˜¯å¦å®Œæˆ
            # æ³¨æ„ï¼šplay_num å’Œ complete_num éƒ½å·²ç»åœ¨ play_video_task ä¸­ç«‹å³æ›´æ–°äº†
            with order_lock:
                # é‡æ–°æŸ¥è¯¢è®¢å•ä¿¡æ¯ï¼ˆæ£€æŸ¥æ˜¯å¦å·²å®Œæˆï¼‰
                    order_info = db.select_one("uni_order", where="id = %s", where_params=(order_id,))
                    if order_info:
                        new_complete = order_info.get('complete_num', 0) or 0
                    logger.debug(f"è®¢å• {order_id} å½“å‰ complete_num={new_complete}")
                    
                    # å¦‚æœå·²å®Œæˆï¼Œé€€å‡ºï¼ˆorder_num=0 æ—¶ä¸ä¼šé€€å‡ºï¼‰
                    if order_num > 0 and new_complete >= order_num:
                        logger.info(f"è®¢å• {order_id} å·²å®Œæˆï¼complete_num={new_complete}, order_num={order_num}")
                        # æ›´æ–°çŠ¶æ€ä¸º2
                        db.update("uni_order", {"status": 2}, "id = %s", (order_id,))
                        db.commit()
                        return success_count
            
            logger.info(f"è®¢å• {order_id} æ‰¹æ¬¡å®Œæˆ: æˆåŠŸ {batch_success}/{len(tasks)}, ç´¯è®¡æˆåŠŸ {success_count}/{processed_count}")
            
            # å¦‚æœè¿˜éœ€è¦å¤„ç†ï¼Œç»§ç»­ä¸‹ä¸€é¡µ
            if processed_count < remaining and len(devices) == _page_size:
                page += 1
            else:
                break
    
    return success_count


# å…¨å±€å˜é‡ï¼ˆç”¨äºæ¶ˆæ¯é˜Ÿåˆ—ï¼‰
_queue_instance: Optional[MessageQueue] = None
_db_instance: Optional[MySQLDB] = None
_api_instance: Optional[TikTokAPI] = None
_http_client_instance = None
_device_table_name: str = "uni_devices_1"
_max_concurrent: int = 1000
_threshold_size: int = 3000  # é˜Ÿåˆ—é˜ˆå€¼å¤§å°ï¼ˆå¯é…ç½®ï¼‰

# å½“å‰æ­£åœ¨å¤„ç†çš„è®¢å•ï¼ˆå…¨å±€å˜é‡ï¼‰
_current_order: Optional[Dict[str, Any]] = None
_current_order_lock = threading.Lock()

# é˜ˆå€¼å›è°ƒé˜Ÿåˆ—å’Œæ§åˆ¶å˜é‡
_threshold_callback_queue = None  # é˜ˆå€¼å›è°ƒä»»åŠ¡é˜Ÿåˆ—
_threshold_callback_processor_thread = None  # é˜ˆå€¼å›è°ƒå¤„ç†å™¨çº¿ç¨‹
_threshold_callback_stop_event = None  # åœæ­¢äº‹ä»¶
_threshold_callback_queue_lock = threading.Lock()  # é˜Ÿåˆ—é”
_threshold_callback_processing = False  # æ˜¯å¦æ­£åœ¨å¤„ç†å›è°ƒé˜Ÿåˆ—
_threshold_callback_stopped = False  # æ˜¯å¦å·²åœæ­¢å¤„ç†ï¼ˆå½“æŸä¸ªå›è°ƒè¿”å›ç©ºåˆ—è¡¨æ—¶è®¾ç½®ä¸ºTrueï¼‰


def _threshold_callback_processor():
    """
    é˜ˆå€¼å›è°ƒå¤„ç†å™¨ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼‰
    æŒ‰é¡ºåºå¤„ç†é˜Ÿåˆ—ä¸­çš„å›è°ƒä»»åŠ¡ï¼Œæ¯æ¬¡å¤„ç†é—´éš”2ç§’
    å¦‚æœæŸä¸ªå›è°ƒè¿”å›ç©ºåˆ—è¡¨ï¼Œåˆ™åœæ­¢å¤„ç†åç»­ä»»åŠ¡å¹¶æ¸…ç©ºé˜Ÿåˆ—
    """
    global _threshold_callback_queue, _threshold_callback_stop_event
    global _threshold_callback_processing, _threshold_callback_stopped
    global _queue_instance
    
    logger.info("[é˜ˆå€¼å›è°ƒå¤„ç†å™¨] å¯åŠ¨")
    
    # é˜ˆå€¼å›è°ƒé—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
    callback_interval = 2.0
    last_callback_time = 0
    
    while not _threshold_callback_stop_event.is_set():
        try:
            # ä»é˜Ÿåˆ—ä¸­è·å–å›è°ƒä»»åŠ¡ï¼ˆé˜»å¡ç­‰å¾…ï¼Œæœ€å¤šç­‰å¾…1ç§’ï¼‰
            try:
                callback_task = _threshold_callback_queue.get(timeout=1.0)
            except:
                # è¶…æ—¶æˆ–é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­å¾ªç¯
                continue
            
            # æ ‡è®°ä¸ºæ­£åœ¨å¤„ç†
            with _threshold_callback_queue_lock:
                _threshold_callback_processing = True
            
            try:
                # ç¡®ä¿é—´éš”æ—¶é—´ä¸º2ç§’
                current_time = time.time()
                time_since_last = current_time - last_callback_time
                if time_since_last < callback_interval:
                    wait_time = callback_interval - time_since_last
                    time.sleep(wait_time)
                
                last_callback_time = time.time()
                
                # æ‰§è¡Œå®é™…çš„å›è°ƒé€»è¾‘ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡ï¼‰
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(_execute_threshold_callback)
                    try:
                        # è¶…æ—¶æ—¶é—´åº”è¯¥å¤§äºå†…éƒ¨æ‰€æœ‰æ“ä½œçš„æ€»å’Œï¼š
                        # - è·å–è®¢å•ä¿¡æ¯: 15ç§’
                        # - get_and_lock_devices: 180ç§’
                        # - åˆ›å»ºä»»åŠ¡: æœ€å¤š30ç§’
                        # æ€»è®¡è‡³å°‘éœ€è¦ 225ç§’ï¼Œè®¾ç½®ä¸º240ç§’ï¼ˆ4åˆ†é’Ÿï¼‰æ›´å®‰å…¨
                        tasks = future.result(timeout=240.0)  # æœ€å¤šç­‰å¾…240ç§’ï¼ˆ4åˆ†é’Ÿï¼‰
                    except concurrent.futures.TimeoutError:
                        logger.error("[é˜ˆå€¼å›è°ƒ] âš ï¸ æ‰§è¡Œè¶…æ—¶ï¼ˆ240ç§’/4åˆ†é’Ÿï¼‰")
                        logger.error("[é˜ˆå€¼å›è°ƒè¶…æ—¶åŸå› åˆ†æ]ï¼š")
                        logger.error("  1. get_and_lock_devices æ“ä½œè¶…è¿‡180ç§’ï¼ˆæ•°æ®åº“é”ç­‰å¾…æˆ–æŸ¥è¯¢æ…¢ï¼‰")
                        logger.error("  2. æ•°æ®åº“è¿æ¥æ± è€—å°½ï¼Œç­‰å¾…å¯ç”¨è¿æ¥")
                        logger.error("  3. ç½‘ç»œå»¶è¿Ÿæˆ–æ•°æ®åº“è´Ÿè½½è¿‡é«˜")
                        logger.error("  å»ºè®®ï¼šæ£€æŸ¥æ•°æ®åº“æ…¢æŸ¥è¯¢æ—¥å¿—å’Œé”ç­‰å¾…æƒ…å†µ")
                        tasks = []
                    except Exception as e:
                        logger.error(f"[é˜ˆå€¼å›è°ƒ] âš ï¸ æ‰§è¡Œå¼‚å¸¸: {e}")
                        import traceback
                        logger.error(traceback.format_exc())
                        tasks = []
                
                # å°†ä»»åŠ¡æ·»åŠ åˆ°é˜Ÿåˆ—
                if tasks:
                    # è·å–æ·»åŠ å‰çš„é˜Ÿåˆ—çŠ¶æ€
                    queue_stats_before = _queue_instance.get_stats() if _queue_instance else {}
                    queue_size_before = queue_stats_before.get('queue_size', 0)
                    
                    # æ‰¹é‡æ·»åŠ ä»»åŠ¡
                    added_count = 0
                    failed_count = 0
                    for task in tasks:
                        if _queue_instance:
                            try:
                                success = _queue_instance.add_task(task)
                                if success:
                                    added_count += 1
                                else:
                                    failed_count += 1
                                    
                                    # å¦‚æœå¤±è´¥è¿‡å¤šï¼Œæå‰ç»ˆæ­¢
                                    if failed_count > 5:
                                        break
                            except Exception:
                                failed_count += 1
                                if failed_count > 5:
                                    break
                        else:
                            break
                    
                    # è·å–æ·»åŠ åçš„é˜Ÿåˆ—çŠ¶æ€
                    queue_stats_after = _queue_instance.get_stats() if _queue_instance else {}
                    queue_size_after = queue_stats_after.get('queue_size', 0)
                    completed_after = queue_stats_after.get('completed_tasks', 0)
                    
                    # ç®€æ´çš„æˆåŠŸæ—¥å¿—ï¼ˆä¸€æ¬¡æ€§è¡¥é½æ¨¡å¼ï¼‰
                    queue_increase = queue_size_after - queue_size_before
                    if failed_count > 0:
                        logger.warning(f"[é˜ˆå€¼å›è°ƒ] âš ï¸ ä¸€æ¬¡æ€§è¡¥é½ï¼šæˆåŠŸ{added_count}ä¸ªï¼Œå¤±è´¥{failed_count}ä¸ª | é˜Ÿåˆ—: {queue_size_before}â†’{queue_size_after}(+{queue_increase})ï¼Œå·²å®Œæˆ: {completed_after}")
                    else:
                        logger.info(f"[é˜ˆå€¼å›è°ƒ] âœ“ ä¸€æ¬¡æ€§è¡¥é½æˆåŠŸ: {added_count}ä¸ªä»»åŠ¡ | é˜Ÿåˆ—: {queue_size_before}â†’{queue_size_after}(+{queue_increase})ï¼Œå·²å®Œæˆ: {completed_after}")
                else:
                    # è¿”å›ç©ºåˆ—è¡¨ï¼Œå¯èƒ½æ˜¯ä¸´æ—¶å¤±è´¥æˆ–æ²¡æœ‰å¯ç”¨è®¾å¤‡
                    logger.debug("[é˜ˆå€¼å›è°ƒ] æ— å¯ç”¨ä»»åŠ¡ï¼ˆå¯èƒ½åŸå› ï¼šæ²¡æœ‰è®¾å¤‡ã€æŸ¥è¯¢è¶…æ—¶ã€è®¢å•å®Œæˆï¼‰")
                
            except Exception as e:
                logger.error(f"[é˜ˆå€¼å›è°ƒå¤„ç†å™¨] å¤„ç†å›è°ƒä»»åŠ¡å¼‚å¸¸: {e}")
                import traceback
                logger.error(traceback.format_exc())
            finally:
                # æ ‡è®°å¤„ç†å®Œæˆ
                with _threshold_callback_queue_lock:
                    _threshold_callback_processing = False
                _threshold_callback_queue.task_done()
        
        except Exception as e:
            logger.error(f"[é˜ˆå€¼å›è°ƒå¤„ç†å™¨] å¾ªç¯å¼‚å¸¸: {e}")
            import traceback
            logger.error(traceback.format_exc())
            time.sleep(0.1)
    
    logger.info("[é˜ˆå€¼å›è°ƒå¤„ç†å™¨] å·²åœæ­¢")


def _execute_threshold_callback() -> List[Dict[str, Any]]:
    """
    æ‰§è¡Œå®é™…çš„é˜ˆå€¼å›è°ƒé€»è¾‘ï¼ˆä»æ•°æ®åº“è·å–è®¾å¤‡å¹¶åˆ›å»ºä»»åŠ¡ï¼‰
    
    Returns:
        ä»»åŠ¡åˆ—è¡¨
    """
    global _db_instance, _queue_instance, _device_table_name, _max_concurrent, _threshold_size
    global _current_order, _current_order_lock
    
    try:
        if not _db_instance or not _queue_instance:
            logger.warning("[é˜ˆå€¼å›è°ƒ] æ•°æ®åº“æˆ–é˜Ÿåˆ—å®ä¾‹æœªåˆå§‹åŒ–")
            return []
            
            # è·å–é˜Ÿåˆ—çŠ¶æ€
            queue_stats = _queue_instance.get_stats()
            queue_size = queue_stats.get("queue_size", 0)
            running_tasks = queue_stats.get("running_tasks", 0)
            
            # è®¡ç®—éœ€è¦è·å–çš„è®¾å¤‡æ•°é‡
        # æ€»ä»»åŠ¡æ•° = é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡æ•° + æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡æ•°
        # éœ€è¦è¡¥å……çš„æ•°é‡ = é˜ˆå€¼æ•°é‡ - æ€»ä»»åŠ¡æ•°
            total_in_queue = queue_size + running_tasks
            need_count = _threshold_size - total_in_queue
        
        if need_count <= 0:
            return []  # é˜Ÿåˆ—å……è¶³ï¼Œä¸éœ€è¦è¡¥å……
        
        # ä¸€æ¬¡æ€§è¡¥é½ç­–ç•¥ï¼šè·å–è¶³å¤Ÿçš„è®¾å¤‡æ•°é‡ï¼Œæ·»åŠ 20%çš„ç¼“å†²é¿å…å¹¶å‘ç«äº‰
        # ä½†é™åˆ¶å•æ¬¡è·å–çš„æœ€å¤§æ•°é‡ï¼Œé¿å…æ•°æ®åº“æ“ä½œè¿‡æ…¢
        need_count_with_buffer = int(need_count * 1.2)
        max_single_request = 2000  # å•æ¬¡æœ€å¤šè¯·æ±‚2000ä¸ªè®¾å¤‡
        
        if need_count_with_buffer > max_single_request:
            logger.info(f"[é˜ˆå€¼å›è°ƒ] éœ€è¦{need_count}ä¸ªä»»åŠ¡ï¼ˆå«ç¼“å†²{need_count_with_buffer}ä¸ªï¼‰ï¼Œä½†å•æ¬¡é™åˆ¶ä¸º{max_single_request}ä¸ªï¼Œå°†åˆ†å¤šæ¬¡è¡¥å……")
            need_count_with_buffer = max_single_request
        else:
            logger.info(f"[é˜ˆå€¼å›è°ƒ] ä¸€æ¬¡æ€§è¡¥é½æ¨¡å¼ï¼šéœ€è¦{need_count}ä¸ªä»»åŠ¡ï¼Œå®é™…è·å–{need_count_with_buffer}ä¸ªè®¾å¤‡ï¼ˆå«20%ç¼“å†²ï¼‰")
            
            # ä½¿ç”¨å½“å‰æ­£åœ¨å¤„ç†çš„è®¢å•ï¼ˆå…¨å±€å˜é‡ï¼‰
            order_id = None
            order_num = 0
            complete_num = 0
            video_ids = []
            
            with _current_order_lock:
                if not _current_order:
                    logger.error("[é˜ˆå€¼å›è°ƒ] å½“å‰è®¢å•ä¸ºç©º")
                    return []
                order_id = _current_order.get('id')
        
        import concurrent.futures
        try:
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(
                    _db_instance.select_one,
                    "uni_order",
                    where="id = %s",
                    where_params=(order_id,)
                )
                order_info = future.result(timeout=15.0)  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°15ç§’
        except concurrent.futures.TimeoutError:
            logger.warning(f"[é˜ˆå€¼å›è°ƒ] è·å–è®¢å•ä¿¡æ¯è¶…æ—¶ï¼ˆ15ç§’ï¼‰ï¼Œè¿”å›ç©ºåˆ—è¡¨ç­‰å¾…ä¸‹æ¬¡å›è°ƒ")
            return []
        except Exception as e:
            logger.error(f"[é˜ˆå€¼å›è°ƒ] è·å–è®¢å•ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
        
        if not order_info:
            logger.error(f"[é˜ˆå€¼å›è°ƒ] è®¢å• {order_id} ä¸å­˜åœ¨ï¼Œè¿™æ˜¯ä¸åº”è¯¥å‘ç”Ÿçš„æƒ…å†µï¼")
            logger.error(f"[é˜ˆå€¼å›è°ƒåœæ­¢åŸå› ] å½“å‰è®¢å• {order_id} å·²è¢«åˆ é™¤æˆ–ä¸å­˜åœ¨")
            return []
        
        order_num = order_info.get('order_num', 0) or 0
        complete_num = order_info.get('complete_num', 0) or 0
        
        # æ£€æŸ¥è®¢å•è¿˜éœ€è¦å¤šå°‘ä»»åŠ¡
        if order_num > 0:
            remaining_tasks = order_num - complete_num
            
            # é™åˆ¶è·å–æ•°é‡ä¸è¶…è¿‡è®¢å•å‰©ä½™ä»»åŠ¡æ•°
            if remaining_tasks < need_count_with_buffer:
                need_count_with_buffer = remaining_tasks
                logger.info(f"[é˜ˆå€¼å›è°ƒ] è®¢å•å‰©ä½™ä»»åŠ¡æ•° {remaining_tasks} å°äºéœ€æ±‚ï¼Œè°ƒæ•´è·å–æ•°é‡ä¸º {need_count_with_buffer}")
            
            # å¦‚æœè®¢å•å·²å®Œæˆï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªè®¢å•
            if remaining_tasks <= 0:
                logger.info(f"[é˜ˆå€¼å›è°ƒ] è®¢å• {order_id} å·²å®Œæˆï¼ˆcomplete_num={complete_num} >= order_num={order_num}ï¼‰ï¼Œæ›´æ–°çŠ¶æ€ä¸ºå·²å®Œæˆå¹¶åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªè®¢å•")
                # æ›´æ–°è®¢å•çŠ¶æ€ä¸ºå·²å®Œæˆå¹¶åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªè®¢å• - åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    def switch_order():
                        _db_instance.update("uni_order", {"status": 2}, "id = %s", (order_id,))
                        _db_instance.commit()
                        return _db_instance.select(
                            "uni_order",
                            where="status IN (0, 1)",
                            order_by="id ASC",
                            limit=1
                        )
                    future = executor.submit(switch_order)
                    try:
                        next_orders = future.result(timeout=15.0)  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°15ç§’
                    except concurrent.futures.TimeoutError:
                        logger.warning(f"[é˜ˆå€¼å›è°ƒ] åˆ‡æ¢è®¢å•æ“ä½œè¶…æ—¶ï¼ˆ15ç§’ï¼‰ï¼Œè¿”å›ç©ºåˆ—è¡¨ç­‰å¾…ä¸‹æ¬¡å›è°ƒ")
                        return []
                    
                    if not next_orders:
                        logger.info("[é˜ˆå€¼å›è°ƒ] æ²¡æœ‰æ›´å¤šå¾…å¤„ç†çš„è®¢å•ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                        logger.info("[é˜ˆå€¼å›è°ƒåœæ­¢åŸå› ] æ‰€æœ‰è®¢å•å·²å®Œæˆï¼Œæ²¡æœ‰å¾…å¤„ç†çš„è®¢å•")
                        with _current_order_lock:
                            _current_order = None
                        return []
                    
                    # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªè®¢å•
                    with _current_order_lock:
                        _current_order = next_orders[0]
                        order_info = _current_order
                        order_id = order_info['id']
                        order_num = order_info.get('order_num', 0) or 0
                        complete_num = order_info.get('complete_num', 0) or 0
                    
                    # ç¼“å­˜æ–°è®¢å•çš„ order_num åˆ° Redis
                    if _redis is not None:
                        set_order_num_to_redis(order_id, order_num)
                        logger.info(f"âœ“ åˆ‡æ¢åˆ°æ–°è®¢å• {order_id}ï¼Œæ€»æ•°å·²ç¼“å­˜åˆ°Redis: order_num={order_num}")
                    
                    # é‡æ–°è®¡ç®—å‰©ä½™ä»»åŠ¡æ•°
                    if order_num > 0:
                        remaining_tasks = order_num - complete_num
                        if remaining_tasks <= 0:
                            return []
                        need_count_with_buffer = min(need_count_with_buffer, remaining_tasks)
                    else:
                        # é™åˆ¶è·å–çš„è®¾å¤‡æ•°é‡ä¸è¶…è¿‡è®¢å•å‰©ä½™ä»»åŠ¡æ•°
                        need_count_with_buffer = min(need_count_with_buffer, remaining_tasks)
        
        if need_count_with_buffer <= 0:
            logger.warning(f"[é˜ˆå€¼å›è°ƒ] è°ƒæ•´åéœ€è¦è¡¥å……æ•°é‡ <= 0ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return []
        
        # æ£€æŸ¥è®¢å•æ˜¯å¦æœ‰æœ‰æ•ˆçš„è§†é¢‘ID
        order_info_str = order_info.get('order_info', '')
        video_ids = parse_video_ids(order_info_str)
        
        if not video_ids:
            logger.warning(f"[é˜ˆå€¼å›è°ƒ] è®¢å• {order_id} æ²¡æœ‰æœ‰æ•ˆçš„è§†é¢‘ID")
            logger.warning(f"[é˜ˆå€¼å›è°ƒåœæ­¢åŸå› ] è®¢å• {order_id} çš„ order_info å­—æ®µä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
            return []
                
        # åœ¨äº‹åŠ¡ä¸­ä»æ•°æ®åº“è·å–è®¾å¤‡å¹¶æ›´æ–°çŠ¶æ€ä¸º1ï¼ˆè¿›è¡Œä¸­ï¼‰
        # ä½¿ç”¨ç¼“å†²æ•°é‡ç¡®ä¿ä¸€æ¬¡æ€§è¡¥é½
        import concurrent.futures
        try:
            logger.debug(f"[é˜ˆå€¼å›è°ƒ] å¼€å§‹è·å–è®¾å¤‡ï¼Œè¯·æ±‚æ•°é‡: {need_count_with_buffer}")
            get_devices_start = time.time()
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(
                    get_and_lock_devices,
                    _db_instance,
                    _device_table_name,
                    need_count_with_buffer,  # ä½¿ç”¨å¸¦ç¼“å†²çš„æ•°é‡ï¼Œä¸€æ¬¡æ€§è¡¥é½
                    0
                )
                devices = future.result(timeout=180.0)  # å¢åŠ åˆ°180ç§’ï¼ˆ3åˆ†é’Ÿï¼‰
            
            get_devices_elapsed = time.time() - get_devices_start
            logger.debug(f"[é˜ˆå€¼å›è°ƒ] è·å–è®¾å¤‡å®Œæˆï¼Œè€—æ—¶: {get_devices_elapsed:.2f}ç§’ï¼Œè·å–æ•°é‡: {len(devices) if devices else 0}")
            
            if get_devices_elapsed > 60:
                logger.warning(f"[é˜ˆå€¼å›è°ƒ] âš ï¸ get_and_lock_devices è€—æ—¶è¿‡é•¿: {get_devices_elapsed:.2f}ç§’")
                logger.warning(f"[é˜ˆå€¼å›è°ƒ] å¯èƒ½åŸå› ï¼š1) æ•°æ®åº“é”ç­‰å¾… 2) è¡¨æ‰«æè¿‡æ…¢ 3) ç½‘ç»œå»¶è¿Ÿ")
        except concurrent.futures.TimeoutError:
            get_devices_elapsed = time.time() - get_devices_start
            logger.error(f"[é˜ˆå€¼å›è°ƒ] è·å–è®¾å¤‡æ“ä½œè¶…æ—¶ï¼ˆ180ç§’ï¼‰ï¼Œå®é™…è€—æ—¶: {get_devices_elapsed:.2f}ç§’")
            logger.error(f"[é˜ˆå€¼å›è°ƒ] è¯·æ±‚è·å– {need_count_with_buffer} ä¸ªè®¾å¤‡")
            logger.error(f"[é˜ˆå€¼å›è°ƒè¶…æ—¶è¯Šæ–­]ï¼š")
            logger.error(f"  1. æ•°æ®åº“SELECTæŸ¥è¯¢å¯èƒ½è¢«å…¶ä»–äº‹åŠ¡é”ä½")
            logger.error(f"  2. è¡¨ {_device_table_name} å¯èƒ½æ²¡æœ‰åˆé€‚çš„ç´¢å¼•")
            logger.error(f"  3. æ•°æ®åº“è¿æ¥æ± å¯èƒ½è€—å°½")
            logger.error(f"  å»ºè®®ï¼šæ‰§è¡Œ SHOW PROCESSLIST; æŸ¥çœ‹æ•°æ®åº“å½“å‰æ‰§è¡Œçš„æŸ¥è¯¢")
            logger.warning(f"[é˜ˆå€¼å›è°ƒåœæ­¢åŸå› ] æ•°æ®åº“è·å–è®¾å¤‡æ“ä½œè¶…æ—¶ï¼ˆ180ç§’ï¼‰ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥æ•°æ®åº“æ€§èƒ½æˆ–å¹¶å‘é”")
            return []  # è¶…æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼Œä½†ä¸åœæ­¢åç»­å¤„ç†
        except Exception as e:
            logger.error(f"[é˜ˆå€¼å›è°ƒ] è·å–è®¾å¤‡æ“ä½œå¤±è´¥: {e}")
            logger.error(f"[é˜ˆå€¼å›è°ƒåœæ­¢åŸå› ] è·å–è®¾å¤‡æ—¶å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []  # å¼‚å¸¸è¿”å›ç©ºåˆ—è¡¨ï¼Œä½†ä¸åœæ­¢åç»­å¤„ç†
        
        if not devices:
            logger.warning(f"[é˜ˆå€¼å›è°ƒ] æ²¡æœ‰å¯ç”¨è®¾å¤‡ (status=0)ï¼Œè¡¨: {_device_table_name}")
            
            # è·å–é˜Ÿåˆ—çŠ¶æ€ï¼Œæ‰“å°å½“å‰ä»»åŠ¡æ•°é‡
            if _queue_instance:
                queue_stats = _queue_instance.get_stats()
                queue_size = queue_stats.get("queue_size", 0)
                running_tasks = queue_stats.get("running_tasks", 0)
                completed_tasks = queue_stats.get("completed_tasks", 0)
                failed_tasks = queue_stats.get("failed_tasks", 0)
                total_in_queue = queue_size + running_tasks
                
                logger.info(f"[é˜ˆå€¼å›è°ƒ] ğŸ“Š å½“å‰é˜Ÿåˆ—çŠ¶æ€ï¼š")
                logger.info(f"  - ç­‰å¾…ä¸­çš„ä»»åŠ¡: {queue_size}")
                logger.info(f"  - æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡: {running_tasks}")
                logger.info(f"  - é˜Ÿåˆ—ä¸­æ€»ä»»åŠ¡æ•°: {total_in_queue} (ç­‰å¾…{queue_size} + æ‰§è¡Œä¸­{running_tasks})")
                logger.info(f"  - å·²å®Œæˆ: {completed_tasks}, å¤±è´¥: {failed_tasks}")
                
                if total_in_queue > 0:
                    logger.info(f"[é˜ˆå€¼å›è°ƒ] â³ ç­‰å¾…é˜Ÿåˆ—ä¸­ {total_in_queue} ä¸ªä»»åŠ¡å®Œæˆåï¼Œè®¾å¤‡å°†è‡ªåŠ¨é‡Šæ”¾å¹¶å¯é‡å¤ä½¿ç”¨")
                else:
                    logger.warning(f"[é˜ˆå€¼å›è°ƒ] âš ï¸ é˜Ÿåˆ—å·²ç©ºä½†ä»æ— å¯ç”¨è®¾å¤‡ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®è®¾å¤‡çŠ¶æ€")
                    
                    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®¾å¤‡éƒ½å·²ä½¿ç”¨è¿‡
                    try:
                        status_sql = f"""
                        SELECT status, COUNT(*) as count
                        FROM {_device_table_name}
                        GROUP BY status
                        """
                        status_results = _db_instance.execute(status_sql, fetch=True)
                        status_counts = {row['status']: row['count'] for row in status_results}
                        
                        total_devices = sum(status_counts.values())
                        completed_devices = status_counts.get(3, 0)
                        failed_devices = status_counts.get(4, 0)
                        
                        # å¦‚æœå¤§éƒ¨åˆ†è®¾å¤‡éƒ½å·²å®Œæˆï¼ˆ>80%ï¼‰ï¼Œåˆ™é‡ç½®è®¾å¤‡çŠ¶æ€
                        if total_devices > 0 and (completed_devices + failed_devices) / total_devices > 0.8:
                            logger.info(f"[é˜ˆå€¼å›è°ƒ] ğŸ”„ æ£€æµ‹åˆ° {(completed_devices + failed_devices) / total_devices * 100:.1f}% çš„è®¾å¤‡å·²ä½¿ç”¨è¿‡ï¼Œé‡ç½®è®¾å¤‡çŠ¶æ€...")
                            reset_count = reset_device_status(_db_instance, _device_table_name)
                            logger.info(f"[é˜ˆå€¼å›è°ƒ] âœ… è®¾å¤‡çŠ¶æ€å·²é‡ç½®ï¼Œ{reset_count} ä¸ªè®¾å¤‡å¯é‡æ–°ä½¿ç”¨")
                            
                            # é‡æ–°è·å–è®¾å¤‡
                            devices = get_devices_from_table(_db_instance, _device_table_name, limit=need_count_with_buffer, status=0)
                            if devices:
                                logger.info(f"[é˜ˆå€¼å›è°ƒ] âœ… é‡ç½®åè·å–åˆ° {len(devices)} ä¸ªè®¾å¤‡ï¼Œç»§ç»­åˆ›å»ºä»»åŠ¡")
                                # ç»§ç»­æ‰§è¡Œåé¢çš„ä»»åŠ¡åˆ›å»ºé€»è¾‘
                            else:
                                logger.warning(f"[é˜ˆå€¼å›è°ƒ] âš ï¸ é‡ç½®åä»æ— å¯ç”¨è®¾å¤‡")
                                return []
                        else:
                            logger.info(f"[é˜ˆå€¼å›è°ƒ] è®¾å¤‡ä½¿ç”¨ç‡ {(completed_devices + failed_devices) / total_devices * 100:.1f}%ï¼Œæš‚ä¸é‡ç½®")
                    except Exception as e:
                        logger.error(f"[é˜ˆå€¼å›è°ƒ] æ£€æŸ¥è®¾å¤‡çŠ¶æ€æ—¶å‡ºé”™: {e}")
            
        if not devices:
            logger.info(f"[é˜ˆå€¼å›è°ƒ] æœ¬æ¬¡ä¸æ·»åŠ æ–°ä»»åŠ¡ï¼Œç­‰å¾…é˜Ÿåˆ—ä¸­ç°æœ‰ä»»åŠ¡å®Œæˆåé‡Šæ”¾è®¾å¤‡")
            logger.info(f"[é˜ˆå€¼å›è°ƒ] æ³¨æ„ï¼šé˜ˆå€¼å›è°ƒè¿”å›ç©ºåˆ—è¡¨ä¸ä¼šå½±å“é˜Ÿåˆ—ä¸­å·²æœ‰ä»»åŠ¡çš„æ­£å¸¸æ‰§è¡Œ")
            return []
        
        # ä¸ºæ¯ä¸ªè®¾å¤‡åˆ›å»ºä»»åŠ¡
        tasks = []
        
        # è·å–ä¸»é”®å­—æ®µåï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡ï¼‰
        try:
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(
                    get_table_primary_key_field,
                    _db_instance,
                    _device_table_name
                )
                primary_key_field = future.result(timeout=5.0)  # æœ€å¤šç­‰å¾…5ç§’
        except Exception as e:
            logger.error(f"[é˜ˆå€¼å›è°ƒ] è·å–ä¸»é”®å­—æ®µå¤±è´¥: {e}")
            primary_key_field = 'id'  # é»˜è®¤ä½¿ç”¨ 'id'
        
        skipped_count = 0
        
        for device in devices:
            try:
                # è·å–ä¸»é”®å€¼
                primary_key_value = device.get(primary_key_field)
                
                if not primary_key_value:
                    logger.warning(f"[é˜ˆå€¼å›è°ƒ] è®¾å¤‡ä¸»é”®å€¼ä¸ºç©ºï¼Œè·³è¿‡")
                    skipped_count += 1
                    continue
                
                # è§£æ device_configï¼ˆå¿«é€Ÿæ“ä½œï¼Œä¸éœ€è¦åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰
                device_config_str = device.get('device_config', '')
                if device_config_str:
                    try:
                        device_dict = parse_device_config(device_config_str)
                    except Exception as e:
                        logger.warning(f"[é˜ˆå€¼å›è°ƒ] è§£æè®¾å¤‡é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨ç©ºå­—å…¸")
                        device_dict = {}
                else:
                    device_dict = {}
                
                # ä»è§£æåçš„ device_config ä¸­è·å– device_id
                device_id = device_dict.get('device_id', '')
                if not device_id:
                    # å¦‚æœæ²¡æœ‰device_idï¼Œä½¿ç”¨ä¸»é”®å€¼ä½œä¸ºæ ‡è¯†
                    device_id = str(primary_key_value)
                
                # éšæœºé€‰æ‹©ä¸€ä¸ªè§†é¢‘ID
                aweme_id = random.choice(video_ids)
                
                # åˆ›å»ºä»»åŠ¡
                task = {
                    "aweme_id": aweme_id,
                    "device": device_dict,
                    "device_id": device_id,
                    "device_table": _device_table_name,
                    "primary_key_value": primary_key_value,
                    "order_id": order_id
                }
                tasks.append(task)
            except Exception as e:
                logger.error(f"[é˜ˆå€¼å›è°ƒ] ä¸ºè®¾å¤‡åˆ›å»ºä»»åŠ¡æ—¶å¼‚å¸¸: {e}")
                skipped_count += 1
                continue
        
        if skipped_count > 0:
            logger.warning(f"[é˜ˆå€¼å›è°ƒ] è·³è¿‡äº† {skipped_count} ä¸ªæ²¡æœ‰ä¸»é”®å€¼çš„è®¾å¤‡")
        
        if not tasks:
            logger.warning(f"[é˜ˆå€¼å›è°ƒ] æ²¡æœ‰åˆ›å»ºä»»ä½•ä»»åŠ¡ï¼ˆè·³è¿‡äº† {skipped_count} ä¸ªè®¾å¤‡ï¼‰ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            # å°†è®¾å¤‡çŠ¶æ€æ›´æ–°å› 0ï¼Œå› ä¸ºä»»åŠ¡åˆ›å»ºå¤±è´¥ - åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡
            device_ids = [device.get(primary_key_field) for device in devices if device.get(primary_key_field) is not None]
            if device_ids:
                try:
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                        future = executor.submit(
                            update_devices_status,
                            _db_instance,
                            device_ids,
                            _device_table_name,
                            0
                        )
                        future.result(timeout=10.0)  # æœ€å¤šç­‰å¾…10ç§’
                except Exception as e:
                    logger.error(f"[é˜ˆå€¼å›è°ƒ] æ›´æ–°è®¾å¤‡çŠ¶æ€å¤±è´¥: {e}")
            return []
        
        # ç¡®ä¿è¿”å›ä»»åŠ¡åˆ—è¡¨ï¼Œè¡¥å……åˆ°é˜Ÿåˆ—ä¸­
        if tasks:
            return tasks  # è¿”å›ä»»åŠ¡åˆ—è¡¨ï¼Œè¡¥å……åˆ°é˜Ÿåˆ—
        else:
            # å°†è®¾å¤‡çŠ¶æ€æ›´æ–°å› 0ï¼Œå› ä¸ºä»»åŠ¡åˆ›å»ºå¤±è´¥
            device_ids = [device.get(primary_key_field) for device in devices if device.get(primary_key_field) is not None]
            if device_ids:
                try:
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                        future = executor.submit(
                            update_devices_status,
                            _db_instance,
                            device_ids,
                            _device_table_name,
                            0
                        )
                        future.result(timeout=10.0)  # æœ€å¤šç­‰å¾…10ç§’
                except Exception as e:
                    logger.error(f"[é˜ˆå€¼å›è°ƒ] æ›´æ–°è®¾å¤‡çŠ¶æ€å¤±è´¥: {e}")
            return []  # ä»»åŠ¡åˆ›å»ºå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
    except Exception as e:
        logger.error(f"é˜ˆå€¼å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return []


def threshold_callback() -> List[Dict[str, Any]]:
    """
    é˜ˆå€¼è¡¥ç»™å›è°ƒå‡½æ•°ï¼ˆåŒæ­¥å‡½æ•°ï¼‰
    å½“é˜Ÿåˆ—è¾¾åˆ°é˜ˆå€¼æ—¶ï¼Œå°†å›è°ƒä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—ï¼Œç”±åå°çº¿ç¨‹æŒ‰é¡ºåºå¤„ç†
    å¦‚æœæŸä¸ªå›è°ƒè¿”å›ç©ºåˆ—è¡¨ï¼Œåˆ™åœæ­¢å¤„ç†åç»­ä»»åŠ¡
    åªæœ‰åœ¨ç¡®å®éœ€è¦å›è°ƒçš„æƒ…å†µä¸‹ï¼ˆæœ‰æ–°è®¢å•æˆ–é˜Ÿåˆ—éœ€è¦è¡¥å……ï¼‰ï¼Œæ‰é‡ç½®åœæ­¢æ ‡å¿—å¹¶ç»§ç»­å¤„ç†
    
    Returns:
        ä»»åŠ¡åˆ—è¡¨ï¼ˆæ€»æ˜¯è¿”å›ç©ºåˆ—è¡¨ï¼Œå®é™…ä»»åŠ¡ç”±åå°çº¿ç¨‹å¤„ç†ï¼‰
    """
    global _threshold_callback_queue, _threshold_callback_stopped
    global _threshold_callback_processing, _threshold_callback_queue_lock
    global _db_instance, _queue_instance, _threshold_size, _current_order, _current_order_lock
    
    # æ£€æŸ¥æ˜¯å¦çœŸçš„éœ€è¦å›è°ƒï¼ˆæ— è®ºæ˜¯å¦å·²åœæ­¢ï¼‰
    need_callback = False
    need_count = 0  # åˆå§‹åŒ– need_count
    
    # æ£€æŸ¥1ï¼šé˜Ÿåˆ—æ˜¯å¦éœ€è¦è¡¥å……
    if _queue_instance:
        queue_stats = _queue_instance.get_stats()
        queue_size = queue_stats.get("queue_size", 0)
        running_tasks = queue_stats.get("running_tasks", 0)
        total_in_queue = queue_size + running_tasks
        need_count = _threshold_size - total_in_queue
        
        logger.debug(f"[é˜ˆå€¼å›è°ƒ] æ£€æŸ¥æ˜¯å¦éœ€è¦å›è°ƒ: é˜Ÿåˆ—å¤§å°={queue_size}, è¿è¡Œä¸­={running_tasks}, æ€»ä»»åŠ¡æ•°={total_in_queue}, é˜ˆå€¼={_threshold_size}, éœ€è¦è¡¥å……={need_count}")
        
        if need_count > 0:
            # æ£€æŸ¥2ï¼šæ˜¯å¦æœ‰è®¢å•éœ€è¦å¤„ç†
            with _current_order_lock:
                if _current_order:
                    # æœ‰è®¢å•ï¼Œéœ€è¦å›è°ƒ
                    need_callback = True
                    logger.debug(f"[é˜ˆå€¼å›è°ƒ] é˜Ÿåˆ—éœ€è¦è¡¥å……ï¼ˆéœ€è¦ {need_count} ä¸ªä»»åŠ¡ï¼‰ï¼Œç»§ç»­å¤„ç†")
                else:
                    # æ²¡æœ‰è®¢å•ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°è®¢å•
                    if _db_instance:
                        next_orders = _db_instance.select(
                            "uni_order",
                            where="status IN (0, 1)",
                            order_by="id ASC",
                            limit=1
                        )
                        if next_orders:
                            # æœ‰æ–°è®¢å•ï¼Œéœ€è¦å›è°ƒ
                            _current_order = next_orders[0]
                            need_callback = True
                            logger.info(f"[é˜ˆå€¼å›è°ƒ] å‘ç°æ–°è®¢å• {_current_order.get('id')}ï¼Œç»§ç»­å¤„ç†")
                        else:
                            # æ²¡æœ‰æ–°è®¢å•ï¼Œä¸éœ€è¦å›è°ƒ
                            logger.debug("[é˜ˆå€¼å›è°ƒ] æ²¡æœ‰æ–°è®¢å•ï¼Œè·³è¿‡æœ¬æ¬¡å›è°ƒ")
                    else:
                        # æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œä¸éœ€è¦å›è°ƒ
                        logger.debug("[é˜ˆå€¼å›è°ƒ] æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æœ¬æ¬¡å›è°ƒ")
        else:
            # é˜Ÿåˆ—ä¸éœ€è¦è¡¥å……ï¼Œä¸éœ€è¦å›è°ƒ
            logger.debug(f"[é˜ˆå€¼å›è°ƒ] é˜Ÿåˆ—å……è¶³ï¼ˆæ€»ä»»åŠ¡æ•°: {total_in_queue}, é˜ˆå€¼: {_threshold_size}ï¼‰ï¼Œè·³è¿‡æœ¬æ¬¡å›è°ƒ")
    
    # å¦‚æœä¸éœ€è¦å›è°ƒï¼Œç›´æ¥è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸æ”¾å…¥é˜Ÿåˆ—
    if not need_callback:
        reason = ""
        if _queue_instance:
            queue_stats = _queue_instance.get_stats()
            queue_size = queue_stats.get("queue_size", 0)
            running_tasks = queue_stats.get("running_tasks", 0)
            total_in_queue = queue_size + running_tasks
            if total_in_queue >= _threshold_size:
                reason = f"é˜Ÿåˆ—å……è¶³ï¼ˆæ€»ä»»åŠ¡æ•°: {total_in_queue} >= é˜ˆå€¼: {_threshold_size}ï¼‰"
            else:
                with _current_order_lock:
                    if not _current_order:
                        reason = "æ²¡æœ‰è®¢å•éœ€è¦å¤„ç†"
                    else:
                        reason = "æœªçŸ¥åŸå› "
        else:
            reason = "é˜Ÿåˆ—å®ä¾‹æœªåˆå§‹åŒ–"
        
        logger.debug(f"[é˜ˆå€¼å›è°ƒ] ä¸éœ€è¦å›è°ƒã€‚åŸå› : {reason}")
        return []
    
    # é˜²é‡å…¥ä¿æŠ¤ï¼šå¦‚æœæ­£åœ¨å¤„ç†å›è°ƒæˆ–é˜Ÿåˆ—ä¸­å·²æœ‰å¾…å¤„ç†çš„å›è°ƒï¼Œä¸å†æ·»åŠ æ–°çš„
    with _threshold_callback_queue_lock:
        if _threshold_callback_processing:
            logger.debug("[é˜ˆå€¼å›è°ƒ] å·²æœ‰å›è°ƒæ­£åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡æœ¬æ¬¡å›è°ƒ")
            return []
        
        # æ£€æŸ¥é˜Ÿåˆ—å¤§å°ï¼Œå¦‚æœå·²æœ‰å¾…å¤„ç†çš„å›è°ƒï¼Œä¸å†æ·»åŠ 
        if _threshold_callback_queue is not None:
            queue_size = _threshold_callback_queue.qsize()
            if queue_size > 0:
                logger.debug(f"[é˜ˆå€¼å›è°ƒ] å›è°ƒé˜Ÿåˆ—ä¸­å·²æœ‰ {queue_size} ä¸ªå¾…å¤„ç†ä»»åŠ¡ï¼Œè·³è¿‡æœ¬æ¬¡å›è°ƒ")
                return []
    
    # å°†å›è°ƒä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
    if _threshold_callback_queue is not None:
        try:
            _threshold_callback_queue.put_nowait(True)
            logger.debug("[é˜ˆå€¼å›è°ƒ] å·²å°†å›è°ƒä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—")
        except:
            logger.warning("[é˜ˆå€¼å›è°ƒ] å›è°ƒé˜Ÿåˆ—å·²æ»¡")
            return []
    
    # æ€»æ˜¯è¿”å›ç©ºåˆ—è¡¨ï¼Œå®é™…ä»»åŠ¡ç”±åå°çº¿ç¨‹å¤„ç†
    # æ³¨æ„ï¼šè¿”å›ç©ºåˆ—è¡¨ä¸ä»£è¡¨æ²¡æœ‰ä»»åŠ¡ï¼Œè€Œæ˜¯ä»»åŠ¡å·²æ”¾å…¥å›è°ƒé˜Ÿåˆ—ï¼Œç”±åå°çº¿ç¨‹æŒ‰é¡ºåºå¤„ç†
            return []


async def task_callback(task_data: Dict[str, Any]):
    """
    ä»»åŠ¡æ‰§è¡Œå›è°ƒå‡½æ•°ï¼ˆå¼‚æ­¥ï¼‰
    æ‰§è¡Œæ’­æ”¾è§†é¢‘ä»»åŠ¡
    
    Args:
        task_data: ä»»åŠ¡æ•°æ®ï¼ŒåŒ…å« aweme_id, device, device_id, device_table, primary_key_value, order_id
    """
    global _db_instance, _api_instance, _http_client_instance
    global _device_fail_count, _device_fail_lock, _device_fail_threshold
    
    try:
        if not _db_instance or not _api_instance or not _http_client_instance:
            logger.error("æ•°æ®åº“ã€API æˆ– HttpClient å®ä¾‹æœªåˆå§‹åŒ–")
            return
        
        aweme_id = task_data.get('aweme_id')
        device = task_data.get('device', {})
        device_id = task_data.get('device_id', '')
        device_table = task_data.get('device_table', _device_table_name)
        primary_key_value = task_data.get('primary_key_value')
        order_id = task_data.get('order_id')
        
        # åœ¨æ‰§è¡Œä»»åŠ¡å‰ï¼Œæ£€æŸ¥è®¢å•æ˜¯å¦å·²ç»å®Œæˆï¼ˆä½¿ç”¨Redisç¼“å­˜ï¼Œé¿å…é¢‘ç¹æŸ¥è¯¢æ•°æ®åº“ï¼‰
        # åªæœ‰å½“è®¢å•æ¥è¿‘å®Œæˆæ—¶æ‰æ£€æŸ¥ï¼Œé¿å…ä¸å¿…è¦çš„æŸ¥è¯¢
        if order_id and _redis:
            try:
                # ä»Redisè·å–è®¢å•è¿›åº¦ï¼ˆå¿«é€Ÿï¼Œä¸æŸ¥è¯¢æ•°æ®åº“ï¼‰
                redis_complete = get_order_complete_from_redis(order_id)
                redis_order_num = get_order_num_from_redis(order_id)
                
                if redis_order_num and redis_order_num > 0:
                    # åªæœ‰å½“å®Œæˆåº¦è¶…è¿‡90%æ—¶æ‰æ£€æŸ¥ï¼ˆé¿å…ä¸å¿…è¦çš„æ£€æŸ¥ï¼‰
                    if redis_complete >= redis_order_num * 0.9:
                        # æ¥è¿‘å®Œæˆï¼Œä»æ•°æ®åº“ç¡®è®¤ä¸€ä¸‹ï¼ˆä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
                        loop = asyncio.get_running_loop()
                        
                        def get_order_status():
                            return _db_instance.select_one("uni_order", where="id = %s", where_params=(order_id,))
                        
                        order_info = await loop.run_in_executor(None, get_order_status)
                        if order_info:
                            order_num = order_info.get('order_num', 0) or 0
                            complete_num = order_info.get('complete_num', 0) or 0
                            
                            if order_num > 0 and complete_num >= order_num:
                                # è®¢å•å·²å®Œæˆï¼Œè·³è¿‡æ­¤ä»»åŠ¡
                                logger.info(f"[ä»»åŠ¡è·³è¿‡] è®¢å• {order_id} å·²å®Œæˆ({complete_num}/{order_num})ï¼Œè·³è¿‡ä»»åŠ¡: ä¸»é”®ID={primary_key_value}, è®¾å¤‡ID={device_id}")
                                
                                # é‡Šæ”¾è®¾å¤‡çŠ¶æ€
                                primary_key_field = get_table_primary_key_field(_db_instance, device_table)
                                update_device_status_to_redis(primary_key_value, 0)  # çŠ¶æ€0ï¼šå¯ç”¨
                                
                                return  # ç›´æ¥è¿”å›ï¼Œä¸æ‰§è¡Œä»»åŠ¡
            except Exception as e:
                logger.debug(f"[ä»»åŠ¡æ£€æŸ¥] æ£€æŸ¥è®¢å•çŠ¶æ€æ—¶å‡ºé”™: {e}ï¼Œç»§ç»­æ‰§è¡Œä»»åŠ¡")
        
        logger.info(f"[ä»»åŠ¡å¼€å§‹] ä¸»é”®ID: {primary_key_value}, è®¾å¤‡ID: {device_id}, è§†é¢‘ID: {aweme_id}")
        task_start = time.time()
        
        # æ‰§è¡Œæ’­æ”¾è§†é¢‘ä»»åŠ¡ï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…ä»»åŠ¡é•¿æ—¶é—´é˜»å¡ï¼‰
        # ä»»åŠ¡æ€»è¶…æ—¶ = statsè¶…æ—¶ + å…¶ä»–é˜¶æ®µé¢„ç•™æ—¶é—´ï¼ˆ20ç§’ï¼‰
        task_timeout = _stats_timeout + 20.0
        try:
            success, _ = await asyncio.wait_for(
                play_video_task(
            aweme_id=aweme_id,
            device=device,
            device_id=device_id,
            device_table=device_table,
            primary_key_value=primary_key_value,
            db=_db_instance,
            api=_api_instance,
            http_client=_http_client_instance,
            order_id=order_id
                ),
                timeout=task_timeout
            )
        except asyncio.TimeoutError:
            task_elapsed = time.time() - task_start
            logger.error(f"[ä»»åŠ¡è¶…æ—¶] æ’­æ”¾è§†é¢‘ä»»åŠ¡è¶…æ—¶ï¼ˆ{task_timeout:.0f}ç§’ï¼‰ï¼Œä¸»é”®ID: {primary_key_value}, è®¾å¤‡ID: {device_id}, è§†é¢‘ID: {aweme_id}ï¼Œå®é™…è€—æ—¶: {task_elapsed:.1f}ç§’")
            logger.error(f"[è¶…æ—¶åˆ†æ] å¯èƒ½åŸå› ï¼š1) HTTPè¯·æ±‚å¡ä½ 2) æ•°æ®åº“æ“ä½œé˜»å¡ 3) ä»£ç†æ— å“åº” 4) çº¿ç¨‹æ± è€—å°½")
            logger.error(f"[è¶…æ—¶åˆ†æ] é…ç½®çš„statsè¶…æ—¶: {_stats_timeout}ç§’ï¼Œä»»åŠ¡æ€»è¶…æ—¶: {task_timeout:.0f}ç§’")
            success = False
        
        # è¯·æ±‚å®Œæˆï¼Œæ‰“å°ä¸»é”®ID
        task_elapsed = time.time() - task_start
        logger.info(f"[ä»»åŠ¡å®Œæˆ] ä¸»é”®ID: {primary_key_value}, è®¾å¤‡ID: {device_id}, ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}, è§†é¢‘ID: {aweme_id}, è€—æ—¶: {task_elapsed:.2f}ç§’")
        
        # æ›´æ–°ä»»åŠ¡ç»Ÿè®¡
        with _task_stats_lock:
            _task_stats["total_completed"] += 1
            if success:
                _task_stats["total_success"] += 1
            else:
                _task_stats["total_failed"] += 1
        
        if success:
            logger.debug(f"ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ: ä¸»é”®ID={primary_key_value}, device_id={device_id}, aweme_id={aweme_id}")
            # æˆåŠŸæ—¶é‡ç½®å¤±è´¥è®¡æ•°
            with _device_fail_lock:
                if device_id in _device_fail_count:
                    _device_fail_count[device_id] = 0
        else:
            logger.warning(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: ä¸»é”®ID={primary_key_value}, device_id={device_id}, aweme_id={aweme_id}")
            # å¤±è´¥æ—¶å¢åŠ å¤±è´¥è®¡æ•°
            with _device_fail_lock:
                current_fail_count = _device_fail_count.get(device_id, 0) + 1
                _device_fail_count[device_id] = current_fail_count
                
                # å¦‚æœè¿ç»­å¤±è´¥è¶…è¿‡é˜ˆå€¼ï¼Œæ ‡è®°è®¾å¤‡ä¸ºå¼‚å¸¸çŠ¶æ€
                if current_fail_count >= _device_fail_threshold:
                    logger.warning(f"è®¾å¤‡ {device_id} è¿ç»­å¤±è´¥ {current_fail_count} æ¬¡ï¼ˆé˜ˆå€¼: {_device_fail_threshold}ï¼‰ï¼Œæ ‡è®°ä¸ºå¼‚å¸¸çŠ¶æ€")
                    # æ›´æ–°è®¾å¤‡çŠ¶æ€ä¸º 4ï¼ˆè¿ç»­å¤±è´¥å¼‚å¸¸çŠ¶æ€ï¼‰- ä½¿ç”¨Redisæ‰¹é‡æ›´æ–°
                    try:
                        if primary_key_value:
                            # å°†è®¾å¤‡çŠ¶æ€å˜æ›´è®°å½•åˆ°Redisé˜Ÿåˆ—ï¼ˆç›®æ ‡çŠ¶æ€=4ï¼Œè¿ç»­å¤±è´¥å¼‚å¸¸ï¼‰
                            set_device_status_in_redis(primary_key_value, target_status=4)
                            logger.info(f"âœ“ è®¾å¤‡ {device_id} (primary_key={primary_key_value}) å¼‚å¸¸çŠ¶æ€æ ‡è®°å·²æäº¤åˆ°Redisé˜Ÿåˆ—")
                        else:
                            logger.warning(f"è®¾å¤‡ {device_id} çš„ä¸»é”®å€¼æœªæ‰¾åˆ°ï¼Œæ— æ³•æ›´æ–°çŠ¶æ€")
                    except Exception as e:
                        logger.error(f"æ›´æ–°è®¾å¤‡ {device_id} çŠ¶æ€å¤±è´¥: {e}")
                        import traceback
                        logger.error(traceback.format_exc())
                
    except Exception as e:
        device_id = task_data.get('device_id', '')
        primary_key_value = task_data.get('primary_key_value')
        aweme_id = task_data.get('aweme_id', '')
        # è¯·æ±‚å®Œæˆï¼ˆå¼‚å¸¸ï¼‰ï¼Œæ‰“å°ä¸»é”®ID
        logger.info(f"[è¯·æ±‚å®Œæˆ] ä¸»é”®ID: {primary_key_value}, è®¾å¤‡ID: {device_id}, ç»“æœ: å¼‚å¸¸, è§†é¢‘ID: {aweme_id}")
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())
        # å¼‚å¸¸ä¹Ÿè§†ä¸ºå¤±è´¥ï¼Œå¢åŠ å¤±è´¥è®¡æ•°
        device_table = task_data.get('device_table', _device_table_name)
        primary_key_value = task_data.get('primary_key_value')
        
        with _device_fail_lock:
            current_fail_count = _device_fail_count.get(device_id, 0) + 1
            _device_fail_count[device_id] = current_fail_count
            
            # å¦‚æœè¿ç»­å¤±è´¥è¶…è¿‡é˜ˆå€¼ï¼Œæ ‡è®°è®¾å¤‡ä¸ºå¼‚å¸¸çŠ¶æ€
            if current_fail_count >= _device_fail_threshold:
                logger.warning(f"è®¾å¤‡ {device_id} è¿ç»­å¤±è´¥ {current_fail_count} æ¬¡ï¼ˆé˜ˆå€¼: {_device_fail_threshold}ï¼‰ï¼Œæ ‡è®°ä¸ºå¼‚å¸¸çŠ¶æ€")
                try:
                    if primary_key_value:
                        primary_key_field = get_table_primary_key_field(_db_instance, device_table)
                        
                        # æ›´æ–°è®¾å¤‡çŠ¶æ€ - åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                        def update_device_status():
                            update_status_sql = f"""
                                UPDATE {device_table} 
                                SET status = 4
                                WHERE {primary_key_field} = %s
                            """
                            with _db_instance.get_cursor() as cursor:
                                cursor.execute(update_status_sql, (primary_key_value,))
                                if not _db_instance.autocommit:
                                    _db_instance._get_connection().commit()
                        
                        loop = asyncio.get_running_loop()
                        await loop.run_in_executor(None, update_device_status)
                        logger.info(f"âœ“ è®¾å¤‡ {device_id} åœ¨è¡¨ {device_table} ä¸­å·²æ ‡è®°ä¸ºè¿ç»­å¤±è´¥å¼‚å¸¸çŠ¶æ€ (status=4)")
                except Exception as update_error:
                    logger.error(f"æ›´æ–°è®¾å¤‡ {device_id} çŠ¶æ€å¤±è´¥: {update_error}")
        raise


def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    
    Returns:
        argparse.Namespace: è§£æåçš„å‚æ•°å¯¹è±¡
    """
    parser = argparse.ArgumentParser(
        description="è®¢å•å¤„ç†è„šæœ¬ - ä» uni_order è¡¨æ‹‰å–è®¢å•ï¼Œå¹¶å‘å¤„ç†è§†é¢‘æ’­æ”¾ä»»åŠ¡",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python order_processor.py 1    # ä½¿ç”¨ uni_devices_1 è¡¨
  python order_processor.py 2    # ä½¿ç”¨ uni_devices_2 è¡¨
  python order_processor.py      # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ device_table æˆ–é»˜è®¤ uni_devices_1
        """
    )
    parser.add_argument(
        "table_number",
        type=int,
        nargs="?",
        default=None,
        help="è®¾å¤‡è¡¨ç¼–å·ï¼ˆä¾‹å¦‚: 1 è¡¨ç¤ºä½¿ç”¨ uni_devices_1 è¡¨ï¼Œ2 è¡¨ç¤ºä½¿ç”¨ uni_devices_2 è¡¨ï¼‰"
    )
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°ï¼ˆä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—ï¼‰"""
    global _db_instance, _api_instance, _http_client_instance, _queue_instance, _thread_pool
    global _device_table_name, _max_concurrent, _threshold_size, _device_fail_threshold
    global _threshold_callback_queue, _threshold_callback_processor_thread, _threshold_callback_stop_event
    global _threshold_callback_stopped, _threshold_callback_queue_lock
    global log_file
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    logger.info("=" * 80)
    logger.info("è®¢å•å¤„ç†ç¨‹åºå¯åŠ¨ï¼ˆæ¶ˆæ¯é˜Ÿåˆ—æ¨¡å¼ï¼‰")
    logger.info("=" * 80)
    
    # è¾“å‡ºæ—¥å¿—æ–‡ä»¶ä½ç½®
    if log_file:
        logger.info(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶: {log_file}")
        logger.info(f"ğŸ“Š æ§åˆ¶å°æ˜¾ç¤º: INFO åŠä»¥ä¸Šçº§åˆ«")
        logger.info(f"ğŸ“Š æ–‡ä»¶è®°å½•: DEBUG åŠä»¥ä¸Šçº§åˆ«ï¼ˆåŒ…å«æ‰€æœ‰é˜¶æ®µè¯Šæ–­æ—¥å¿—ï¼‰")
        logger.info("=" * 80)
    else:
        logger.warning("âš ï¸ æ—¥å¿—ä»…è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œæœªå†™å…¥æ–‡ä»¶")
    logger.info("=" * 80)
    
    # åˆå§‹åŒ–é˜ˆå€¼å›è°ƒé˜Ÿåˆ—å’Œåœæ­¢äº‹ä»¶
    from queue import Queue
    _threshold_callback_queue = Queue()
    _threshold_callback_stop_event = threading.Event()
    with _threshold_callback_queue_lock:
        _threshold_callback_stopped = False
    
    # å¯åŠ¨é˜ˆå€¼å›è°ƒå¤„ç†å™¨çº¿ç¨‹
    _threshold_callback_processor_thread = threading.Thread(
        target=_threshold_callback_processor,
        daemon=True,
        name="ThresholdCallbackProcessor"
    )
    _threshold_callback_processor_thread.start()
    logger.info("é˜ˆå€¼å›è°ƒå¤„ç†å™¨çº¿ç¨‹å·²å¯åŠ¨")
    
    # è¿æ¥æ•°æ®åº“ï¼ˆä½¿ç”¨è¿æ¥æ± ï¼‰
    try:
        # ä½¿ç”¨è¿æ¥æ± ï¼šå›ºå®šæ•°é‡çš„è¿æ¥ï¼Œå¤šçº¿ç¨‹å…±äº«
        # pool_size: æ ¸å¿ƒè¿æ¥æ•°ï¼ˆå»ºè®®è®¾ç½®ä¸º 10-20ï¼‰
        # max_overflow: æœ€å¤§æº¢å‡ºè¿æ¥æ•°ï¼ˆé«˜å³°æœŸä¸´æ—¶åˆ›å»ºï¼‰
        # æ•°æ®åº“è¿æ¥æ± å¤§å°åº”è¯¥ >= å¹¶å‘æ•°ï¼Œé¿å…ä»»åŠ¡ç­‰å¾…è¿æ¥
        # pool_size + max_overflow åº”è¯¥ >= max_concurrent
        _db_instance = MySQLConnectionPool(
            pool_size=50,  # æ ¸å¿ƒè¿æ¥æ•°ï¼š50ä¸ªå›ºå®šè¿æ¥
            max_overflow=200,  # æœ€å¤§æº¢å‡ºï¼šé«˜å³°æœŸå¯å¢åŠ 200ä¸ªï¼ˆæ€»å…±æœ€å¤š250ä¸ªï¼‰
            timeout=30  # è·å–è¿æ¥è¶…æ—¶ï¼š30ç§’
        )
        stats = _db_instance.get_stats()
        logger.info(f"æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–æˆåŠŸ: {stats}")
    except Exception as e:
        logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        sys.exit(1)
    
    # åˆå§‹åŒ– Redis å®¢æˆ·ç«¯
    try:
        global _redis
        _redis = RedisClient()
        logger.info("Rediså®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯• Redis è¿æ¥
        if _redis.ping():
            logger.info("Redisè¿æ¥æµ‹è¯•æˆåŠŸ")
    except Exception as e:
        logger.error(f"Redisè¿æ¥å¤±è´¥: {e}")
        logger.warning("ç¨‹åºå°†ç»§ç»­è¿è¡Œï¼Œä½†æ•°æ®æ›´æ–°å°†ç›´æ¥å†™å…¥æ•°æ®åº“ï¼ˆæ€§èƒ½è¾ƒä½ï¼‰")
        _redis = None
    
    # åŠ è½½é…ç½®
    config = ConfigLoader._load_config_file()
    mq_config = config.get("message_queue", {})
    order_config = config.get("order_processor", {})
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–å‚æ•°
    _max_concurrent = order_config.get("max_concurrent", 1000)
    _threshold_size = order_config.get("threshold_size", 3 * _max_concurrent)  # é»˜è®¤é˜ˆå€¼ä¸ºå¹¶å‘æ•°çš„3å€
    
    # ç¡®å®šè®¾å¤‡è¡¨åï¼ˆä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > é…ç½®æ–‡ä»¶ > é»˜è®¤å€¼ï¼‰
    if args.table_number is not None:
        # å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆ
        _device_table_name = f"uni_devices_{args.table_number}"
        logger.info(f"ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šçš„è®¾å¤‡è¡¨: {_device_table_name}")
    else:
        # ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        _device_table_name = order_config.get("device_table", "uni_devices_1")
        logger.info(f"ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾å¤‡è¡¨: {_device_table_name}")
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–è®¾å¤‡è¿ç»­å¤±è´¥é˜ˆå€¼ï¼ˆå¿…é¡»é…ç½®ï¼‰
    if "device_fail_threshold" not in order_config:
        logger.error("é…ç½®æ–‡ä»¶ä¸­æœªè®¾ç½® device_fail_threshold (order_processor.device_fail_threshold)")
        sys.exit(1)
    _device_fail_threshold = order_config.get("device_fail_threshold")
    if not isinstance(_device_fail_threshold, int) or _device_fail_threshold <= 0:
        logger.error(f"é…ç½®æ–‡ä»¶ä¸­ device_fail_threshold å¿…é¡»ä¸ºæ­£æ•´æ•°ï¼Œå½“å‰å€¼: {_device_fail_threshold}")
        sys.exit(1)
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–statsè¶…æ—¶å’Œè¯·æ±‚å»¶è¿Ÿé…ç½®
    global _stats_timeout, _request_delay_min, _request_delay_max
    _stats_timeout = order_config.get("stats_timeout", 45.0)
    _request_delay_min = order_config.get("request_delay_min", 0.05)
    _request_delay_max = order_config.get("request_delay_max", 0.15)
    
    logger.info(f"å¹¶å‘æ•°é…ç½®: {_max_concurrent}")
    logger.info(f"é˜Ÿåˆ—é˜ˆå€¼é…ç½®: {_threshold_size}")
    logger.info(f"è®¾å¤‡è¡¨å: {_device_table_name}")
    logger.info(f"è®¾å¤‡è¿ç»­å¤±è´¥é˜ˆå€¼: {_device_fail_threshold}")
    logger.info(f"Statsè¯·æ±‚è¶…æ—¶: {_stats_timeout}ç§’")
    logger.info(f"è¯·æ±‚å»¶è¿ŸèŒƒå›´: {_request_delay_min*1000:.0f}-{_request_delay_max*1000:.0f}ms")
    
    # ä¼˜å…ˆä» order_processor è¯»å–ä»£ç†ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä» message_queue è¯»å–
    proxy = order_config.get("proxy", "")
    if not proxy:
        proxy = mq_config.get("proxy", "")
    
    if not proxy:
        logger.error("é…ç½®æ–‡ä»¶ä¸­æœªè®¾ç½®ä»£ç† (order_processor.proxy æˆ– message_queue.proxy)")
        sys.exit(1)
    
    logger.info(f"ä½¿ç”¨ä»£ç†: {proxy[:50]}..." if len(proxy) > 50 else f"ä½¿ç”¨ä»£ç†: {proxy}")
    
    # ä»é…ç½®æ–‡ä»¶è¯»å– session ç®¡ç†å‚æ•°
    # ä¼˜å…ˆä» order_processor è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä» message_queue è¯»å–
    max_session_usage = order_config.get("max_session_usage", mq_config.get("max_session_usage", 100))
    max_pool_size = order_config.get("max_pool_size", mq_config.get("pool_max_size", 5000))
    
    logger.info(f"Session ç®¡ç†é…ç½®: max_session_usage={max_session_usage}, max_pool_size={max_pool_size}")
    
    # åˆ›å»º TikTokAPI å®ä¾‹
    _api_instance = TikTokAPI(
        proxy=proxy,
        timeout=30,
        max_retries=1,
        retry_delay=2.0,
        pool_initial_size=mq_config.get("pool_initial_size", 100),  # å·²åºŸå¼ƒï¼Œä»…å‘åå…¼å®¹
        pool_max_size=max_pool_size,  # å…¨å±€æ± æœ€å¤§å¤§å°ï¼ˆæœ€å¤šæ”¯æŒå¤šå°‘è®¾å¤‡ï¼‰
        pool_grow_step=mq_config.get("pool_grow_step", 10),  # å·²åºŸå¼ƒï¼Œä»…å‘åå…¼å®¹
        max_session_usage=max_session_usage,  # æ¯ä¸ª session çš„æœ€å¤§ä½¿ç”¨æ¬¡æ•°ï¼Œä»é…ç½®æ–‡ä»¶è¯»å–
        use_global_client=True
    )
    
    _http_client_instance = _api_instance.http_client
    
    try:
        # æ­¥éª¤0ï¼šåˆ·æ–°ä¸Šæ¬¡ç¨‹åºé—ç•™åœ¨Redisä¸­çš„è®¾å¤‡æ•°æ®åˆ°MySQLï¼ˆåªåœ¨ç¨‹åºå¯åŠ¨æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰
        # æ³¨æ„ï¼šè®¢å•æ•°æ®ä¸åœ¨æ­¤åˆ·æ–°ï¼Œåªæœ‰åœ¨è®¢å•å®Œæˆæ—¶æ‰åˆ·æ–°
        logger.info("=" * 80)
        logger.info("æ­¥éª¤0ï¼šåˆ·æ–°ä¸Šæ¬¡é—ç•™çš„Redisè®¾å¤‡æ•°æ®åˆ°MySQL...")
        logger.info("=" * 80)
        if _redis is not None:
            # åªåˆ·æ–°è®¾å¤‡æ’­æ”¾æ¬¡æ•°å’ŒçŠ¶æ€ï¼Œè®¢å•complete_numåªåœ¨è®¢å•å®Œæˆæ—¶æ›´æ–°
            flush_stats = flush_redis_to_mysql(_db_instance, _device_table_name)
            if flush_stats['devices_updated'] > 0:
                logger.info(f"å‘ç°å¹¶å¤„ç†äº†ä¸Šæ¬¡é—ç•™çš„è®¾å¤‡æ•°æ®: è®¾å¤‡={flush_stats['devices_updated']}")
                # åˆ·æ–°ååªæ¸…ç†è®¾å¤‡ç¼“å­˜ï¼Œè®¢å•ç¼“å­˜åœ¨æ­¥éª¤1é‡æ–°åŠ è½½æ—¶ä¼šè¢«è¦†ç›–
                clear_redis_cache(clear_orders=False)
            else:
                logger.info("æ²¡æœ‰å‘ç°ä¸Šæ¬¡é—ç•™çš„Redisè®¾å¤‡æ•°æ®")
        else:
            logger.info("Redisæœªè¿æ¥ï¼Œè·³è¿‡æ­¥éª¤0")
        
        # ä¸»å¾ªç¯ï¼šæŒç»­å¤„ç†è®¢å•
        logger.info("=" * 80)
        logger.info("è¿›å…¥è®¢å•å¤„ç†ä¸»å¾ªç¯...")
        logger.info("=" * 80)
        
        while True:  # å¤–å±‚å¾ªç¯ï¼šæŒç»­ç­‰å¾…å’Œå¤„ç†è®¢å•
            global _order_completed_flag, _order_completed_lock, _current_order
            
            try:
                logger.info("")
                logger.info("ğŸ”„" * 40)
                logger.info("ğŸ”„ å¼€å§‹æ–°ä¸€è½®è®¢å•å¤„ç†å¾ªç¯")
                logger.info("ğŸ”„" * 40)
                logger.info("")
                
                # æ­¥éª¤1ï¼šåŠ è½½æ‰€æœ‰å¾…å¤„ç†è®¢å•åˆ°Redis
                logger.info("=" * 80)
                logger.info("æ­¥éª¤1ï¼šåŠ è½½æ‰€æœ‰å¾…å¤„ç†è®¢å•åˆ°Redis...")
                logger.info("=" * 80)
                if _redis is not None:
                    orders_loaded = load_orders_to_redis(_db_instance)
                    if orders_loaded > 0:
                        logger.info(f"âœ… æˆåŠŸåŠ è½½ {orders_loaded} ä¸ªè®¢å•åˆ°Redis")
                    else:
                        # æ²¡æœ‰è®¢å•æ—¶ï¼Œç­‰å¾…è®¢å•è€Œä¸æ˜¯é€€å‡º
                        logger.warning("æ²¡æœ‰æ‰¾åˆ°å¾…å¤„ç†è®¢å•ï¼Œç¨‹åºå°†ç­‰å¾…æ–°è®¢å•...")
                        logger.info("æç¤ºï¼šç¨‹åºå°†æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰æ–°è®¢å•ï¼ŒæŒ‰ Ctrl+C å¯é€€å‡º")
                        
                        # ç­‰å¾…è®¢å•å‡ºç°
                        wait_interval = 30  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                        while True:
                            try:
                                time.sleep(wait_interval)
                                logger.info(f"[ç­‰å¾…è®¢å•] æ£€æŸ¥æ˜¯å¦æœ‰æ–°è®¢å•...")
                                
                                # é‡æ–°åŠ è½½è®¢å•
                                orders_loaded = load_orders_to_redis(_db_instance)
                                if orders_loaded > 0:
                                    logger.info(f"âœ… å‘ç° {orders_loaded} ä¸ªæ–°è®¢å•ï¼Œå¼€å§‹å¤„ç†...")
                                    break
                                else:
                                    logger.info(f"[ç­‰å¾…è®¢å•] æš‚æ— æ–°è®¢å•ï¼Œ{wait_interval}ç§’åå†æ¬¡æ£€æŸ¥...")
                            except Exception as e:
                                logger.error(f"æ£€æŸ¥è®¢å•æ—¶å‡ºé”™: {e}")
                                logger.info(f"{wait_interval}ç§’åé‡è¯•...")
                else:
                    logger.error("Redisæœªè¿æ¥ï¼Œæ— æ³•åŠ è½½è®¢å•ï¼Œç¨‹åºé€€å‡º")
                    sys.exit(1)
        
                # æ­¥éª¤2ï¼šé‡ç½®è®¾å¤‡çŠ¶æ€ï¼ˆå°†æ‰€æœ‰ status in (0,1) çš„è®¾å¤‡æ›´æ–°ä¸º status = 0ï¼‰
                logger.info("=" * 80)
                logger.info("æ­¥éª¤2ï¼šé‡ç½®è®¾å¤‡çŠ¶æ€...")
                logger.info("=" * 80)
                reset_count = reset_device_status(_db_instance, _device_table_name)
                logger.info(f"è®¾å¤‡çŠ¶æ€é‡ç½®å®Œæˆï¼Œå…±é‡ç½® {reset_count} ä¸ªè®¾å¤‡")
                
                # ç»Ÿè®¡è®¾å¤‡æ€»æ•°
                try:
                    total_devices_sql = f"SELECT COUNT(*) as total FROM {_device_table_name}"
                    result = _db_instance.execute(total_devices_sql, fetch=True)
                    if result and len(result) > 0:
                        total_devices = result[0].get('total', 0)
                        logger.info(f"è®¾å¤‡è¡¨ {_device_table_name} æ€»è®¾å¤‡æ•°: {total_devices}")
                        if total_devices > 0:
                            logger.info(f"å¯ç”¨è®¾å¤‡å æ¯”: {reset_count}/{total_devices} ({reset_count/total_devices*100:.1f}%)")
                except Exception as e:
                    logger.warning(f"ç»Ÿè®¡è®¾å¤‡æ€»æ•°å¤±è´¥: {e}")
                
                # æ­¥éª¤3ï¼šåœ¨äº‹åŠ¡ä¸­è·å–å¹¶å‘æ•°æ•°é‡çš„è®¾å¤‡å¹¶æ›´æ–°çŠ¶æ€ä¸º1ï¼ˆè¿›è¡Œä¸­ï¼‰
                logger.info("=" * 80)
                logger.info(f"æ­¥éª¤3ï¼šåœ¨äº‹åŠ¡ä¸­è·å– {_max_concurrent} ä¸ªè®¾å¤‡å¹¶æ›´æ–°çŠ¶æ€ä¸º1...")
                logger.info("=" * 80)
                initial_devices = get_and_lock_devices(
                    db=_db_instance,
                    table_name=_device_table_name,
                    limit=_max_concurrent,
                    status=0
                )
                
                if not initial_devices:
                    logger.warning("æ²¡æœ‰å¯ç”¨çš„è®¾å¤‡ï¼ˆstatus=0ï¼‰ï¼Œç­‰å¾…è®¾å¤‡é‡Šæ”¾...")
                    logger.info("æç¤ºï¼šç¨‹åºå°†æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰å¯ç”¨è®¾å¤‡ï¼ŒæŒ‰ Ctrl+C å¯é€€å‡º")
                    
                    # ç­‰å¾…è®¾å¤‡é‡Šæ”¾
                    wait_interval = 30
                    while True:
                        try:
                            time.sleep(wait_interval)
                            logger.info(f"[ç­‰å¾…è®¾å¤‡] æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨è®¾å¤‡...")
                            
                            # é‡æ–°å°è¯•è·å–è®¾å¤‡
                            initial_devices = get_and_lock_devices(
                                db=_db_instance,
                                table_name=_device_table_name,
                                limit=_max_concurrent,
                                status=0
                            )
                            
                            if initial_devices:
                                logger.info(f"âœ… è·å–åˆ° {len(initial_devices)} ä¸ªå¯ç”¨è®¾å¤‡")
                                break
                            else:
                                logger.info(f"[ç­‰å¾…è®¾å¤‡] æš‚æ— å¯ç”¨è®¾å¤‡ï¼Œ{wait_interval}ç§’åå†æ¬¡æ£€æŸ¥...")
                        except Exception as e:
                            logger.error(f"æ£€æŸ¥è®¾å¤‡æ—¶å‡ºé”™: {e}")
                            logger.info(f"{wait_interval}ç§’åé‡è¯•...")
                
                # æ­¥éª¤4ï¼šä»Redisè·å–ç¬¬ä¸€ä¸ªå¾…å¤„ç†è®¢å•
                logger.info("=" * 80)
                logger.info("æ­¥éª¤4ï¼šä»Redisè·å–ç¬¬ä¸€ä¸ªå¾…å¤„ç†è®¢å•...")
                logger.info("=" * 80)
                orders = get_all_pending_orders_from_redis()
                
                if not orders:
                    logger.warning("Redisä¸­æ²¡æœ‰å¾…å¤„ç†çš„è®¢å•ï¼ˆè¿™ä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºæ­¥éª¤1å·²ç¡®ä¿æœ‰è®¢å•ï¼‰")
                    # å°†è®¾å¤‡çŠ¶æ€æ›´æ–°å› 0
                    device_ids = [device.get('id') for device in initial_devices if device.get('id') is not None]
                    if device_ids:
                        update_devices_status(_db_instance, device_ids, _device_table_name, status=0)
                    # å›åˆ°å¤–å±‚å¾ªç¯é‡æ–°å¼€å§‹
                    logger.info("è¿”å›æ­¥éª¤1é‡æ–°æ£€æŸ¥è®¢å•...")
                    continue
                
                order = orders[0]
                order_id = order['id']
                order_info_str = order.get('order_info', '')
                order_num = order.get('order_num', 0) or 0
                video_ids = parse_video_ids(order_info_str)
                
                logger.info(f"ä»Redisè·å–åˆ°ç¬¬ä¸€ä¸ªè®¢å•: ID={order_id}, order_num={order_num}, Redisä¸­å…±æœ‰ {len(orders)} ä¸ªå¾…å¤„ç†è®¢å•")
                
                if not video_ids:
                    logger.warning(f"è®¢å• {order_id} æ²¡æœ‰æœ‰æ•ˆçš„è§†é¢‘IDï¼Œè·³è¿‡æ­¤è®¢å•")
                    # å°†è®¾å¤‡çŠ¶æ€æ›´æ–°å› 0
                    device_ids = [device.get('id') for device in initial_devices if device.get('id') is not None]
                    if device_ids:
                        update_devices_status(_db_instance, device_ids, _device_table_name, status=0)
                    # æ ‡è®°è®¢å•ä¸ºå¤±è´¥çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
                    _db_instance.update("uni_order", {"status": 3}, "id = %s", (order_id,))
                    _db_instance.commit()
                    # å›åˆ°å¤–å±‚å¾ªç¯é‡æ–°å¼€å§‹
                    logger.info("è¿”å›æ­¥éª¤1å¤„ç†ä¸‹ä¸€ä¸ªè®¢å•...")
                    continue
                
                # è®¾ç½®å½“å‰æ­£åœ¨å¤„ç†çš„è®¢å•ï¼ˆå…¨å±€å˜é‡ï¼‰
                with _current_order_lock:
                    _current_order = order
                
                # æ£€æŸ¥è®¢å•çš„ proxyUrlï¼Œå¦‚æœä¸ä¸ºç©ºåˆ™æ›´æ–°ä»£ç†ï¼ˆåªåˆ¤æ–­ä¸€æ¬¡ï¼Œåç»­æ‰¹æ¬¡å¤ç”¨ï¼‰
                proxy_url = order.get('proxyUrl', '') or order.get('proxy_url', '')
                # å¦‚æœ Redis ä¸­çš„è®¢å•ä¿¡æ¯æ²¡æœ‰ proxyUrlï¼Œå°è¯•ä»æ•°æ®åº“è¯»å–
                if not proxy_url:
                    try:
                        order_from_db = _db_instance.select_one("uni_order", where="id = %s", where_params=(order_id,))
                        if order_from_db:
                            proxy_url = order_from_db.get('proxyUrl', '') or order_from_db.get('proxy_url', '')
                    except Exception as e:
                        logger.debug(f"ä»æ•°æ®åº“è¯»å–è®¢å• {order_id} çš„ proxyUrl å¤±è´¥: {e}")
                
                if proxy_url:
                    try:
                        _api_instance.update_proxy(proxy_url)
                        logger.info(f"âœ… è®¢å• {order_id} çš„ proxyUrl ä¸ä¸ºç©ºï¼Œå·²æ›´æ–°ä»£ç†ä¸º: {proxy_url[:50]}..." if len(proxy_url) > 50 else f"âœ… è®¢å• {order_id} çš„ proxyUrl ä¸ä¸ºç©ºï¼Œå·²æ›´æ–°ä»£ç†ä¸º: {proxy_url}")
                    except Exception as e:
                        logger.error(f"æ›´æ–°ä»£ç†å¤±è´¥: {e}")
                else:
                    logger.debug(f"è®¢å• {order_id} çš„ proxyUrl ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤ä»£ç†")
                
                logger.info(f"ä½¿ç”¨è®¢å• {order_id}ï¼Œè§†é¢‘IDæ•°é‡: {len(video_ids)}ï¼Œorder_num={order_num}ï¼Œå·²è®¾ç½®ä¸ºå½“å‰å¤„ç†è®¢å•")
                
                # æ­¥éª¤5ï¼šåˆ›å»ºåˆå§‹ä»»åŠ¡åˆ—è¡¨
                logger.info("=" * 80)
                logger.info("æ­¥éª¤5ï¼šåˆ›å»ºåˆå§‹ä»»åŠ¡åˆ—è¡¨...")
                logger.info("=" * 80)
                initial_tasks = []
                primary_key_field = get_table_primary_key_field(_db_instance, _device_table_name)
                
                for device in initial_devices:
                    # è·å–ä¸»é”®å€¼
                    primary_key_value = device.get(primary_key_field)
                    
                    if not primary_key_value:
                        logger.warning(f"è®¾å¤‡ä¸»é”®å€¼ä¸ºç©ºï¼Œè·³è¿‡")
                        continue
                    
                    # è§£æ device_config
                    device_config_str = device.get('device_config', '')
                    if device_config_str:
                        device_dict = parse_device_config(device_config_str)
                    else:
                        device_dict = {}
                    
                    # ä»è§£æåçš„ device_config ä¸­è·å– device_id
                    device_id = device_dict.get('device_id', '')
                    if not device_id:
                        # å¦‚æœæ²¡æœ‰device_idï¼Œä½¿ç”¨ä¸»é”®å€¼ä½œä¸ºæ ‡è¯†
                        device_id = str(primary_key_value)
                    
                    # éšæœºé€‰æ‹©ä¸€ä¸ªè§†é¢‘ID
                    aweme_id = random.choice(video_ids)
                    
                    # åˆ›å»ºä»»åŠ¡
                    task = {
                        "aweme_id": aweme_id,
                        "device": device_dict,
                        "device_id": device_id,
                        "device_table": _device_table_name,
                        "primary_key_value": primary_key_value,
                        "order_id": order_id
                    }
                    initial_tasks.append(task)
                
                logger.info(f"åˆ›å»ºäº† {len(initial_tasks)} ä¸ªåˆå§‹ä»»åŠ¡")
                
                # æ­¥éª¤6ï¼šåˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—ï¼ˆå¦‚æœè¿˜æ²¡åˆ›å»ºï¼‰
                logger.info("=" * 80)
                if _queue_instance is None:
                    logger.info("æ­¥éª¤6ï¼šåˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—...")
                    logger.info("=" * 80)
                    _queue_instance = MessageQueue(
                        max_concurrent=_max_concurrent,
                        threshold_callback=threshold_callback,
                        task_callback=task_callback,
                        task_timeout=300.0  # 5 åˆ†é’Ÿè¶…æ—¶ï¼ˆè§†é¢‘æ’­æ”¾ä»»åŠ¡ï¼‰
                    )
                    
                    # æ­¥éª¤7ï¼šå¯åŠ¨é˜Ÿåˆ—
                    logger.info("=" * 80)
                    logger.info("æ­¥éª¤7ï¼šå¯åŠ¨æ¶ˆæ¯é˜Ÿåˆ—...")
                    logger.info("=" * 80)
                    _queue_instance.start()
                    
                    # ç­‰å¾…é˜Ÿåˆ—å¯åŠ¨
                    logger.info("ç­‰å¾…é˜Ÿåˆ—å¯åŠ¨...")
                    max_wait = 10
                    wait_count = 0
                    while not _queue_instance.is_running and wait_count < max_wait * 10:
                        time.sleep(0.1)
                        wait_count += 1
                        if wait_count % 10 == 0:
                            logger.info(f"ç­‰å¾…é˜Ÿåˆ—å¯åŠ¨... ({wait_count/10:.1f}ç§’)")
                    
                    if not _queue_instance.is_running:
                        logger.error("é˜Ÿåˆ—å¯åŠ¨è¶…æ—¶ï¼Œè¿”å›æ­¥éª¤1é‡è¯•")
                        continue
                    
                    logger.info("é˜Ÿåˆ—å·²å¯åŠ¨")
                    
                    # æ­¥éª¤6.5ï¼šä¸ºäº‹ä»¶å¾ªç¯è®¾ç½®ä¸“ç”¨çº¿ç¨‹æ± ï¼ˆè§£å†³çº¿ç¨‹æ± è€—å°½é—®é¢˜ï¼‰
                    logger.info("=" * 80)
                    logger.info("æ­¥éª¤6.5ï¼šè®¾ç½®ä¸“ç”¨çº¿ç¨‹æ± ...")
                    logger.info("=" * 80)
                    import concurrent.futures
                    # åˆ›å»ºä¸€ä¸ªè¶³å¤Ÿå¤§çš„çº¿ç¨‹æ± ï¼šmax_concurrent * 3ï¼ˆæ¯ä¸ªworkerå¯èƒ½åŒæ—¶ä½¿ç”¨å¤šä¸ªçº¿ç¨‹ï¼‰
                    thread_pool_size = _max_concurrent * 3
                    _thread_pool = concurrent.futures.ThreadPoolExecutor(
                        max_workers=thread_pool_size,
                        thread_name_prefix="OrderProcessor"
                    )
                    
                    # å°†çº¿ç¨‹æ± è®¾ç½®ä¸ºäº‹ä»¶å¾ªç¯çš„é»˜è®¤executor
                    if _queue_instance.loop:
                        _queue_instance.loop.set_default_executor(_thread_pool)
                        logger.info(f"å·²ä¸ºäº‹ä»¶å¾ªç¯è®¾ç½®ä¸“ç”¨çº¿ç¨‹æ± ï¼Œå¤§å°: {thread_pool_size} ä¸ªçº¿ç¨‹")
                    else:
                        logger.error("é˜Ÿåˆ—çš„äº‹ä»¶å¾ªç¯ä¸å­˜åœ¨ï¼Œæ— æ³•è®¾ç½®çº¿ç¨‹æ± ")
                        continue
                    
                    # æ­¥éª¤6.8ï¼šå¯åŠ¨è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹
                    logger.info("=" * 80)
                    logger.info("æ­¥éª¤6.8ï¼šå¯åŠ¨è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹...")
                    logger.info("=" * 80)
                    global _monitor_thread, _monitor_stop_event
                    _monitor_stop_event.clear()
                    _monitor_thread = threading.Thread(
                        target=device_status_monitor,
                        name="DeviceMonitor",
                        daemon=True
                    )
                    _monitor_thread.start()
                    logger.info("è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæ¯30ç§’æŠ¥å‘Šä¸€æ¬¡ï¼‰")
                else:
                    logger.info("æ¶ˆæ¯é˜Ÿåˆ—å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»ºæ­¥éª¤")
                    logger.info("=" * 80)
                
                # æ­¥éª¤8ï¼šæ·»åŠ åˆå§‹ä»»åŠ¡åˆ°é˜Ÿåˆ—
                logger.info("=" * 80)
                logger.info("æ­¥éª¤8ï¼šæ·»åŠ åˆå§‹ä»»åŠ¡åˆ°é˜Ÿåˆ—...")
                logger.info("=" * 80)
                
                initial_added = 0
                initial_failed = 0
                for idx, task in enumerate(initial_tasks):
                    success = _queue_instance.add_task(task)
                    if success:
                        initial_added += 1
                    else:
                        initial_failed += 1
                        logger.error(f"åˆå§‹ä»»åŠ¡æ·»åŠ å¤±è´¥ï¼ˆç¬¬ {idx+1}/{len(initial_tasks)} ä¸ªï¼‰")
                
                if initial_failed > 0:
                    logger.warning(f"åˆå§‹ä»»åŠ¡æ·»åŠ å®Œæˆ: æˆåŠŸ={initial_added}, å¤±è´¥={initial_failed}, æ€»è®¡={len(initial_tasks)}")
                    if initial_added == 0:
                        logger.error("æ‰€æœ‰åˆå§‹ä»»åŠ¡æ·»åŠ å¤±è´¥ï¼Œè¿”å›æ­¥éª¤1é‡è¯•")
                        continue
                else:
                    logger.info(f"å·²æˆåŠŸæ·»åŠ  {initial_added} ä¸ªåˆå§‹ä»»åŠ¡åˆ°é˜Ÿåˆ—")
                
                # æ­¥éª¤9ï¼šä¸»å¾ªç¯ï¼ˆç›‘æ§é˜Ÿåˆ—çŠ¶æ€ï¼‰
                logger.info("=" * 80)
                logger.info("æ­¥éª¤9ï¼šè¿›å…¥å†…å±‚å¾ªç¯ï¼Œç›‘æ§é˜Ÿåˆ—çŠ¶æ€...")
                logger.info("=" * 80)
                
                stats_every = order_config.get("stats_every", 5)
                
                # Session æ± ç›‘æ§å˜é‡
                last_session_check = time.time()
                session_check_interval = 60  # æ¯ 60 ç§’æ£€æŸ¥ä¸€æ¬¡ session æ± 
                
                # æ€§èƒ½ç›‘æ§å˜é‡
                last_performance_check = time.time()
                performance_check_interval = 60  # æ¯ 60 ç§’æ£€æŸ¥ä¸€æ¬¡æ€§èƒ½æŒ‡æ ‡
                last_completed_count = 0
                last_failed_count = 0
                
                # åœæ­¢åŸå› å˜é‡
                stop_reason = "æœªçŸ¥åŸå› "
                
                # æ— è®¾å¤‡ç­‰å¾…è®¡æ•°å™¨
                no_device_wait_count = 0
                max_no_device_wait = 6  # æœ€å¤šç­‰å¾…6ä¸ªå‘¨æœŸï¼ˆ30ç§’ï¼Œå¦‚æœstats_every=5ï¼‰
                
                try:
                    while _queue_instance.is_running:
                        time.sleep(stats_every)  # ä¸»å¾ªç¯ä¸­çš„ sleepï¼Œç”¨äºæ§åˆ¶ç»Ÿè®¡é¢‘ç‡
                        
                        queue_stats = _queue_instance.get_stats()
                        queue_size = queue_stats.get("queue_size", 0)
                        running_tasks = queue_stats.get("running_tasks", 0)
                        completed_tasks = queue_stats.get("completed_tasks", 0)
                        failed_tasks = queue_stats.get("failed_tasks", 0)
                
                        # è·å–å½“å‰è®¢å•çš„å®æ—¶è¿›åº¦ï¼ˆä»Redisï¼‰
                        order_progress_info = ""
                        with _current_order_lock:
                            if _current_order:
                                current_order_id = _current_order.get('id')
                                if current_order_id and _redis:
                                    try:
                                        redis_complete = get_order_complete_from_redis(current_order_id)
                                        redis_order_num = get_order_num_from_redis(current_order_id)
                                        if redis_order_num is not None:
                                            order_progress_info = f", è®¢å•{current_order_id}è¿›åº¦={redis_complete}/{redis_order_num}"
                                        else:
                                            order_progress_info = f", è®¢å•{current_order_id}è¿›åº¦={redis_complete}"
                                    except:
                                        pass
                        
                        logger.info(f"é˜Ÿåˆ—çŠ¶æ€: é˜Ÿåˆ—å¤§å°={queue_size}, è¿è¡Œä¸­={running_tasks}/{_max_concurrent}, "
                                  f"é˜Ÿåˆ—ä»»åŠ¡å®Œæˆ={completed_tasks}, å¤±è´¥={failed_tasks}{order_progress_info}")
                        
                        # æ£€æŸ¥å¤±è´¥ç‡ï¼Œå¦‚æœè¿‡é«˜åˆ™å‘å‡ºè­¦å‘Š
                        total_tasks = completed_tasks + failed_tasks
                        if total_tasks > 50:  # è‡³å°‘æœ‰50ä¸ªä»»åŠ¡åæ‰å¼€å§‹æ£€æŸ¥
                            failure_rate = (failed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                            if failure_rate > 50:
                                logger.error(f"ğŸ”´ ä»»åŠ¡å¤±è´¥ç‡è¿‡é«˜: {failure_rate:.1f}% ({failed_tasks}/{total_tasks})")
                                logger.error(f"ğŸ”´ å»ºè®®ï¼š1) æ£€æŸ¥ä»£ç†è´¨é‡ 2) é™ä½å¹¶å‘æ•°ï¼ˆå½“å‰{_max_concurrent}ï¼‰3) å¢åŠ è¯·æ±‚å»¶è¿Ÿ")
                                logger.error(f"ğŸ”´ å¦‚æœæŒç»­å¤±è´¥ï¼Œè¯·è€ƒè™‘æš‚åœç¨‹åºæ£€æŸ¥é…ç½®")
                        
                        # æ£€æŸ¥æ˜¯å¦é˜Ÿåˆ—ä¸ºç©ºä¸”æ²¡æœ‰å¯ç”¨è®¾å¤‡
                        if queue_size == 0 and running_tasks == 0:
                            # é˜Ÿåˆ—å®Œå…¨ç©ºäº†ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨è®¾å¤‡
                            try:
                                check_devices = get_devices_from_table(_db_instance, _device_table_name, limit=1, status=0)
                                if not check_devices:
                                    no_device_wait_count += 1
                                    logger.warning(f"âš ï¸ é˜Ÿåˆ—å·²ç©ºä¸”æ²¡æœ‰å¯ç”¨è®¾å¤‡ (ç­‰å¾… {no_device_wait_count}/{max_no_device_wait})")
                                    
                                    if no_device_wait_count >= max_no_device_wait:
                                        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®¾å¤‡éƒ½å·²ä½¿ç”¨è¿‡ï¼ˆstatus=3ï¼‰
                                        logger.info("æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®¾å¤‡éƒ½å·²ä½¿ç”¨è¿‡...")
                                        try:
                                            # ç»Ÿè®¡å„çŠ¶æ€è®¾å¤‡æ•°é‡
                                            status_sql = f"""
                                            SELECT status, COUNT(*) as count
                                            FROM {_device_table_name}
                                            GROUP BY status
                                            """
                                            status_results = _db_instance.execute(status_sql, fetch=True)
                                            status_counts = {row['status']: row['count'] for row in status_results}
                                            
                                            total_devices = sum(status_counts.values())
                                            completed_devices = status_counts.get(3, 0)  # status=3: å·²å®Œæˆ
                                            failed_devices = status_counts.get(4, 0)  # status=4: è¿ç»­å¤±è´¥å¼‚å¸¸
                                            
                                            logger.info(f"è®¾å¤‡çŠ¶æ€ç»Ÿè®¡: æ€»æ•°={total_devices}, å·²å®Œæˆ={completed_devices}, å¤±è´¥={failed_devices}")
                                            
                                            # å¦‚æœå¤§éƒ¨åˆ†è®¾å¤‡éƒ½å·²å®Œæˆï¼ˆ>80%ï¼‰ï¼Œåˆ™é‡ç½®è®¾å¤‡çŠ¶æ€
                                            if total_devices > 0 and (completed_devices + failed_devices) / total_devices > 0.8:
                                                logger.info("=" * 80)
                                                logger.info(f"ğŸ”„ æ£€æµ‹åˆ° {(completed_devices + failed_devices) / total_devices * 100:.1f}% çš„è®¾å¤‡å·²ä½¿ç”¨è¿‡")
                                                logger.info("ğŸ”„ é‡ç½®è®¾å¤‡çŠ¶æ€ï¼Œè®©æ‰€æœ‰è®¾å¤‡å¯ä»¥é‡æ–°ä½¿ç”¨...")
                                                logger.info("=" * 80)
                                                
                                                # é‡ç½®è®¾å¤‡çŠ¶æ€ï¼šå°† status=3 å’Œ status=1 çš„è®¾å¤‡æ”¹ä¸º status=0
                                                reset_count = reset_device_status(_db_instance, _device_table_name)
                                                logger.info(f"âœ… è®¾å¤‡çŠ¶æ€å·²é‡ç½®ï¼Œ{reset_count} ä¸ªè®¾å¤‡å¯é‡æ–°ä½¿ç”¨")
                                                
                                                # é‡ç½®ç­‰å¾…è®¡æ•°å™¨ï¼Œç»§ç»­å¤„ç†
                                                no_device_wait_count = 0
                                                continue
                                            else:
                                                logger.warning(f"è®¾å¤‡ä½¿ç”¨ç‡è¾ƒä½ ({(completed_devices + failed_devices) / total_devices * 100:.1f}%)ï¼Œä¸é‡ç½®")
                                        except Exception as e:
                                            logger.error(f"æ£€æŸ¥è®¾å¤‡çŠ¶æ€æ—¶å‡ºé”™: {e}")
                                        
                                        stop_reason = "é˜Ÿåˆ—å·²ç©ºä¸”æŒç»­æ— å¯ç”¨è®¾å¤‡"
                                        logger.info(f"[é˜Ÿåˆ—åœæ­¢] åŸå› : {stop_reason}")
                                        logger.info(f"[é˜Ÿåˆ—åœæ­¢] æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œè®¾å¤‡è¡¨ä¸­æ— å¯ç”¨è®¾å¤‡ï¼Œç¨‹åºå°†ä¼˜é›…é€€å‡º")
                                        break
                                else:
                                    # æœ‰è®¾å¤‡äº†ï¼Œé‡ç½®è®¡æ•°å™¨
                                    if no_device_wait_count > 0:
                                        logger.info(f"âœ… å‘ç°å¯ç”¨è®¾å¤‡ï¼Œæ¢å¤æ­£å¸¸è¿è¡Œ")
                                        no_device_wait_count = 0
                            except Exception as e:
                                logger.error(f"æ£€æŸ¥å¯ç”¨è®¾å¤‡æ—¶å‡ºé”™: {e}")
                        else:
                            # é˜Ÿåˆ—ä¸ä¸ºç©ºï¼Œé‡ç½®è®¡æ•°å™¨
                            if no_device_wait_count > 0:
                                no_device_wait_count = 0
                        
                        # å®šæœŸæ£€æŸ¥ Session æ± çŠ¶æ€
                        if time.time() - last_session_check > session_check_interval:
                            try:
                                # è·å– HttpClient ç»Ÿè®¡ä¿¡æ¯
                                http_stats = _http_client_instance.get_stats()
                                
                                # æ–°è®¾è®¡ï¼šåŸºäº user_id çš„å…¨å±€æ± 
                                pool_size = http_stats.get('pool_size', 0)
                                pool_max_size = http_stats.get('pool_max_size', 5000)
                                avg_usage = http_stats.get('avg_usage_count', 0)
                                
                                # è®¡ç®—ä½¿ç”¨ç‡
                                usage_rate = (pool_size / pool_max_size * 100) if pool_max_size > 0 else 0
                                
                                proxy_close_count = http_stats.get('proxy_close_errors', 0)
                                dead_sessions = http_stats.get('dead_sessions_removed', 0)
                                sessions_created = http_stats.get('sessions_created', 0)
                                sessions_recycled = http_stats.get('sessions_recycled', 0)
                                
                                logger.info(f"Sessionæ± çŠ¶æ€: è®¾å¤‡æ•°={pool_size}/{pool_max_size}, "
                                          f"æ± ä½¿ç”¨ç‡={usage_rate:.1f}%, "
                                          f"å¹³å‡ä½¿ç”¨æ¬¡æ•°={avg_usage:.1f}, "
                                          f"è¯·æ±‚={http_stats.get('requests', 0)}, "
                                          f"å¤±è´¥={http_stats.get('failures', 0)}, "
                                          f"é‡è¯•={http_stats.get('retries', 0)}, "
                                          f"ğŸ”´ProxyClose={proxy_close_count}, "
                                          f"åˆ›å»º={sessions_created}, "
                                          f"å›æ”¶={sessions_recycled}, "
                                          f"å¤±æ•ˆæ¸…ç†={dead_sessions}")
                                
                                # è­¦å‘Šï¼šæ± æ¥è¿‘æ»¡è½½
                                if pool_size > pool_max_size * 0.9:
                                    logger.warning(f"âš ï¸ Sessionæ± æ¥è¿‘æ»¡è½½: {pool_size}/{pool_max_size} ({usage_rate:.1f}%), "
                                                 f"å»ºè®®å¢åŠ  max_pool_size æˆ–æ¸…ç†æ— ç”¨è®¾å¤‡")
                                
                                # è­¦å‘Šï¼šå¤±è´¥ç‡è¿‡é«˜
                                total_requests = http_stats.get('requests', 0)
                                total_failures = http_stats.get('failures', 0)
                                if total_requests > 100 and total_failures > 0:
                                    failure_rate = (total_failures / total_requests * 100)
                                    if failure_rate > 10:
                                        logger.warning(f"âš ï¸ HTTPè¯·æ±‚å¤±è´¥ç‡è¿‡é«˜: {failure_rate:.1f}% ({total_failures}/{total_requests})")
                                
                                # è­¦å‘Šï¼šProxy Close é”™è¯¯è¿‡å¤š
                                if proxy_close_count > 0:
                                    proxy_close_rate = (proxy_close_count / total_failures * 100) if total_failures > 0 else 0
                                    if proxy_close_rate > 30:
                                        logger.warning(f"ğŸ”´ Proxy Close é”™è¯¯å æ¯”è¿‡é«˜: {proxy_close_rate:.1f}% ({proxy_close_count}/{total_failures})")
                                        logger.warning(f"   å»ºè®®: 1) æ£€æŸ¥ä»£ç†è´¨é‡ 2) é™ä½ max_session_usage 3) ç¼©çŸ­ health_check_interval")
                                    elif proxy_close_count > 50:
                                        logger.warning(f"ğŸ”´ Proxy Close é”™è¯¯æ€»æ•°è¾ƒå¤š: {proxy_close_count} æ¬¡")
                                
                                last_session_check = time.time()
                            except Exception as e:
                                logger.error(f"æ£€æŸ¥ Session æ± çŠ¶æ€æ—¶å‡ºé”™: {e}")
                        
                        # å®šæœŸæ£€æŸ¥æ€§èƒ½æŒ‡æ ‡å¹¶ç»™å‡ºè°ƒä¼˜å»ºè®®
                        if time.time() - last_performance_check > performance_check_interval:
                            try:
                                queue_stats = _queue_instance.get_stats()
                                current_completed = queue_stats.get('completed_tasks', 0)
                                current_failed = queue_stats.get('failed_tasks', 0)
                                
                                # è®¡ç®—æœ€è¿‘1åˆ†é’Ÿçš„å®Œæˆæ•°å’Œå¤±è´¥æ•°
                                completed_delta = current_completed - last_completed_count
                                failed_delta = current_failed - last_failed_count
                                total_delta = completed_delta + failed_delta
                                
                                if total_delta > 0:
                                    success_rate = (completed_delta / total_delta * 100)
                                    throughput = total_delta / performance_check_interval  # æ¯ç§’å¤„ç†æ•°
                                    
                                    logger.info(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡ï¼ˆæœ€è¿‘{performance_check_interval:.0f}ç§’ï¼‰ï¼š")
                                    logger.info(f"   - å¤„ç†é€Ÿåº¦: {throughput:.1f} ä»»åŠ¡/ç§’")
                                    logger.info(f"   - æˆåŠŸç‡: {success_rate:.1f}% ({completed_delta}æˆåŠŸ/{failed_delta}å¤±è´¥)")
                                    logger.info(f"   - æ€»è®¡: å®Œæˆ{current_completed}, å¤±è´¥{current_failed}")
                                    
                                    # ç»™å‡ºæ€§èƒ½è°ƒä¼˜å»ºè®®
                                    if success_rate < 50:
                                        logger.warning(f"âš ï¸ [æ€§èƒ½å»ºè®®] æˆåŠŸç‡è¿‡ä½({success_rate:.1f}%)ï¼Œå»ºè®®ï¼š")
                                        logger.warning(f"   1. é™ä½å¹¶å‘æ•°ï¼ˆå½“å‰{_max_concurrent}ï¼‰åˆ° {int(_max_concurrent * 0.7)}")
                                        logger.warning(f"   2. å¢åŠ è¯·æ±‚å»¶è¿Ÿï¼ˆå½“å‰{_request_delay_min*1000:.0f}-{_request_delay_max*1000:.0f}msï¼‰")
                                        logger.warning(f"   3. æ£€æŸ¥ä»£ç†è´¨é‡å’Œç½‘ç»œçŠ¶å†µ")
                                    elif success_rate > 90 and throughput < _max_concurrent * 0.3:
                                        logger.info(f"âœ… [æ€§èƒ½å»ºè®®] æˆåŠŸç‡å¾ˆé«˜({success_rate:.1f}%)ä½†ååé‡è¾ƒä½ï¼Œå¯ä»¥è€ƒè™‘ï¼š")
                                        logger.info(f"   1. é€‚å½“æé«˜å¹¶å‘æ•°åˆ° {int(_max_concurrent * 1.3)}")
                                        logger.info(f"   2. å‡å°‘è¯·æ±‚å»¶è¿Ÿï¼ˆå½“å‰{_request_delay_min*1000:.0f}-{_request_delay_max*1000:.0f}msï¼‰")
                                
                                last_completed_count = current_completed
                                last_failed_count = current_failed
                                last_performance_check = time.time()
                            except Exception as e:
                                logger.error(f"æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
                        
                        # æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦æ„å¤–åœæ­¢
                        if not _queue_instance.is_running:
                            stop_reason = "é˜Ÿåˆ—æ„å¤–åœæ­¢"
                            logger.error(f"[é˜Ÿåˆ—åœæ­¢] åŸå› : {stop_reason}")
                            break
                        
                        # æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å®Œå…¨ç©ºé—²ï¼ˆæ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆï¼‰
                        if queue_size == 0 and running_tasks == 0:
                            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å…¶ä»–æ£€æŸ¥å®Œæˆäº†è®¢å•
                            with _order_completed_lock:
                                if _order_completed_flag:
                                    logger.info("âœ… è®¢å•å·²è¢«æ ‡è®°ä¸ºå®Œæˆï¼Œè·³å‡ºå¾ªç¯åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªè®¢å•")
                                    stop_reason = "è®¢å•å·²å®Œæˆ"
                                    break
                            
                            logger.info("=" * 80)
                            logger.info("æ£€æµ‹åˆ°é˜Ÿåˆ—å®Œå…¨ç©ºé—²ï¼Œæ£€æŸ¥è®¢å•çŠ¶æ€...")
                            logger.info("=" * 80)
                            
                            # ç«‹å³æ£€æŸ¥è®¢å•æ˜¯å¦å®Œæˆï¼ˆå®Œå…¨ä»Redisè¯»å–ï¼‰
                            try:
                                # ä»Redisè·å–è®¢å•ä¿¡æ¯å’Œè¿›åº¦
                                if not _redis:
                                    logger.warning("Redisæœªè¿æ¥ï¼Œæ— æ³•æ£€æŸ¥è®¢å•çŠ¶æ€")
                                    continue
                                
                                redis_complete = get_order_complete_from_redis(order_id)
                                redis_order_num = get_order_num_from_redis(order_id)
                                
                                if redis_order_num is None or redis_order_num == 0:
                                    logger.warning(f"è®¢å• {order_id} åœ¨Redisä¸­æ²¡æœ‰order_numæ•°æ®ï¼Œå°è¯•ä»æ•°æ®åº“é‡æ–°åŠ è½½...")
                                    # ä»æ•°æ®åº“é‡æ–°åŠ è½½è®¢å•ä¿¡æ¯åˆ°Redis
                                    try:
                                        order_info = _db_instance.select_one("uni_order", where="id = %s", where_params=(order_id,))
                                        if order_info:
                                            # ä¿å­˜è®¢å•ä¿¡æ¯åˆ°Redis
                                            order_info_json = json.dumps(order_info, ensure_ascii=False, default=str)
                                            _redis.hset(REDIS_ORDER_INFO_KEY, str(order_id), order_info_json)
                                            
                                            # ä¿å­˜order_numåˆ°Redis
                                            order_num = order_info.get('order_num', 0) or 0
                                            _redis.hset(REDIS_ORDER_NUM_KEY, str(order_id), order_num)
                                            
                                            # ä¿å­˜complete_numåˆ°Redis
                                            complete_num = order_info.get('complete_num', 0) or 0
                                            _redis.hset(REDIS_ORDER_COMPLETE_KEY, str(order_id), complete_num)
                                            
                                            logger.info(f"âœ… è®¢å• {order_id} ä¿¡æ¯å·²é‡æ–°åŠ è½½åˆ°Redis: order_num={order_num}, complete_num={complete_num}")
                                            
                                            # é‡æ–°è·å–Redisæ•°æ®
                                            redis_complete = complete_num
                                            redis_order_num = order_num
                                        else:
                                            logger.error(f"è®¢å• {order_id} åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨")
                                            continue
                                    except Exception as reload_error:
                                        logger.error(f"ä»æ•°æ®åº“é‡æ–°åŠ è½½è®¢å• {order_id} å¤±è´¥: {reload_error}")
                                        continue
                                
                                logger.info(f"å½“å‰è®¢å• {order_id} çŠ¶æ€(Redis): complete_num={redis_complete}/{redis_order_num}")
                                
                                # å®Œå…¨åŸºäºRedisæ•°æ®åˆ¤æ–­
                                if redis_complete >= redis_order_num:
                                    # è®¾ç½®è®¢å•å®Œæˆæ ‡å¿—ï¼Œå–æ¶ˆå…¶ä»–æ£€æŸ¥
                                    with _order_completed_lock:
                                        _order_completed_flag = True
                                    logger.info(f"âœ… è®¢å• {order_id} å·²å®Œæˆï¼å·²è®¾ç½®å®Œæˆæ ‡å¿—")
                                    
                                    # æ›´æ–°æ•°æ®åº“çŠ¶æ€ï¼ˆä½¿ç”¨Redisä¸­çš„å®Œæˆæ•°ï¼‰
                                    _db_instance.update("uni_order", {"status": 2, "complete_num": redis_complete}, "id = %s", (order_id,))
                                    _db_instance.commit()
                                    logger.info(f"âœ… è®¢å• {order_id} æ•°æ®åº“çŠ¶æ€å·²æ›´æ–°: status=2, complete_num={redis_complete}")
                                    
                                    # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªå¾…å¤„ç†è®¢å•
                                    next_orders = _db_instance.select(
                                        "uni_order",
                                        where="status IN (0, 1)",
                                        order_by="id ASC",
                                        limit=1
                                    )
                                    
                                    if next_orders:
                                        next_order = next_orders[0]
                                        next_order_id = next_order['id']
                                        logger.info(f"å‘ç°ä¸‹ä¸€ä¸ªè®¢å• {next_order_id}ï¼Œå‡†å¤‡åˆ‡æ¢...")
                                        stop_reason = "å½“å‰è®¢å•å®Œæˆï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªè®¢å•"
                                    else:
                                        logger.info("æ²¡æœ‰æ›´å¤šå¾…å¤„ç†è®¢å•")
                                        stop_reason = "æ‰€æœ‰è®¢å•å·²å®Œæˆ"
                                    break
                                else:
                                    # è®¢å•æœªå®Œæˆï¼Œä½†é˜Ÿåˆ—å·²ç©º
                                    logger.warning(f"âš ï¸ è®¢å• {order_id} æœªå®Œæˆä½†é˜Ÿåˆ—å·²ç©º")
                                    logger.warning(f"   è®¢å•è¿›åº¦(Redis): {redis_complete}/{redis_order_num}")
                                    logger.warning(f"   ä»»åŠ¡ç»Ÿè®¡: å®Œæˆ={completed_tasks}, å¤±è´¥={failed_tasks}")
                                    
                                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¯ç”¨è®¾å¤‡
                                    available_devices = get_devices_from_table(_db_instance, _device_table_name, limit=1, status=0)
                                    if not available_devices:
                                        logger.warning(f"   æ²¡æœ‰å¯ç”¨è®¾å¤‡ï¼Œè®¢å•æ— æ³•ç»§ç»­")
                                        logger.info("ç»“æŸå½“å‰è®¢å•å¤„ç†ï¼Œè¿”å›å¤–å±‚å¾ªç¯")
                                        stop_reason = "è®¢å•æœªå®Œæˆä½†æ— å¯ç”¨è®¾å¤‡"
                                        break
                                    else:
                                        logger.info(f"   æœ‰å¯ç”¨è®¾å¤‡ï¼Œä½†é˜Ÿåˆ—å·²ç©ºï¼Œå¯èƒ½æ˜¯é˜ˆå€¼å›è°ƒæœªè§¦å‘")
                                        logger.info(f"   ç»§ç»­ç­‰å¾…é˜ˆå€¼å›è°ƒè¡¥å……ä»»åŠ¡...")
                            except Exception as e:
                                logger.error(f"æ£€æŸ¥è®¢å•çŠ¶æ€æ—¶å‡ºé”™: {e}")
                                import traceback
                                logger.error(traceback.format_exc())
                        
                        # æ³¨æ„ï¼šè®¢å•å®Œæˆæ£€æŸ¥å·²ç»åœ¨é˜Ÿåˆ—ç©ºé—²æ—¶ç«‹å³æ‰§è¡Œ
                        # è¿™é‡Œä¸å†éœ€è¦å®šæœŸæ£€æŸ¥ï¼Œé¿å…é‡å¤æŸ¥è¯¢æ•°æ®åº“
                except Exception as inner_e:
                    stop_reason = f"ä¸»å¾ªç¯å¼‚å¸¸: {inner_e}"
                    logger.error(f"[é˜Ÿåˆ—åœæ­¢] åŸå› : {stop_reason}")
                    import traceback
                    logger.error(traceback.format_exc())
                    # å‘ç”Ÿå¼‚å¸¸æ—¶ä¹Ÿè·³å‡ºå†…å±‚å¾ªç¯ï¼Œå›åˆ°å¤–å±‚å¾ªç¯é‡è¯•
                    logger.info("å‘ç”Ÿå¼‚å¸¸ï¼Œè¿”å›æ­¥éª¤1é‡æ–°å¼€å§‹...")
                
                # å†…å±‚å¾ªç¯ç»“æŸï¼Œè®°å½•åŸå› 
                logger.info(f"å†…å±‚å¾ªç¯ç»“æŸï¼ŒåŸå› : {stop_reason}")
                
                # æ¸…ç†é˜Ÿåˆ—å’Œèµ„æºï¼Œå‡†å¤‡ä¸‹ä¸€è½®å¾ªç¯ï¼ˆå¼ºåˆ¶åœæ­¢æ¨¡å¼ï¼‰
                logger.info("=" * 80)
                logger.info("å¼ºåˆ¶æ¸…ç†å½“å‰å¾ªç¯çš„èµ„æº...")
                logger.info("=" * 80)
                
                # 0. é‡ç½®è®¢å•å®Œæˆæ ‡å¿—
                with _order_completed_lock:
                    _order_completed_flag = False
                logger.info("âœ“ è®¢å•å®Œæˆæ ‡å¿—å·²é‡ç½®")
                
                # 1. å¼ºåˆ¶åœæ­¢é˜Ÿåˆ—ï¼ˆä¸ç­‰å¾…ï¼‰
                if _queue_instance:
                    logger.info("å¼ºåˆ¶åœæ­¢æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆä¸ç­‰å¾…ä»»åŠ¡å®Œæˆï¼‰...")
                    try:
                        # ç›´æ¥åœæ­¢ï¼Œä¸ç­‰å¾…
                        if _queue_instance.is_running:
                            _queue_instance.stop()
                        logger.info("âœ“ æ¶ˆæ¯é˜Ÿåˆ—åœæ­¢ä¿¡å·å·²å‘é€")
                    except Exception as e:
                        logger.warning(f"åœæ­¢é˜Ÿåˆ—æ—¶å‡ºé”™: {e}")
                    
                    # ä¸ç­‰å¾…äº‹ä»¶å¾ªç¯å…³é—­ï¼Œç›´æ¥ç»§ç»­
                    logger.info("âœ“ è·³è¿‡äº‹ä»¶å¾ªç¯ç­‰å¾…ï¼ˆå¼ºåˆ¶æ¨¡å¼ï¼‰")
                
                # 2. åˆ·æ–°Redisæ•°æ®åˆ°MySQL
                if _redis is not None:
                    logger.info("åˆ·æ–°Redisç¼“å­˜æ•°æ®åˆ°MySQL...")
                    try:
                        flush_stats = flush_redis_to_mysql(_db_instance, _device_table_name)
                        logger.info(f"æ•°æ®åˆ·æ–°å®Œæˆ: è®¾å¤‡æ›´æ–°={flush_stats['devices_updated']}, "
                                  f"è®¾å¤‡å¤±è´¥={flush_stats.get('devices_failed', 0)}")
                        
                        # æ¸…ç†Redisç¼“å­˜ï¼ˆåªæ¸…ç†è®¾å¤‡ç¼“å­˜ï¼Œè®¢å•ç¼“å­˜åœ¨ä¸‹ä¸€è½®é‡æ–°åŠ è½½ï¼‰
                        clear_redis_cache(clear_orders=False)
                        logger.info("Redisè®¾å¤‡ç¼“å­˜å·²æ¸…ç†")
                    except Exception as e:
                        logger.error(f"åˆ·æ–°æ•°æ®å¤±è´¥: {e}")
                
                # 3. æ¸…ç†HTTP sessionæ± ï¼ˆé¿å…äº‹ä»¶å¾ªç¯ç»‘å®šé—®é¢˜ï¼‰
                logger.info("æ¸…ç†HTTP sessionæ± ...")
                try:
                    http_client_async.clear_global_pool()
                    logger.info("âœ“ HTTP sessionæ± å·²æ¸…ç†")
                except Exception as e:
                    logger.warning(f"æ¸…ç†HTTP sessionæ± æ—¶å‡ºé”™: {e}")
                
                # 4. å¼ºåˆ¶å…³é—­çº¿ç¨‹æ± ï¼ˆä¸ç­‰å¾…ï¼‰
                if _thread_pool:
                    logger.info("å¼ºåˆ¶å…³é—­çº¿ç¨‹æ± ï¼ˆä¸ç­‰å¾…ï¼‰...")
                    try:
                        _thread_pool.shutdown(wait=False)
                        logger.info("âœ“ çº¿ç¨‹æ± å·²å¼ºåˆ¶å…³é—­")
                    except Exception as e:
                        logger.warning(f"å…³é—­çº¿ç¨‹æ± æ—¶å‡ºé”™: {e}")
                    _thread_pool = None
                
                # 5. å¼ºåˆ¶é‡ç½®é˜Ÿåˆ—å®ä¾‹
                if _queue_instance:
                    try:
                        del _queue_instance
                    except:
                        pass
                _queue_instance = None
                logger.info("âœ“ é˜Ÿåˆ—å®ä¾‹å·²å¼ºåˆ¶é‡ç½®")
                
                # 6. å¼ºåˆ¶åœæ­¢è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹ï¼ˆä¸ç­‰å¾…ï¼‰
                if _monitor_thread and _monitor_thread.is_alive():
                    logger.info("å¼ºåˆ¶åœæ­¢è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹ï¼ˆä¸ç­‰å¾…ï¼‰...")
                    _monitor_stop_event.set()
                    # ä¸ç­‰å¾…çº¿ç¨‹ç»“æŸï¼Œç›´æ¥ç»§ç»­
                    logger.info("âœ“ ç›‘æ§çº¿ç¨‹åœæ­¢ä¿¡å·å·²å‘é€")
                
                logger.info("=" * 80)
                logger.info("èµ„æºæ¸…ç†å®Œæˆï¼Œå‡†å¤‡å¼€å§‹æ–°ä¸€è½®å¾ªç¯...")
                logger.info("=" * 80)
                
                # æ˜ç¡®æ ‡è®°ï¼šå³å°†å›åˆ°å¤–å±‚å¾ªç¯å¼€å§‹
                logger.info("ğŸ”„ å›åˆ°å¤–å±‚å¾ªç¯ï¼Œé‡æ–°å¼€å§‹æ­¥éª¤1...")
                
            except Exception as outer_e:
                logger.error(f"å¤–å±‚å¾ªç¯å¼‚å¸¸: {outer_e}")
                import traceback
                logger.error(traceback.format_exc())
                logger.info("30ç§’åé‡è¯•...")
                time.sleep(30)
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())
        # ç¡®ä¿æ¸…ç†èµ„æº
        if _queue_instance and _queue_instance.is_running:
            _queue_instance.stop()
            _queue_instance.wait()
        if _db_instance:
            _db_instance.close()
        sys.exit(1)
    finally:
        # å…ˆåœæ­¢é˜Ÿåˆ—ï¼Œç­‰å¾…æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•
        if _queue_instance:
            logger.info("æ­£åœ¨åœæ­¢æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼‰...")
            _queue_instance.stop()
            _queue_instance.wait()
            logger.info("æ¶ˆæ¯é˜Ÿåˆ—å·²åœæ­¢ï¼Œæ‰€æœ‰ä»»åŠ¡å·²å¤„ç†å®Œæ¯•")
        
        # ä¸å†åœ¨ç¨‹åºé€€å‡ºæ—¶åˆ·æ–°Redisæ•°æ®
        # æ•°æ®åˆ·æ–°ç­–ç•¥ï¼š
        # 1. ç¨‹åºå¯åŠ¨æ—¶åˆ·æ–°è®¾å¤‡æ’­æ”¾æ¬¡æ•°ï¼ˆå¤„ç†ä¸Šæ¬¡é—ç•™æ•°æ®ï¼‰
        # 2. è®¢å•å®Œæˆæ—¶åˆ·æ–°æ‰€æœ‰æ•°æ®ï¼ˆè®¾å¤‡ + è®¢å•ï¼‰
        logger.info("=" * 80)
        logger.info("ç¨‹åºé€€å‡ºï¼ŒRedisæ•°æ®ä¿ç•™åœ¨ç¼“å­˜ä¸­ï¼ˆå°†åœ¨ä¸‹æ¬¡å¯åŠ¨æ—¶åˆ·æ–°ï¼‰")
        logger.info("=" * 80)
        
        # å†åœæ­¢é˜ˆå€¼å›è°ƒå¤„ç†å™¨çº¿ç¨‹ï¼ˆæ­¤æ—¶é˜Ÿåˆ—å·²ç©ºï¼Œä¸ä¼šå†æœ‰æ–°ä»»åŠ¡ï¼‰
        if _threshold_callback_stop_event:
            logger.info("æ­£åœ¨åœæ­¢é˜ˆå€¼å›è°ƒå¤„ç†å™¨çº¿ç¨‹...")
            _threshold_callback_stop_event.set()
            if _threshold_callback_processor_thread and _threshold_callback_processor_thread.is_alive():
                _threshold_callback_processor_thread.join(timeout=5)
                if _threshold_callback_processor_thread.is_alive():
                    logger.warning("é˜ˆå€¼å›è°ƒå¤„ç†å™¨çº¿ç¨‹æœªåœ¨5ç§’å†…åœæ­¢")
                else:
                    logger.info("é˜ˆå€¼å›è°ƒå¤„ç†å™¨çº¿ç¨‹å·²åœæ­¢")
        
        # åœæ­¢è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹
        if _monitor_thread and _monitor_thread.is_alive():
            logger.info("æ­£åœ¨åœæ­¢è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹...")
            _monitor_stop_event.set()
            _monitor_thread.join(timeout=3)
            if _monitor_thread.is_alive():
                logger.warning("è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹æœªåœ¨3ç§’å†…åœæ­¢")
            else:
                logger.info("è®¾å¤‡çŠ¶æ€ç›‘æ§çº¿ç¨‹å·²åœæ­¢")
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        if _queue_instance:
            final_stats = _queue_instance.get_stats()
            total_tasks = final_stats.get('total_tasks', 0)
            completed_tasks = final_stats.get('completed_tasks', 0)
            failed_tasks = final_stats.get('failed_tasks', 0)
            success_rate = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
            
            logger.info("=" * 80)
            logger.info("ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            logger.info(f"  é˜Ÿåˆ—æ€»ä»»åŠ¡æ•°: {total_tasks}")
            logger.info(f"  âœ… å·²å®Œæˆ: {completed_tasks}")
            logger.info(f"  âŒ å¤±è´¥: {failed_tasks}")
            logger.info(f"  ğŸ“ˆ æˆåŠŸç‡: {success_rate:.2f}%")
            logger.info(f"  ğŸ›‘ åœæ­¢åŸå› : {stop_reason}")
            logger.info("=" * 80)
            
            # æ ¹æ®æˆåŠŸç‡ç»™å‡ºè¯„ä»·
            if success_rate >= 80:
                logger.info("ğŸ‰ æ€§èƒ½è¯„ä»·: ä¼˜ç§€ - ç³»ç»Ÿè¿è¡Œéå¸¸ç¨³å®š")
            elif success_rate >= 60:
                logger.info("âœ… æ€§èƒ½è¯„ä»·: è‰¯å¥½ - ç³»ç»Ÿè¿è¡ŒåŸºæœ¬ç¨³å®š")
            elif success_rate >= 40:
                logger.warning("âš ï¸ æ€§èƒ½è¯„ä»·: ä¸€èˆ¬ - å»ºè®®ä¼˜åŒ–é…ç½®æˆ–æ£€æŸ¥ç½‘ç»œ")
            else:
                logger.error("âŒ æ€§èƒ½è¯„ä»·: è¾ƒå·® - éœ€è¦ç«‹å³æ£€æŸ¥ä»£ç†ã€ç½‘ç»œæˆ–é™ä½å¹¶å‘")
            
            logger.info("=" * 80)
        
        # å…³é—­çº¿ç¨‹æ± 
        if _thread_pool:
            logger.info("æ­£åœ¨å…³é—­çº¿ç¨‹æ± ...")
            _thread_pool.shutdown(wait=True, cancel_futures=False)
            logger.info("çº¿ç¨‹æ± å·²å…³é—­")
        
        _db_instance.close()
        logger.info("æ•°æ®åº“è¿æ¥æ± å·²å…³é—­")
        logger.info("ç¨‹åºå·²é€€å‡º")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)

