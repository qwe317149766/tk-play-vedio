# 日志优化和超时配置总结

## 修改日期
2025-11-16

## 修改内容

### 1. 日志简化

#### 1.1 `order_processor.py`
- ❌ 删除 `[get_and_lock_devices]` 的详细日志（SELECT、UPDATE、提交事务等）
- ❌ 删除 "在事务中获取并锁定 X 个设备" 日志
- ✅ 保留异常和警告日志（超时、并发竞争等）

#### 1.2 `message_queue.py`
- ❌ 删除所有 worker 启动/停止日志
- ❌ 删除任务获取/开始执行的日志
- ❌ 删除任务执行完成的日志（正常流程）
- ❌ 简化停止时的警告日志（改为 debug 级别）
- ❌ 队列未运行时的错误日志改为 debug 级别
- ✅ 保留错误日志和异常情况

#### 1.3 `http_client.py`
- ❌ 删除请求开始日志
- ❌ 删除请求完成日志（正常情况）
- ❌ 删除网络错误重试日志（正常情况）
- ✅ 只在 debug 模式下显示详细日志
- ✅ 保留异常情况的错误日志

#### 1.4 `demos/stats/tem3.py`
- ✅ 简化响应日志为一行：`[设备: {device_id}] {response_json}`
- ❌ 删除 "Status Code" 和 "--- Response Body ---" 分隔线

### 2. 超时配置优化

#### 2.1 `message_queue.py`
**新增参数：**
```python
def __init__(
    self,
    max_concurrent: int = 1000,
    threshold_callback: Optional[Callable] = None,
    task_callback: Optional[Callable] = None,
    task_timeout: float = 600.0  # 新增：任务超时时间（秒）
):
```

**超时检测优化：**
- 只在超过 `task_timeout` 时才认为任务超时
- 只在超过 **50% 的任务都超时**时才警告（减少噪音）
- 删除 120 秒"长时间运行"的额外警告
- 警告信息更简洁：`检测到 X/Y 个任务执行超时（超过 Z秒）`

#### 2.2 `device_flow_queue.py`
```python
_queue_instance = MessageQueue(
    max_concurrent=CONFIG.get("max_concurrent", 1000),
    threshold_callback=threshold_callback,
    task_callback=task_callback,
    task_timeout=1200.0  # 20 分钟超时（设备流程任务可能较慢）
)
```

**原因：** 设备流程任务包含多个步骤（获取seed、token、播放视频等），可能需要较长时间。

#### 2.3 `order_processor.py`
```python
_queue_instance = MessageQueue(
    max_concurrent=_max_concurrent,
    threshold_callback=threshold_callback,
    task_callback=task_callback,
    task_timeout=300.0  # 5 分钟超时（视频播放任务）
)
```

**原因：** 视频播放任务相对简单，5 分钟足够。

### 3. 日志级别说明

#### 正常运行（INFO 级别）
- ✅ 启动/停止消息
- ✅ 阈值回调补充任务结果
- ✅ 最终统计信息

#### 警告（WARNING 级别）
- ⚠️ 超过 50% 的任务执行超时
- ⚠️ 数据库查询超过 10 秒
- ⚠️ 设备更新时出现并发竞争
- ⚠️ 信号量死锁检测

#### 错误（ERROR 级别）
- ❌ 任务执行异常
- ❌ 数据库操作失败
- ❌ 网络请求失败（达到最大重试次数）
- ❌ 严重的系统问题（所有任务都超时等）

#### 调试（DEBUG 级别）
- 🔍 任务添加确认
- 🔍 队列停止时的超时警告
- 🔍 HttpClient 的详细请求信息（需要开启 debug 模式）

## 效果

### 修改前（噪音日志）
```
INFO:__main__:[阈值回调] 队列状态检查: 队列大小=19, 运行中=10...
INFO:__main__:[阈值回调] 开始补充任务，需要补充 1 个任务
INFO:__main__:[阈值回调] 使用当前订单 1，从数据库获取最新信息...
INFO:__main__:[get_and_lock_devices] 执行SELECT查询...
INFO:__main__:[get_and_lock_devices] SELECT查询完成，耗时: 0.693秒
INFO:__main__:[get_and_lock_devices] 执行UPDATE查询...
INFO:__main__:[get_and_lock_devices] UPDATE查询完成，耗时: 0.025秒
INFO:__main__:[get_and_lock_devices] 提交事务
INFO:__main__:在事务中获取并锁定 1 个设备，状态已更新为1
[HttpClient] [发起请求] 开始调用 post(), url=..., timeout=30
[HttpClient] 请求完成，耗时: 5.956s, 状态码: 200
[HttpClient] 总耗时: 5.957s
INFO:message_queue:工作协程 1 任务执行完成，耗时: 22.211秒
INFO:message_queue:工作协程 9 已获取信号量，从队列获取任务...
INFO:message_queue:工作协程 9 开始执行任务，当前运行中: 10/10
WARNING:message_queue:  工作协程 71 任务执行时间: 286.1秒
WARNING:message_queue:  工作协程 73 任务执行时间: 286.1秒
... (大量重复日志)
```

### 修改后（简洁日志）
```
INFO:__main__:[阈值回调] ✓ 成功补充 5 个任务到队列 | 队列: 14→19，已完成: 882
[设备: 7570414424780834318] {"status_code":0,"extra":{"now":1763224011000},...}
WARNING:message_queue:检测到 15/20 个任务执行超时（超过 1200.0秒）
```

## 配置建议

### 开发/调试环境
```python
# 开启 HttpClient debug 模式
http_client = HttpClient(debug=True, ...)

# 设置较短的超时时间以快速发现问题
MessageQueue(..., task_timeout=60.0)  # 1分钟

# 设置日志级别为 DEBUG
logging.basicConfig(level=logging.DEBUG)
```

### 生产环境
```python
# 关闭 HttpClient debug 模式（默认）
http_client = HttpClient(debug=False, ...)

# 设置合理的超时时间
MessageQueue(..., task_timeout=300.0)  # 5分钟（视频播放）
MessageQueue(..., task_timeout=1200.0)  # 20分钟（设备流程）

# 设置日志级别为 INFO
logging.basicConfig(level=logging.INFO)
```

## 注意事项

1. **超时时间设置**
   - 根据实际任务类型设置合理的超时时间
   - 网络请求密集的任务需要更长的超时时间
   - 可以通过监控日志中的超时警告来调整

2. **日志监控**
   - 正常运行时日志应该很少（除了定期的补充任务日志）
   - 如果出现大量警告，需要检查系统是否有问题
   - 超过 50% 的任务超时说明有严重问题，需要立即处理

3. **Debug 模式**
   - 只在需要排查问题时开启
   - Debug 模式会产生大量日志，影响性能

4. **停止时的日志**
   - "队列未运行"错误已改为 debug 级别，避免停止时的噪音
   - 停止超时警告已改为 debug 级别，避免正常停止时的误报

